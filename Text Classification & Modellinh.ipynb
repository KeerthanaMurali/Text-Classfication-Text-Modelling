{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5G4SCrIxcsY"
   },
   "source": [
    "# Assignment 1 for FIT5212, Semester 1, 2020\n",
    "\n",
    "**Student Name:**  Keerthana Muralitharan\n",
    "\n",
    "**Student ID:**    30159474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbyfXLkIxcsd"
   },
   "source": [
    "## Part 1:  Text Classification\n",
    "\n",
    "Text Classification is to be done on the content gathered from the popular academic website arXiv.org for articles tagged under computer science content which are also present under mathematics and physics categories.We are provided with a training set whose data is from 1990-2014 and the testing set data consists of data from 2015 and a bit from 2016 as well.\n",
    " InfoTheory, CompVis and Math are the three classes which are occurring in the text in any combination whether present in all three classes or any two,one or not even in any of the three classes.Our assignment task is to build three text classifiers that predict these three classes only by using the Abstract field using the modelling statistical text classifiers and neural network classifiers and decide the efficiency among the all 6 models.\n",
    "\n",
    " #### 1.1:  Text Processing & Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "ntIOdHpfe5aL",
    "outputId": "f5179d90-7546-4866-a36e-3dcc3c3de63f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs-9301111</td>\n",
       "      <td>arxiv.org/abs/cs/9301111</td>\n",
       "      <td>31/12/1989</td>\n",
       "      <td>Nested satisfiability</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nested satisfiability A special case of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs-9301112</td>\n",
       "      <td>arxiv.org/abs/cs/9301112</td>\n",
       "      <td>31/03/1990</td>\n",
       "      <td>A note on digitized angles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A note on digitized angles We study the confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs-9301113</td>\n",
       "      <td>arxiv.org/abs/cs/9301113</td>\n",
       "      <td>31/07/1991</td>\n",
       "      <td>Textbook examples of recursion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Textbook examples of recursion We discuss pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs-9301114</td>\n",
       "      <td>arxiv.org/abs/cs/9301114</td>\n",
       "      <td>31/10/1991</td>\n",
       "      <td>Theory and practice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory and practice The author argues to Sili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs-9301115</td>\n",
       "      <td>arxiv.org/abs/cs/9301115</td>\n",
       "      <td>30/11/1991</td>\n",
       "      <td>Context-free multilanguages</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Context-free multilanguages This article is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  ...                                           Abstract\n",
       "0  cs-9301111  ...   Nested satisfiability A special case of the s...\n",
       "1  cs-9301112  ...   A note on digitized angles We study the confi...\n",
       "2  cs-9301113  ...   Textbook examples of recursion We discuss pro...\n",
       "3  cs-9301114  ...   Theory and practice The author argues to Sili...\n",
       "4  cs-9301115  ...   Context-free multilanguages This article is a...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre- processing\n",
    "import pandas as pd \n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df_train = pd.read_csv(\"/content/drive/My Drive/axcs_train.csv\", delimiter=',')\n",
    "df_test = pd.read_csv(\"/content/drive/My Drive/axcs_test.csv\", delimiter=',')\n",
    "\n",
    "#display sample of the rows present in the dataframes\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "vXtqsrsZkw7r",
    "outputId": "b22afdf5-421d-422e-f695-473a2e7b96a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-150100335</td>\n",
       "      <td>arxiv.org/abs/1501.00335</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appli...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-14024178</td>\n",
       "      <td>arxiv.org/abs/1402.4178</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>A reclaimer scheduling problem arising in coal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A reclaimer scheduling problem arising in coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-150100263</td>\n",
       "      <td>arxiv.org/abs/1501.00263</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>Communication-Efficient Distributed Optimizati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Communication-Efficient Distributed Optimizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-150100287</td>\n",
       "      <td>arxiv.org/abs/1501.00287</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>Consistent Classification Algorithms for Multi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consistent Classification Algorithms for Mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-11070586</td>\n",
       "      <td>arxiv.org/abs/1107.0586</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>Managing key multicasting through orthogonal s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Managing key multicasting through orthogonal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                           Abstract\n",
       "0  no-150100335  ...   A Data Transparency Framework for Mobile Appl...\n",
       "1   no-14024178  ...   A reclaimer scheduling problem arising in coa...\n",
       "2  no-150100263  ...   Communication-Efficient Distributed Optimizat...\n",
       "3  no-150100287  ...   Consistent Classification Algorithms for Mult...\n",
       "4   no-11070586  ...   Managing key multicasting through orthogonal ...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the sample of rows in the test dataframe\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "luPgR1R7fzqN",
    "outputId": "43da61ad-6fe0-41e4-be7e-2b32486b4762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimesions of the training dataframe:  (54731, 8)\n",
      "The dimesions of the test dataframe:  (19679, 8)\n"
     ]
    }
   ],
   "source": [
    "#Display the shape of the dataframe for knowing the dimensions of it\n",
    "print(\"The dimesions of the training dataframe: \",df_train.shape)\n",
    "print(\"The dimesions of the test dataframe: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "r0q-cBZee5aP",
    "outputId": "b4e0aeba-7840-43fb-e140-155f15a692df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID            0\n",
       "URL           0\n",
       "Date          0\n",
       "Title         0\n",
       "InfoTheory    0\n",
       "CompVis       0\n",
       "Math          0\n",
       "Abstract      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the NULL values in the training dataframe\n",
    "df_train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "FIz2V_Joe5aS",
    "outputId": "ad06a9a3-eee1-4d7e-b545-913d25123f7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID            0\n",
       "URL           0\n",
       "Date          0\n",
       "Title         0\n",
       "InfoTheory    1\n",
       "CompVis       1\n",
       "Math          1\n",
       "Abstract      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for Null values in the test dataframe\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSB7s9IEkUp7"
   },
   "source": [
    "**Findings :**\n",
    "\n",
    "The train dataframe doesnot have any null values whereas the test dataframe have one line of Null values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXBhXH7Yxcsm"
   },
   "source": [
    "### Part 1: Neural Network Method\n",
    "\n",
    "In this Method the three text classifiers for InfoThoery,CompVis,Math classes are implemented by building a simple Recurrent Neural Networks using TorchText and Pytorch. Then confusion matrix for each of text classifier models is being analysed.\n",
    "\n",
    "#### Importing the packages \n",
    "\n",
    "Packages used for building the models are torch,torchtext,spacy(for tokenization),string(pre-processing),nltk(text-processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "HawKyXF3uOVg",
    "outputId": "e9237885-52bb-4e33-e2b7-7eb1d991a26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#install the packages which are being used for developing RNN models\n",
    "#!pip3 install torch\n",
    "#!pip3 install torchtext\n",
    "#!pip install spacy\n",
    "\n",
    "\n",
    "#importing the packages which are supposed to be used in the development of the models\n",
    "import torch #open source machine learning library used for developing and training neural network based deep learning models\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "import spacy # open source for natural language processing\n",
    "import string\n",
    "import nltk\n",
    "import torch.optim as optim\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from torchtext.data import TabularDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JA7vQx3atHMW"
   },
   "source": [
    "##### Preprocessing the data\n",
    "\n",
    "The data is being pre-processed to build the models by initializing the Output and Input from the dataset using TorchText to set the Text(Abstract-Input) and Label(InfoTheory/CompVis/Math-Output) fields. \n",
    "\n",
    "*\tSince the test dataset has a null value, we cannot proceed to build the text \n",
    "classifiers so the empty lines are being replaced by special characters(Null) for the Abstract field and  (0) for all the other 3 output classes {InfoTheory,CompVis,Math}\n",
    "*\tThe Input data from the Abstract  is being tokenized using the spacy  tokenizer\n",
    "*\tThe stopwords and punctuation are also removed from the tokens \n",
    "*\tThe tokens are all converted to lowercase \n",
    "*\tduplicate tokens are removed and a unique set of tokens is only sent for building the dataset \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-6h-VD_xcsn"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Referred from https://github.com/pytorch/text/issues/430\n",
    "\n",
    "\n",
    "#The seed value will set the random number generator with value of \"200\" using SEED.\n",
    "SEED = 200\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#Text-processing, The blank lines are being replaced by the 'Null' value for the abstract field and '0' for the other input classes.\n",
    "preprocess_text = lambda x:'Null'if (len(x)==0) else x\n",
    "preprocess_label = lambda x:0 if(len(x)==0) else x\n",
    "\n",
    "#Removing the stopwords and punctuation from the tokens\n",
    "final_stopword_list=set(list(string.punctuation)+list(stopwords.words('english')))\n",
    "\n",
    "#Setting the Text and Labal fields for tokenising and processing the input data\n",
    "TEXT = data.Field(sequential=True, tokenize = 'spacy', lower=True, stop_words=final_stopword_list)\n",
    "LABEL = data.LabelField(dtype = torch.float, use_vocab=False)\n",
    "\n",
    "#Updating the preprocessing of the input and output.\n",
    "TEXT.preprocessing = preprocess_text\n",
    "LABEL.preprocessing = preprocess_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x41AURwxGM5L"
   },
   "source": [
    "The input and ouput are being specified and read using the Tabular Dataset, where we won't be needing the ID,URL,Date,Title so we pass in None as the field.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9qbRRiFjIpm"
   },
   "outputs": [],
   "source": [
    "#Referred from https://torchtext.readthedocs.io/en/latest/data.html\n",
    "\n",
    "#The input and ouput is specified by Tabular Dataset by reading from the train and test dataset.\n",
    "\n",
    "##Tabular Dataset for InfoTheory Class\n",
    "info_datafields = [(\"ID\", None),\n",
    "                 (\"URL\", None),\n",
    "                 (\"Date\", None),\n",
    "                 (\"Title\", None),\n",
    "                 (\"InfoTheory\", LABEL),\n",
    "                 ('CompVis',None),\n",
    "                 (\"Math\", None),\n",
    "                 (\"Abstract\", TEXT)]\n",
    "\n",
    "#Reading the dataset for InfoTheory Class\n",
    "train_data_Info = TabularDataset(path='/content/drive/My Drive/axcs_train.csv',format='csv',skip_header=True,fields=info_datafields)\n",
    "test_data_Info = TabularDataset(path='/content/drive/My Drive/axcs_test.csv',format='csv',skip_header=True,fields=info_datafields )\n",
    "\n",
    "##Tabular Dataset for CompVis Class\n",
    "comp_datafields = [(\"ID\", None),\n",
    "                 (\"URL\", None),\n",
    "                 (\"Date\", None),\n",
    "                 (\"Title\", None),\n",
    "                 (\"InfoTheory\", None),\n",
    "                 ('CompVis',LABEL),\n",
    "                 (\"Math\", None),\n",
    "                 (\"Abstract\", TEXT)]\n",
    "\n",
    "#Reading the dataset for CompVis Class\n",
    "train_data_Comp = TabularDataset(path='/content/drive/My Drive/axcs_train.csv',format='csv',skip_header=True,fields=comp_datafields)\n",
    "test_data_Comp = TabularDataset(path='/content/drive/My Drive/axcs_test.csv',format='csv',skip_header=True,fields=comp_datafields )\n",
    "\n",
    "##Tabular Dataset for Math Class\n",
    "math_datafields = [(\"ID\", None),\n",
    "                 (\"URL\", None),\n",
    "                 (\"Date\", None),\n",
    "                 (\"Title\", None),\n",
    "                 (\"InfoTheory\", None),\n",
    "                 ('CompVis',None),\n",
    "                 (\"Math\", LABEL),\n",
    "                 (\"Abstract\", TEXT)]\n",
    "\n",
    "#Reading the dataset for Math Class\n",
    "train_data_math = TabularDataset(path='/content/drive/My Drive/axcs_train.csv',format='csv',skip_header=True,fields=math_datafields)\n",
    "test_data_math = TabularDataset(path='/content/drive/My Drive/axcs_test.csv',format='csv',skip_header=True,fields=math_datafields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "H0G44j1HjIvm",
    "outputId": "b8d5e2fa-13e2-4f60-890e-613b0d027503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Info_Theory training lines: 54731\n",
      "Number of  Comp_Vis training lines: 54731\n",
      "Number of Math training lines: 54731\n",
      "Number of testing lines: 19679\n"
     ]
    }
   ],
   "source": [
    "#Display the number of rows in the tabular dataset\n",
    "print(f'Number of Info_Theory training lines: {len(train_data_Info)}')\n",
    "print(f'Number of  Comp_Vis training lines: {len(train_data_Comp)}')\n",
    "print(f'Number of Math training lines: {len(train_data_math)}')\n",
    "print(f'Number of testing lines: {len(test_data_Info)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Dj6TUEM-0IL1",
    "outputId": "6b9e5e9d-69d6-4c49-fe0f-b4470802c380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text length of the vocabularis :  91885\n"
     ]
    }
   ],
   "source": [
    "#Building the vocabulary to find the total number of vocabularies\n",
    "TEXT.build_vocab(train_data_Info,)\n",
    "print(\"The text length of the vocabularis : \",len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "muXtiWKRHRgD"
   },
   "source": [
    "##### Model Building\n",
    "\n",
    "Based on comparing with vocab size and Batch size the below values have given more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WKYSvcTjI44"
   },
   "outputs": [],
   "source": [
    "# The vocabulary size is set\n",
    "MAX_VOCABULARY_SIZE=5000\n",
    "\n",
    "#Building the vocabulary for the input and output datafields\n",
    "TEXT.build_vocab(train_data_Info, max_size = MAX_VOCABULARY_SIZE)\n",
    "LABEL.build_vocab(train_data_Info, max_size = MAX_VOCABULARY_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbjWoZD7J7U2"
   },
   "outputs": [],
   "source": [
    "#Buiding a RNN model \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "      \n",
    "        embedded = self.embedding(text) \n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcuOvu-mL6dS"
   },
   "outputs": [],
   "source": [
    "#Initialising the dimensions required for the RNN model\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mq-q7rVgH1q8"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # Batch size is initialised\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Learning rate and optimiser is being set up\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "#Calculating the loss using the criterion function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTazad-vL3TG"
   },
   "outputs": [],
   "source": [
    "#Funtion to find the accuracy of the batch of input being processed\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AXBdl0RoJuD5",
    "outputId": "f78b3c8f-2534-4c8e-cfda-dbfac3ee1c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 5002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2EWLzmlzqg0U"
   },
   "source": [
    "##### Info Theory Model\n",
    "\n",
    "- Steps involved in building the model:\n",
    "\n",
    "The iterator is defined-> the training model is being defined -> The loss and accuracy is being returned from the model along with the predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQnuBW7gjIl6"
   },
   "outputs": [],
   "source": [
    "#iterator is used to split the data batch wise\n",
    "train_iterator_Info, test_iterator_Info = data.BucketIterator.splits(\n",
    "    (train_data_Info, test_data_Info), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJDirvaXtrQ6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model Building\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    #caling the RNN model \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #Calculate the predictions,loss and accuracy and prediction of every model\n",
    "        predictions = model(batch.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch.InfoTheory)\n",
    "        acc = binary_accuracy(predictions, batch.InfoTheory)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #store the loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    #return the loss and accuracy of the model  \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oU2iXIrH8N-z"
   },
   "outputs": [],
   "source": [
    "#Calling the train function\n",
    "train_loss, train_acc= train(model, train_iterator_Info, optimizer, criterion)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8Fr07IDr5on"
   },
   "outputs": [],
   "source": [
    "#Create a empty list\n",
    "y_predict_InfoTheory = []\n",
    "y_test_InfoTheory = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    #for every iterator value, populate the predicted values \n",
    "    for batch in test_iterator_Info:\n",
    "        predictions = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        y_predict_InfoTheory += rounded_preds.tolist()\n",
    "        y_test_InfoTheory += batch.InfoTheory.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDnkqRydqzrI"
   },
   "source": [
    "##### Comp Vis Model\n",
    "\n",
    "\n",
    "- Steps involved in building the model:\n",
    "\n",
    "The iterator is defined-> the training model is being defined -> The loss and accuracy is being returned from the model along with the predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbmH7oJMqp1q"
   },
   "outputs": [],
   "source": [
    "#iterator is used to split the data batch wise\n",
    "train_iterator_Comp, test_iterator_Comp = data.BucketIterator.splits(\n",
    "    (train_data_Comp, test_data_Comp), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-a52yrddkjRB"
   },
   "outputs": [],
   "source": [
    "#Defining the function for the CompVis class\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    #calling th RNN modle\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #Calculate the predictions,loss and accuracy and prediction of every model\n",
    "        predictions = model(batch.Abstract).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.CompVis)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.CompVis)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #store the loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    #return the loss and accuracy   \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGxXH4r98ekS"
   },
   "outputs": [],
   "source": [
    "#Calling the train function\n",
    "train_loss, train_acc = train(model, train_iterator_Comp, optimizer, criterion)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwx8JNdQr_u4"
   },
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "y_predict_CompVis = []\n",
    "y_test_CompVis = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    #for eveery iterator value ,populate the predicted values\n",
    "    for batch in test_iterator_Comp:\n",
    "        predictions = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        y_predict_CompVis += rounded_preds.tolist()\n",
    "        y_test_CompVis += batch.CompVis.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTfwPWlf5s25"
   },
   "source": [
    "##### Math Model\n",
    "\n",
    "\n",
    "- Steps involved in building the model:\n",
    "\n",
    "The iterator is defined-> the training model is being defined -> The loss and accuracy is being returned from the model along with the predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_3sBG0ekY04"
   },
   "outputs": [],
   "source": [
    "#iterator is used to split the data batch wise\n",
    "train_iterator_Math, test_iterator_Math = data.BucketIterator.splits(\n",
    "    (train_data_math, test_data_math), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCJMn6kVk1Xw"
   },
   "outputs": [],
   "source": [
    "#definin the model\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #calculate the predictions,loss and acuuracy      \n",
    "        predictions = model(batch.Abstract).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Math)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.Math)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #store the loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    #return the loss and accuracy    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFVrAH8n8iQ6"
   },
   "outputs": [],
   "source": [
    "#Calling the train function\n",
    "train_loss, train_acc = train(model, train_iterator_Math, optimizer, criterion)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSwe581DraOD"
   },
   "outputs": [],
   "source": [
    "#Creating the empty list\n",
    "y_predict_Math = []\n",
    "y_test_Math = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    #for every test iterator values,populate the predicted values\n",
    "    for batch in test_iterator_Math:\n",
    "        predictions = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        y_predict_Math += rounded_preds.tolist()\n",
    "        y_test_Math += batch.Math.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qm1zAJ7U5s3e"
   },
   "source": [
    "##### Confusion Matrix of the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "uyyMj-hBOEwc",
    "outputId": "7658574e-ed7f-46c0-adfd-a1fa09b960cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full confusion matrix for method on InfoTheory:\n",
      "[[13133  2930]\n",
      " [ 2891   725]]\n",
      "Full confusion matrix for method on CompVis:\n",
      "[[15689  1838]\n",
      " [ 1921   231]]\n",
      "Full confusion matrix for method on Math:\n",
      "[[12411  1338]\n",
      " [ 5296   634]]\n"
     ]
    }
   ],
   "source": [
    "#Display the confusion matrix for all the 3 classes\n",
    "y_predict_Info = np.asarray(y_predict_InfoTheory)\n",
    "y_test_InfoTheory = np.asarray(y_test_InfoTheory)\n",
    "y_predict_Comp = np.asarray(y_predict_CompVis)\n",
    "y_test_CompVis = np.asarray(y_test_CompVis)\n",
    "y_predict_Math = np.asarray(y_predict_Math)\n",
    "y_test_Math = np.asarray(y_test_Math)\n",
    "\n",
    "\n",
    "print(f'Full confusion matrix for method on InfoTheory:\\n{confusion_matrix(y_test_InfoTheory,y_predict_Info)}')\n",
    "print(f'Full confusion matrix for method on CompVis:\\n{confusion_matrix(y_test_CompVis,y_predict_Comp)}')\n",
    "print(f'Full confusion matrix for method on Math:\\n{confusion_matrix(y_test_Math,y_predict_Math)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODdhXHylxcsw"
   },
   "source": [
    "### Part 2: Machine Learning Method\n",
    "\n",
    "Using the traditional machine learning algorithms like Logistic Regression,Linear SVC,Random Forest,Bernoulli’s Naïve Bayes we have developed three best accurate text classifiers for Infotheory,Compvis and Math classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "ssSXwUhfe5ah",
    "outputId": "49830551-86c8-45c1-ac92-161e70030521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the pacakages and libraries necessary to build the 3 text classifiers\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize    \n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing\n",
    "\n",
    "While preprocessing the data we have to follow the first step where the empty elements have been identified and it is dropped from the test dataset using a function from Pandas library function called dropna(). The second step involves the data being converted to a list for processing where one list for Input text column is denoting to the Abstract Column and three other lists for each label for the output classes which are InfoTheory,CompVis,Math columns from the datasets.The length of the training dataset lists is 54731.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "kq5wn_3Te5al",
    "outputId": "5d6219bc-2119-4828-ffcd-dd4de11c33ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 54,731\n",
      "\n",
      "Number of testing sentences: 19,679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df_train = pd.read_csv(\"/content/drive/My Drive/axcs_train.csv\", delimiter=',')\n",
    "df_test = pd.read_csv(\"/content/drive/My Drive/axcs_test.csv\", delimiter=',')\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
    "print('Number of testing sentences: {:,}\\n'.format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "sQAQZ1dCe5aq",
    "outputId": "f8b16986-1161-45f6-d902-6c5348ef2faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 54,731\n",
      "\n",
      "Number of testing sentences: 19,678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test=df_test.dropna()\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
    "print('Number of testing sentences: {:,}\\n'.format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "pracVsFQe5aw",
    "outputId": "b1cdc9b5-62a5-46fb-bd62-8f42be4d7e61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-150100335</td>\n",
       "      <td>arxiv.org/abs/1501.00335</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appli...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-14024178</td>\n",
       "      <td>arxiv.org/abs/1402.4178</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>A reclaimer scheduling problem arising in coal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A reclaimer scheduling problem arising in coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-150100263</td>\n",
       "      <td>arxiv.org/abs/1501.00263</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>Communication-Efficient Distributed Optimizati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Communication-Efficient Distributed Optimizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-150100287</td>\n",
       "      <td>arxiv.org/abs/1501.00287</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>Consistent Classification Algorithms for Multi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consistent Classification Algorithms for Mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-11070586</td>\n",
       "      <td>arxiv.org/abs/1107.0586</td>\n",
       "      <td>1/01/2015</td>\n",
       "      <td>Managing key multicasting through orthogonal s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Managing key multicasting through orthogonal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                           Abstract\n",
       "0  no-150100335  ...   A Data Transparency Framework for Mobile Appl...\n",
       "1   no-14024178  ...   A reclaimer scheduling problem arising in coa...\n",
       "2  no-150100263  ...   Communication-Efficient Distributed Optimizat...\n",
       "3  no-150100287  ...   Consistent Classification Algorithms for Mult...\n",
       "4   no-11070586  ...   Managing key multicasting through orthogonal ...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "GVT_Bj2Le5az",
    "outputId": "4614fb50-bf7f-44c3-ed99-a48eed506ebf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>InfoTheory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39754</th>\n",
       "      <td>Throughput Maximization in the Speed-Scaling ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14222</th>\n",
       "      <td>On the periods of generalized Fibonacci recur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24905</th>\n",
       "      <td>Ordered community structure in networks Commu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51740</th>\n",
       "      <td>Network Utility Aware Traffic Loading Balanci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15350</th>\n",
       "      <td>Bilateral filters: what they can and cannot d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Abstract  InfoTheory\n",
       "39754   Throughput Maximization in the Speed-Scaling ...           0\n",
       "14222   On the periods of generalized Fibonacci recur...           0\n",
       "24905   Ordered community structure in networks Commu...           0\n",
       "51740   Network Utility Aware Traffic Loading Balanci...           0\n",
       "15350   Bilateral filters: what they can and cannot d...           0"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#snippet of the train dataset with infoTheory value to be '0'\n",
    "df_train.loc[df_train.InfoTheory == 0].sample(5)[['Abstract', 'InfoTheory']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkmJC75ze5a9"
   },
   "outputs": [],
   "source": [
    "#Converting the dataframe columns into a list fo rprocessing\n",
    "trainInfo = df_train['InfoTheory'].tolist() \n",
    "trainComp= df_train['CompVis'].tolist() \n",
    "trainMath = df_train['Math'].tolist() \n",
    "trainAbstract = df_train['Abstract'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2byHZAyWe5bA",
    "outputId": "ea2169e0-3bcf-45e6-f29a-4017b1a63130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54731\n",
      "54731\n"
     ]
    }
   ],
   "source": [
    "print(len(trainInfo))\n",
    "print(len(trainAbstract))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization & Lemmatization\n",
    "The TF_IDF vectorizer  is used to convert the input text into vectors. This vectorizer is then used to transform the input text of the training and testing data into vectors with parameters set with minimum df, maximum df, token pattern and remove the stopwords and also the punctuations is filtered.\n",
    "The tokenizer which is used here is Regex tokenizer that filters only the words and whitespaces. The train data is being fit with this transformation and they are converted to features. The total length of the preprocessed vectorizer features is 20335 which is then used to build the models to find the best classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAP4fQVse5bF"
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl=WordNetLemmatizer()\n",
    "    def __call__(self,doc):\n",
    "        #using regex tokenizer,extracting the words with whitespaces alone\n",
    "        output = ''.join(re.findall('[a-zA-Z\\s]+',doc))\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyKaNzsme5bM"
   },
   "outputs": [],
   "source": [
    "#for the preprocessing, the english stopwords and punctuations are being concatenated into a list\n",
    "final_stopwords_list=stopwords.words('english')+list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oCvnbKu8e5bR",
    "outputId": "32ee5f34-4b61-4b9b-ceaf-b54e308a3de0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of stopwords and punctuations \n",
    "len(final_stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzivnJvOe5bc"
   },
   "outputs": [],
   "source": [
    "#A TF_IDF vectorizer is defined with minimum df to be 5 and maximum document frequency t o 80%\n",
    "\n",
    "vectorizer=TfidfVectorizer(analyzer='word',input='content',\n",
    "                           lowercase=True,\n",
    "                           token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                           min_df=5,\n",
    "                           max_df=0.8,\n",
    "                           stop_words=final_stopwords_list,\n",
    "                           tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uHV9d5oe5bh"
   },
   "outputs": [],
   "source": [
    "#Transforming the input into tokenized form\n",
    "x_train=vectorizer.fit_transform(trainAbstract)\n",
    "y1_train=np.asarray(trainInfo)\n",
    "y2_train=np.asarray(trainComp)\n",
    "y3_train=np.asarray(trainMath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qQp-48J9e5bl",
    "outputId": "a5a822ef-1af6-462e-a7e4-21fa7ee9598d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20335"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of features to be used in building a model\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Four different traditional models are built and tested using Cross-validation for 5 folds to identify the best fit model for the classification task. Methods selected are Logistic Regression, Bernoulli’s Naïve Bayes, Linear SVC and Random Forest. These models are built for all of the three classes and one of the model which has higher accuracy is selected as the best Classifier model. A boxplot with jitter points is plotted across the accuracy and the most accurate model will be chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### InfoTheory Class\n",
    "\n",
    "Cross validation is performed with 5 fold and a box plot is plotted to find the most accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiYbh86le5br"
   },
   "outputs": [],
   "source": [
    "#InfoTheory\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    BernoulliNB(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "\n",
    "#setting the fold value for cross validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "#finding the accuracies of each model\n",
    "for model in models:\n",
    "     model_name = model.__class__.__name__\n",
    "     accuracies = cross_val_score(model, x_train, y1_train, scoring='accuracy', cv=CV)\n",
    "     for fold_idx, accuracy in enumerate(accuracies):\n",
    "          entries.append((model_name, fold_idx, accuracy))\n",
    "        \n",
    "#a dataframe is populated with the accuracies\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "#cv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "GztinDmbe5bu",
    "outputId": "61123678-1a7b-4ca6-bacb-e97e14126b76"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Box plot is plotted for all the 4 models\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "\n",
    "#jitters are plotted\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "#Disply the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CompVis Class\n",
    "\n",
    "Cross validation is performed with 5 fold and a box plot is plotted to find the most accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01O9SsDBe5bx"
   },
   "outputs": [],
   "source": [
    "#CompVis\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    BernoulliNB(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "#setting the fold value for the cross validation\n",
    "CV = 5\n",
    "cv_df1 = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "#finding the accuracies for each model \n",
    "for model in models:\n",
    "     model_name = model.__class__.__name__\n",
    "     accuracies = cross_val_score(model, x_train, y2_train, scoring='accuracy', cv=CV)\n",
    "     for fold_idx, accuracy in enumerate(accuracies):\n",
    "          entries.append((model_name, fold_idx, accuracy))\n",
    "        \n",
    "# Accuracies for each model is populated in a dataframe\n",
    "cv_df1 = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "#cv_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "p30CP-WJe5b0",
    "outputId": "96bd6669-5e42-43e0-c781-515e1953fb07"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Boxplot is plotted for the accuracies\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df1)\n",
    "#Jitters are added to the boxplot\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df1, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "\n",
    "#display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Math Class\n",
    "\n",
    "Cross validation is performed with 5 fold and a box plot is plotted to find the most accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaaObYOGe5b3"
   },
   "outputs": [],
   "source": [
    "#Math\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    BernoulliNB(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "#setting the fold value for the cross validation\n",
    "CV = 5\n",
    "cv_df2 = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "#Calculate the accuracies \n",
    "for model in models:\n",
    "     model_name = model.__class__.__name__\n",
    "     accuracies = cross_val_score(model, x_train, y3_train, scoring='accuracy', cv=CV)\n",
    "     for fold_idx, accuracy in enumerate(accuracies):\n",
    "          entries.append((model_name, fold_idx, accuracy))\n",
    "#populate the dataframe with the accuracies for the model\n",
    "cv_df2 = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "#cv_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "kgXMpEEWe5b7",
    "outputId": "e060db32-7eb6-4fce-dd80-a602ca5517e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Box plot is plotted for the accuracies of the model\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df2)\n",
    "\n",
    "#Jitters are being fitted to the boxplot\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df2, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "#Disply the graph \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building:\n",
    "Based on the all the other techniques we could infer that the Linear SVC is the most accurate model with less distortion, therefore it is used to build the text classifiers for all the three classes.\n",
    "\n",
    "- Converting the test dataframes into a list and transforming the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQ7wVKvOe5b-"
   },
   "outputs": [],
   "source": [
    "#converting the dataframe columns to list\n",
    "testInfo = df_test.InfoTheory.tolist() \n",
    "testComp = df_test.CompVis.tolist()\n",
    "testMath = df_test.Math.tolist() \n",
    "testAbstract = df_test.Abstract.tolist()\n",
    "# Using the same vectorizer to transform the test set\n",
    "x_test=vectorizer.transform(testAbstract)\n",
    "y1_test=np.asarray(testInfo)\n",
    "y2_test=np.asarray(testComp)\n",
    "y3_test=np.asarray(testMath)\n",
    "\n",
    "#Setting the model as Linear SVC\n",
    "clf=LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math class model:\n",
    "\n",
    "Model is built for the math class and the predicted value is being stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGqlJKEre5cB"
   },
   "outputs": [],
   "source": [
    "#Building the model and fiting train with test values\n",
    "    model_name = clf.__class__.__name__\n",
    "    clf.fit(x_train, y3_train)\n",
    "    # Do the prediction\n",
    "    y3_predict=clf.predict(x_test)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info Theory class model:\n",
    "\n",
    "Model is built for the infotheory class and the predicted value is being stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEMHR2Mhe5cE"
   },
   "outputs": [],
   "source": [
    "#building the model and fiting train with test values\n",
    "model_name = clf.__class__.__name__\n",
    "clf.fit(x_train, y1_train)\n",
    "    # Do the prediction\n",
    "y1_predict=clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CompVis class model:\n",
    "\n",
    "Model is built for the compvis class and the predicted value is being stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and fitting the train and test  values\n",
    "model_name = clf.__class__.__name__\n",
    "clf.fit(x_train, y2_train)\n",
    "    # Do the prediction\n",
    "y2_predict=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "The final confusion matrix is being calculated and displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "_xVg03I4e5cI",
    "outputId": "6a208305-92ae-431d-addb-06c29ab3dc75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for InfoTheory :\n",
      " [[15777   285]\n",
      " [  665  2951]]\n",
      "Confusion Matrix for CompVis :\n",
      " [[17426   100]\n",
      " [  503  1649]]\n",
      "Confusion Matrix for Math :\n",
      " [[12731  1017]\n",
      " [ 1482  4448]]\n"
     ]
    }
   ],
   "source": [
    "#display the confusion matrix for \n",
    "print(\"Confusion Matrix for InfoTheory :\\n\",confusion_matrix(y1_test,y1_predict))\n",
    "print(\"Confusion Matrix for CompVis :\\n\",confusion_matrix(y2_test,y2_predict))\n",
    "print(\"Confusion Matrix for Math :\\n\",confusion_matrix(y3_test,y3_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZCKBACaxcs2"
   },
   "source": [
    "## Part 2: Topic Modelling\n",
    "\n",
    "Based on the content being gathered from news sites, containing the term \"Monash University\", or at tagged with the label \"Monash University\" by an external annotator. Topic models are to be built on the content to analyse the range of topics present in the articles regarding Monash University.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "F3iBbdlGiOHd",
    "outputId": "b04c74ab-2f19-4f8b-edd2-dcbde5b9421f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Keerthana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Keerthana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#installing the required packages\n",
    "#!pip3 install pyLDAvis\n",
    "\n",
    "#Importing the required packages and libraries\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import LdaModel\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrJJ0g3kxcs3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2wagsXPeTfm"
   },
   "outputs": [],
   "source": [
    "#Read the data \n",
    "df = pd.read_csv('Monash_crawled.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "0Ra-SHveebPf",
    "outputId": "de91f40e-f4c9-45a1-ab93-bb10ae143e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uri      0\n",
       "url      0\n",
       "date     0\n",
       "title    0\n",
       "body     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for any null or empty lines in the dataframe\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "EMbKUUz3PBGb",
    "outputId": "2d66f1f7-61a1-4bd6-999b-5970fdb2df81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "366\n"
     ]
    }
   ],
   "source": [
    "#converting the body and title column from the dataframe into a list\n",
    "docs = df['body'].tolist()\n",
    "title = df['title'].tolist()\n",
    "#display the length and title of the documents\n",
    "print(len(docs))\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "7w44QTOs4Vjh",
    "outputId": "1da21615-62eb-472f-a392-fdb3dd4657bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n"
     ]
    }
   ],
   "source": [
    "#concatenating the stopwords and punctuation in a list to preprocess \n",
    "final_stopwords=list(string.punctuation)+list(stopwords.words('english'))\n",
    "print(len(final_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing of Data\n",
    "The data was checked for null values and then processed with the regular text processing techniques. In this step, the pre-processing techniques like as tokenisation, lemmatisation, stop words, punctuations,bigrams and trigrams are removed. \n",
    "\n",
    "The text is converted to corpus -> bag of words using the Dictionary and then the corpus is used to build the LDA model.The final result of unique tokens and number of documents is taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBm_zaEafEul"
   },
   "outputs": [],
   "source": [
    "def processing(docs):\n",
    "# Preprocessing  the documents.  \n",
    "#Split the documents into tokens.\n",
    "  tokenizer = RegexpTokenizer(r'\\w+')\n",
    "  #Tokenising\n",
    "  for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()\n",
    "      # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Tokenize into words.\n",
    "  # Remove numbers, but not words that contain numbers.\n",
    "  docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "  #Removing all the stopwords and punctuations\n",
    "  docs = [[token for token in doc if token not in final_stopwords] for doc in docs]\n",
    "\n",
    "  # Remove words that are only one character.\n",
    "  docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "  #Lemmatize the tokens\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  #\n",
    "  docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "  #Adding bigrams\n",
    "  bigram = Phrases(docs, min_count=20)\n",
    " \n",
    "  for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "  #Create a dictionary representation of the documents.\n",
    "  dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 85% of the documents.\n",
    "  dictionary.filter_extremes(no_below=20, no_above=0.85)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "  corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "#return the documents,corpus and dictionary\n",
    "  return(docs, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "a19-SSuhPBKm",
    "outputId": "f20d197d-e1d0-4f47-997b-d6103a7a8d70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:53:44,468 : INFO : collecting all words and their counts\n",
      "2020-05-08 14:53:44,470 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2020-05-08 14:53:45,049 : INFO : collected 124892 word types from a corpus of 192463 words (unigram + bigrams) and 366 sentences\n",
      "2020-05-08 14:53:45,049 : INFO : using 124892 counts as vocab in Phrases<0 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "2020-05-08 14:53:46,378 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-05-08 14:53:46,939 : INFO : built Dictionary(15396 unique tokens: ['1am', '42c', 'aavoid', 'able', 'according']...) from 366 documents (total 203755 corpus positions)\n",
      "2020-05-08 14:53:46,997 : INFO : discarding 14077 tokens: [('1am', 4), ('42c', 1), ('aavoid', 1), ('acertainly', 1), ('actas', 1), ('acting', 16), ('advise', 7), ('aextremely', 1), ('air_pollution', 8), ('aitas', 12)]...\n",
      "2020-05-08 14:53:47,002 : INFO : keeping 1319 tokens which were in no less than 20 and no more than 311 (=85.0%) documents\n",
      "2020-05-08 14:53:47,013 : INFO : resulting dictionary: Dictionary(1319 unique tokens: ['able', 'according', 'act', 'activity', 'advice']...)\n"
     ]
    }
   ],
   "source": [
    "#Assigning the processed tokens, corpus and dictionaries.\n",
    "process_body=processing(docs)\n",
    "process_docs=process_body[0]\n",
    "process_corpus=process_body[1]\n",
    "process_dic=process_body[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "x1mOjtnAPBWK",
    "outputId": "48505823-6cdf-4dac-d96e-e820467933b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 1319\n",
      "Number of documents: 366\n"
     ]
    }
   ],
   "source": [
    "#display the number of unique tokens and the documents\n",
    "print('Number of unique tokens: %d' % len(process_dic))\n",
    "print('Number of documents: %d' % len(process_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model \n",
    "The Latent Dirichlet Allocation model is developed by using the gensim library. The parameters needed for the model are setup such as Number of Topics from the corpus,chunk_size,iterations count and its passes.\n",
    "Once the model is built, using the perplexity and coherence is used to determine the num_topics to be used. The model is iterated for topic numbers from 2 to 15 and coherence is calculated for each of the model.Two LDA models are created based on the top 2 coherence score denoting NUM_TOPIC values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sgLdnVUPBOm"
   },
   "outputs": [],
   "source": [
    "# Training the LDA model.\n",
    "\n",
    "def model1(topic,dictionary,corpus):\n",
    "# Setting the training parameters.\n",
    "  NUM_TOPICS = topic\n",
    "  chunksize = 2000\n",
    "  passes = 20\n",
    "  iterations = 400\n",
    "  eval_every = None  \n",
    "\n",
    "# Making an index to dictionary of wrds.\n",
    "  temp = dictionary[0] \n",
    "#\n",
    "  id2word = dictionary.id2token\n",
    "#model is being built \n",
    "  model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    "  )\n",
    "#returning the model\n",
    "  return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### To find the coherence of different number of topics\n",
    " The parameters used are dictionary : Gensim dictionary,corpus : Gensim corpus,texts : List of input texts,limit : Max num of topics\n",
    " which in turn  returns a List of LDA topic models and its Coherence values corresponding to the LDA model with respective number of topics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fHNKbN6GdYF"
   },
   "outputs": [],
   "source": [
    "#referred from https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "\n",
    "    coherence_values = []\n",
    "    #A LDA model is called and coherence is calculated\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    " \n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    #the coherence values are being returned\n",
    "    return coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dZfPEAzcHO5C",
    "outputId": "a7c63346-78dd-4e9f-ddbf-2edd1b924191"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 10:34:08,855 : INFO : using symmetric alpha at 0.5\n",
      "2020-05-08 10:34:08,858 : INFO : using symmetric eta at 0.5\n",
      "2020-05-08 10:34:08,860 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:34:08,862 : INFO : running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:34:08,863 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:34:09,574 : INFO : -7.570 per-word bound, 190.0 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:34:09,575 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:34:10,001 : INFO : topic #0 (0.500): 0.016*\"australia\" + 0.013*\"january\" + 0.012*\"february\" + 0.012*\"coronavirus\" + 0.011*\"people\" + 0.009*\"australian\" + 0.008*\"virus\" + 0.007*\"china\" + 0.007*\"university\" + 0.006*\"case\"\n",
      "2020-05-08 10:34:10,002 : INFO : topic #1 (0.500): 0.012*\"people\" + 0.011*\"coronavirus\" + 0.011*\"february\" + 0.010*\"australia\" + 0.009*\"virus\" + 0.009*\"health\" + 0.009*\"case\" + 0.008*\"china\" + 0.008*\"january\" + 0.007*\"australian\"\n",
      "2020-05-08 10:34:10,003 : INFO : topic diff=0.653365, rho=1.000000\n",
      "2020-05-08 10:34:10,004 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:34:20,449 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:34:20,468 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:34:20,481 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:34:20,491 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:34:20,508 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:34:20,516 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:34:21,639 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:34:21,651 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:34:21,737 : INFO : using symmetric alpha at 0.3333333333333333\n",
      "2020-05-08 10:34:21,738 : INFO : using symmetric eta at 0.3333333333333333\n",
      "2020-05-08 10:34:21,738 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:34:21,740 : INFO : running online (single-pass) LDA training, 3 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:34:21,741 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:34:22,583 : INFO : -7.634 per-word bound, 198.6 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:34:22,584 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:34:23,060 : INFO : topic #0 (0.333): 0.014*\"january\" + 0.014*\"february\" + 0.013*\"australia\" + 0.012*\"coronavirus\" + 0.011*\"australian\" + 0.010*\"people\" + 0.007*\"china\" + 0.006*\"one\" + 0.006*\"wuhan\" + 0.006*\"case\"\n",
      "2020-05-08 10:34:23,061 : INFO : topic #1 (0.333): 0.015*\"australia\" + 0.014*\"coronavirus\" + 0.012*\"people\" + 0.011*\"february\" + 0.008*\"virus\" + 0.008*\"january\" + 0.007*\"university\" + 0.007*\"case\" + 0.007*\"australian\" + 0.006*\"south\"\n",
      "2020-05-08 10:34:23,061 : INFO : topic #2 (0.333): 0.013*\"australia\" + 0.012*\"people\" + 0.011*\"virus\" + 0.010*\"china\" + 0.010*\"january\" + 0.010*\"february\" + 0.009*\"coronavirus\" + 0.008*\"health\" + 0.008*\"case\" + 0.006*\"year\"\n",
      "2020-05-08 10:34:23,062 : INFO : topic diff=0.654171, rho=1.000000\n",
      "2020-05-08 10:34:23,064 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:34:33,120 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:34:33,131 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:34:33,141 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:34:33,149 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:34:33,171 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:34:33,182 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:34:34,333 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:34:34,343 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:34:34,455 : INFO : using symmetric alpha at 0.25\n",
      "2020-05-08 10:34:34,455 : INFO : using symmetric eta at 0.25\n",
      "2020-05-08 10:34:34,456 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:34:34,459 : INFO : running online (single-pass) LDA training, 4 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:34:34,460 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:34:35,171 : INFO : -7.679 per-word bound, 204.9 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:34:35,172 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:34:35,618 : INFO : topic #0 (0.250): 0.018*\"australia\" + 0.014*\"coronavirus\" + 0.013*\"january\" + 0.012*\"february\" + 0.008*\"people\" + 0.008*\"china\" + 0.008*\"australian\" + 0.006*\"one\" + 0.006*\"also\" + 0.006*\"two\"\n",
      "2020-05-08 10:34:35,620 : INFO : topic #1 (0.250): 0.012*\"australia\" + 0.012*\"coronavirus\" + 0.010*\"february\" + 0.010*\"january\" + 0.009*\"people\" + 0.009*\"health\" + 0.007*\"virus\" + 0.007*\"university\" + 0.007*\"china\" + 0.006*\"case\"\n",
      "2020-05-08 10:34:35,621 : INFO : topic #2 (0.250): 0.017*\"february\" + 0.013*\"australia\" + 0.012*\"january\" + 0.011*\"people\" + 0.010*\"coronavirus\" + 0.010*\"australian\" + 0.008*\"case\" + 0.008*\"virus\" + 0.007*\"south\" + 0.007*\"university\"\n",
      "2020-05-08 10:34:35,623 : INFO : topic #3 (0.250): 0.014*\"people\" + 0.013*\"australia\" + 0.012*\"coronavirus\" + 0.012*\"virus\" + 0.010*\"january\" + 0.009*\"china\" + 0.009*\"australian\" + 0.008*\"february\" + 0.008*\"case\" + 0.007*\"health\"\n",
      "2020-05-08 10:34:35,625 : INFO : topic diff=0.657947, rho=1.000000\n",
      "2020-05-08 10:34:35,627 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:34:45,008 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:34:45,019 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:34:45,030 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:34:45,041 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:34:45,055 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:34:45,069 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:34:46,173 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:34:46,194 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:34:46,321 : INFO : using symmetric alpha at 0.2\n",
      "2020-05-08 10:34:46,321 : INFO : using symmetric eta at 0.2\n",
      "2020-05-08 10:34:46,322 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:34:46,325 : INFO : running online (single-pass) LDA training, 5 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 10:34:46,326 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:34:47,031 : INFO : -7.713 per-word bound, 209.8 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:34:47,032 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:34:47,401 : INFO : topic #0 (0.200): 0.011*\"people\" + 0.009*\"virus\" + 0.009*\"university\" + 0.008*\"coronavirus\" + 0.008*\"health\" + 0.007*\"january\" + 0.007*\"also\" + 0.006*\"could\" + 0.006*\"australia\" + 0.006*\"china\"\n",
      "2020-05-08 10:34:47,401 : INFO : topic #1 (0.200): 0.015*\"february\" + 0.013*\"people\" + 0.012*\"australia\" + 0.010*\"china\" + 0.009*\"australian\" + 0.009*\"january\" + 0.008*\"case\" + 0.007*\"virus\" + 0.007*\"coronavirus\" + 0.006*\"health\"\n",
      "2020-05-08 10:34:47,401 : INFO : topic #2 (0.200): 0.013*\"australia\" + 0.011*\"people\" + 0.010*\"february\" + 0.009*\"january\" + 0.009*\"coronavirus\" + 0.008*\"australian\" + 0.007*\"virus\" + 0.007*\"year\" + 0.007*\"china\" + 0.006*\"health\"\n",
      "2020-05-08 10:34:47,401 : INFO : topic #3 (0.200): 0.015*\"coronavirus\" + 0.011*\"february\" + 0.010*\"people\" + 0.010*\"china\" + 0.009*\"australian\" + 0.009*\"australia\" + 0.009*\"january\" + 0.009*\"virus\" + 0.008*\"case\" + 0.007*\"university\"\n",
      "2020-05-08 10:34:47,417 : INFO : topic #4 (0.200): 0.019*\"australia\" + 0.015*\"january\" + 0.015*\"coronavirus\" + 0.014*\"february\" + 0.011*\"people\" + 0.009*\"virus\" + 0.008*\"australian\" + 0.007*\"south\" + 0.007*\"case\" + 0.007*\"china\"\n",
      "2020-05-08 10:34:47,418 : INFO : topic diff=0.669413, rho=1.000000\n",
      "2020-05-08 10:34:47,421 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:34:56,736 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:34:56,757 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:34:56,771 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:34:56,780 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:34:56,796 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:34:56,807 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:34:58,041 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:34:58,051 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:34:58,226 : INFO : using symmetric alpha at 0.16666666666666666\n",
      "2020-05-08 10:34:58,227 : INFO : using symmetric eta at 0.16666666666666666\n",
      "2020-05-08 10:34:58,228 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:34:58,230 : INFO : running online (single-pass) LDA training, 6 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:34:58,231 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:34:58,990 : INFO : -7.754 per-word bound, 215.9 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:34:58,992 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:34:59,381 : INFO : topic #2 (0.167): 0.019*\"australia\" + 0.011*\"february\" + 0.011*\"coronavirus\" + 0.011*\"australian\" + 0.009*\"health\" + 0.009*\"january\" + 0.008*\"university\" + 0.007*\"people\" + 0.007*\"china\" + 0.006*\"one\"\n",
      "2020-05-08 10:34:59,381 : INFO : topic #5 (0.167): 0.015*\"people\" + 0.013*\"australia\" + 0.012*\"january\" + 0.011*\"coronavirus\" + 0.011*\"china\" + 0.010*\"february\" + 0.009*\"virus\" + 0.009*\"case\" + 0.007*\"chinese\" + 0.007*\"australian\"\n",
      "2020-05-08 10:34:59,381 : INFO : topic #3 (0.167): 0.013*\"coronavirus\" + 0.011*\"february\" + 0.010*\"australia\" + 0.009*\"january\" + 0.009*\"people\" + 0.007*\"health\" + 0.007*\"virus\" + 0.007*\"also\" + 0.007*\"china\" + 0.007*\"australian\"\n",
      "2020-05-08 10:34:59,389 : INFO : topic #1 (0.167): 0.015*\"january\" + 0.014*\"australia\" + 0.012*\"february\" + 0.010*\"people\" + 0.010*\"virus\" + 0.009*\"coronavirus\" + 0.009*\"student\" + 0.009*\"china\" + 0.008*\"case\" + 0.008*\"university\"\n",
      "2020-05-08 10:34:59,390 : INFO : topic #0 (0.167): 0.016*\"february\" + 0.016*\"coronavirus\" + 0.015*\"australia\" + 0.012*\"january\" + 0.012*\"people\" + 0.009*\"virus\" + 0.009*\"australian\" + 0.008*\"case\" + 0.007*\"china\" + 0.006*\"ship\"\n",
      "2020-05-08 10:34:59,392 : INFO : topic diff=0.677995, rho=1.000000\n",
      "2020-05-08 10:34:59,394 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:35:08,864 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:35:08,887 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:35:08,897 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:35:08,911 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:35:08,931 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:35:08,944 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:35:10,179 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:35:10,206 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:35:10,401 : INFO : using symmetric alpha at 0.14285714285714285\n",
      "2020-05-08 10:35:10,402 : INFO : using symmetric eta at 0.14285714285714285\n",
      "2020-05-08 10:35:10,403 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:35:10,405 : INFO : running online (single-pass) LDA training, 7 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:35:10,405 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:35:11,038 : INFO : -7.781 per-word bound, 219.9 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:35:11,039 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:35:11,445 : INFO : topic #2 (0.143): 0.012*\"australia\" + 0.011*\"february\" + 0.010*\"coronavirus\" + 0.010*\"australian\" + 0.010*\"people\" + 0.010*\"virus\" + 0.009*\"january\" + 0.008*\"china\" + 0.008*\"case\" + 0.006*\"health\"\n",
      "2020-05-08 10:35:11,445 : INFO : topic #0 (0.143): 0.018*\"australia\" + 0.012*\"people\" + 0.010*\"coronavirus\" + 0.008*\"january\" + 0.008*\"virus\" + 0.007*\"australian\" + 0.007*\"february\" + 0.007*\"south\" + 0.007*\"case\" + 0.006*\"health\"\n",
      "2020-05-08 10:35:11,445 : INFO : topic #3 (0.143): 0.016*\"january\" + 0.016*\"february\" + 0.014*\"coronavirus\" + 0.014*\"australia\" + 0.014*\"people\" + 0.008*\"china\" + 0.008*\"virus\" + 0.008*\"university\" + 0.007*\"australian\" + 0.007*\"case\"\n",
      "2020-05-08 10:35:11,458 : INFO : topic #1 (0.143): 0.014*\"people\" + 0.011*\"australia\" + 0.010*\"coronavirus\" + 0.008*\"february\" + 0.008*\"january\" + 0.008*\"case\" + 0.008*\"australian\" + 0.007*\"china\" + 0.007*\"virus\" + 0.006*\"day\"\n",
      "2020-05-08 10:35:11,459 : INFO : topic #4 (0.143): 0.011*\"february\" + 0.011*\"coronavirus\" + 0.010*\"australia\" + 0.009*\"people\" + 0.009*\"one\" + 0.008*\"australian\" + 0.008*\"january\" + 0.008*\"woman\" + 0.008*\"health\" + 0.006*\"year\"\n",
      "2020-05-08 10:35:11,459 : INFO : topic diff=0.680425, rho=1.000000\n",
      "2020-05-08 10:35:11,462 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:35:20,782 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:35:20,801 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:35:20,816 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:35:20,832 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 10:35:20,848 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:35:20,866 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:35:22,149 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:35:22,168 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:35:22,367 : INFO : using symmetric alpha at 0.125\n",
      "2020-05-08 10:35:22,367 : INFO : using symmetric eta at 0.125\n",
      "2020-05-08 10:35:22,367 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:35:22,383 : INFO : running online (single-pass) LDA training, 8 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:35:22,384 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:35:23,090 : INFO : -7.818 per-word bound, 225.6 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:35:23,090 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:35:23,569 : INFO : topic #1 (0.125): 0.019*\"australia\" + 0.011*\"people\" + 0.010*\"january\" + 0.010*\"february\" + 0.009*\"coronavirus\" + 0.008*\"area\" + 0.008*\"australian\" + 0.007*\"virus\" + 0.007*\"health\" + 0.006*\"case\"\n",
      "2020-05-08 10:35:23,571 : INFO : topic #0 (0.125): 0.017*\"coronavirus\" + 0.014*\"australia\" + 0.012*\"february\" + 0.010*\"people\" + 0.010*\"january\" + 0.010*\"university\" + 0.009*\"australian\" + 0.008*\"china\" + 0.008*\"health\" + 0.006*\"virus\"\n",
      "2020-05-08 10:35:23,572 : INFO : topic #7 (0.125): 0.016*\"january\" + 0.013*\"february\" + 0.012*\"australia\" + 0.010*\"coronavirus\" + 0.009*\"china\" + 0.009*\"australian\" + 0.009*\"people\" + 0.008*\"virus\" + 0.008*\"university\" + 0.008*\"year\"\n",
      "2020-05-08 10:35:23,573 : INFO : topic #3 (0.125): 0.017*\"february\" + 0.015*\"coronavirus\" + 0.014*\"australia\" + 0.011*\"january\" + 0.010*\"australian\" + 0.008*\"people\" + 0.007*\"one\" + 0.006*\"ship\" + 0.006*\"health\" + 0.006*\"would\"\n",
      "2020-05-08 10:35:23,574 : INFO : topic #4 (0.125): 0.018*\"people\" + 0.013*\"virus\" + 0.012*\"case\" + 0.011*\"china\" + 0.011*\"coronavirus\" + 0.009*\"january\" + 0.009*\"february\" + 0.009*\"wuhan\" + 0.009*\"health\" + 0.007*\"australia\"\n",
      "2020-05-08 10:35:23,576 : INFO : topic diff=0.697516, rho=1.000000\n",
      "2020-05-08 10:35:23,579 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:35:32,747 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:35:32,762 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:35:32,786 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:35:32,798 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:35:32,822 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:35:32,842 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:35:34,257 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:35:34,274 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:35:34,475 : INFO : using symmetric alpha at 0.1111111111111111\n",
      "2020-05-08 10:35:34,475 : INFO : using symmetric eta at 0.1111111111111111\n",
      "2020-05-08 10:35:34,475 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:35:34,488 : INFO : running online (single-pass) LDA training, 9 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:35:34,489 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:35:35,219 : INFO : -7.840 per-word bound, 229.2 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:35:35,220 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:35:35,601 : INFO : topic #2 (0.111): 0.018*\"february\" + 0.016*\"january\" + 0.015*\"australia\" + 0.015*\"coronavirus\" + 0.011*\"australian\" + 0.010*\"people\" + 0.010*\"china\" + 0.007*\"case\" + 0.007*\"one\" + 0.006*\"university\"\n",
      "2020-05-08 10:35:35,601 : INFO : topic #0 (0.111): 0.013*\"australia\" + 0.008*\"people\" + 0.008*\"coronavirus\" + 0.008*\"february\" + 0.007*\"january\" + 0.007*\"virus\" + 0.007*\"one\" + 0.006*\"china\" + 0.006*\"health\" + 0.006*\"also\"\n",
      "2020-05-08 10:35:35,601 : INFO : topic #5 (0.111): 0.016*\"australia\" + 0.013*\"people\" + 0.011*\"january\" + 0.010*\"coronavirus\" + 0.010*\"virus\" + 0.009*\"australian\" + 0.009*\"february\" + 0.006*\"university\" + 0.006*\"would\" + 0.006*\"year\"\n",
      "2020-05-08 10:35:35,601 : INFO : topic #8 (0.111): 0.014*\"february\" + 0.013*\"australia\" + 0.011*\"january\" + 0.010*\"coronavirus\" + 0.009*\"china\" + 0.008*\"area\" + 0.008*\"people\" + 0.007*\"patient\" + 0.006*\"week\" + 0.006*\"australian\"\n",
      "2020-05-08 10:35:35,607 : INFO : topic #7 (0.111): 0.021*\"february\" + 0.015*\"people\" + 0.015*\"coronavirus\" + 0.013*\"australia\" + 0.012*\"january\" + 0.010*\"australian\" + 0.009*\"virus\" + 0.009*\"health\" + 0.009*\"china\" + 0.006*\"case\"\n",
      "2020-05-08 10:35:35,608 : INFO : topic diff=0.706702, rho=1.000000\n",
      "2020-05-08 10:35:35,613 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:35:45,256 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:35:45,269 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:35:45,284 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:35:45,302 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:35:45,327 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:35:45,339 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:35:46,763 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:35:46,780 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:35:47,033 : INFO : using symmetric alpha at 0.1\n",
      "2020-05-08 10:35:47,034 : INFO : using symmetric eta at 0.1\n",
      "2020-05-08 10:35:47,035 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:35:47,037 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:35:47,038 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:35:47,704 : INFO : -7.873 per-word bound, 234.4 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:35:47,704 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:35:48,126 : INFO : topic #8 (0.100): 0.024*\"february\" + 0.015*\"january\" + 0.014*\"australia\" + 0.012*\"coronavirus\" + 0.011*\"australian\" + 0.008*\"people\" + 0.007*\"virus\" + 0.007*\"health\" + 0.007*\"case\" + 0.006*\"woman\"\n",
      "2020-05-08 10:35:48,127 : INFO : topic #0 (0.100): 0.016*\"australia\" + 0.010*\"coronavirus\" + 0.010*\"australian\" + 0.008*\"people\" + 0.007*\"january\" + 0.007*\"health\" + 0.007*\"china\" + 0.007*\"area\" + 0.006*\"virus\" + 0.006*\"south\"\n",
      "2020-05-08 10:35:48,128 : INFO : topic #1 (0.100): 0.015*\"coronavirus\" + 0.013*\"people\" + 0.012*\"january\" + 0.012*\"australia\" + 0.012*\"china\" + 0.010*\"virus\" + 0.010*\"australian\" + 0.009*\"case\" + 0.007*\"two\" + 0.006*\"wuhan\"\n",
      "2020-05-08 10:35:48,130 : INFO : topic #5 (0.100): 0.014*\"january\" + 0.014*\"australia\" + 0.013*\"people\" + 0.012*\"february\" + 0.011*\"coronavirus\" + 0.009*\"australian\" + 0.008*\"virus\" + 0.007*\"case\" + 0.007*\"china\" + 0.006*\"health\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 10:35:48,131 : INFO : topic #2 (0.100): 0.013*\"australia\" + 0.011*\"university\" + 0.010*\"january\" + 0.010*\"australian\" + 0.009*\"coronavirus\" + 0.009*\"february\" + 0.008*\"people\" + 0.006*\"china\" + 0.006*\"two\" + 0.006*\"virus\"\n",
      "2020-05-08 10:35:48,132 : INFO : topic diff=0.721162, rho=1.000000\n",
      "2020-05-08 10:35:48,136 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:35:57,643 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:35:57,664 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:35:57,674 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:35:57,684 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:35:57,707 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:35:57,721 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:35:59,061 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:35:59,073 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:35:59,321 : INFO : using symmetric alpha at 0.09090909090909091\n",
      "2020-05-08 10:35:59,321 : INFO : using symmetric eta at 0.09090909090909091\n",
      "2020-05-08 10:35:59,322 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:35:59,324 : INFO : running online (single-pass) LDA training, 11 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:35:59,325 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:36:00,041 : INFO : -7.901 per-word bound, 239.0 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:36:00,043 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:36:00,482 : INFO : topic #3 (0.091): 0.018*\"february\" + 0.015*\"australia\" + 0.014*\"january\" + 0.012*\"people\" + 0.011*\"health\" + 0.010*\"virus\" + 0.010*\"australian\" + 0.009*\"coronavirus\" + 0.008*\"case\" + 0.005*\"would\"\n",
      "2020-05-08 10:36:00,484 : INFO : topic #10 (0.091): 0.015*\"people\" + 0.014*\"coronavirus\" + 0.013*\"australia\" + 0.012*\"february\" + 0.010*\"china\" + 0.009*\"australian\" + 0.008*\"virus\" + 0.007*\"january\" + 0.006*\"university\" + 0.005*\"one\"\n",
      "2020-05-08 10:36:00,484 : INFO : topic #1 (0.091): 0.013*\"australia\" + 0.012*\"coronavirus\" + 0.010*\"health\" + 0.009*\"january\" + 0.008*\"people\" + 0.008*\"virus\" + 0.008*\"australian\" + 0.007*\"february\" + 0.006*\"university\" + 0.006*\"china\"\n",
      "2020-05-08 10:36:00,485 : INFO : topic #9 (0.091): 0.012*\"coronavirus\" + 0.011*\"january\" + 0.011*\"people\" + 0.010*\"virus\" + 0.010*\"china\" + 0.010*\"february\" + 0.009*\"australia\" + 0.008*\"chinese\" + 0.007*\"case\" + 0.007*\"wuhan\"\n",
      "2020-05-08 10:36:00,486 : INFO : topic #7 (0.091): 0.014*\"australia\" + 0.013*\"coronavirus\" + 0.011*\"february\" + 0.010*\"people\" + 0.010*\"january\" + 0.010*\"australian\" + 0.009*\"health\" + 0.009*\"virus\" + 0.008*\"china\" + 0.008*\"case\"\n",
      "2020-05-08 10:36:00,487 : INFO : topic diff=0.729204, rho=1.000000\n",
      "2020-05-08 10:36:00,490 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:36:09,779 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:36:09,799 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:36:09,815 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:36:09,825 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:36:09,848 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:36:09,859 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:36:11,251 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:36:11,263 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:36:11,518 : INFO : using symmetric alpha at 0.08333333333333333\n",
      "2020-05-08 10:36:11,518 : INFO : using symmetric eta at 0.08333333333333333\n",
      "2020-05-08 10:36:11,518 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:36:11,529 : INFO : running online (single-pass) LDA training, 12 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:36:11,530 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:36:12,225 : INFO : -7.929 per-word bound, 243.8 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:36:12,226 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:36:12,660 : INFO : topic #0 (0.083): 0.015*\"coronavirus\" + 0.014*\"australia\" + 0.012*\"people\" + 0.009*\"university\" + 0.008*\"health\" + 0.008*\"australian\" + 0.007*\"woman\" + 0.007*\"january\" + 0.006*\"one\" + 0.006*\"also\"\n",
      "2020-05-08 10:36:12,676 : INFO : topic #7 (0.083): 0.023*\"february\" + 0.018*\"january\" + 0.016*\"coronavirus\" + 0.015*\"australia\" + 0.014*\"people\" + 0.011*\"australian\" + 0.010*\"wuhan\" + 0.009*\"virus\" + 0.009*\"china\" + 0.008*\"chinese\"\n",
      "2020-05-08 10:36:12,676 : INFO : topic #9 (0.083): 0.017*\"people\" + 0.013*\"virus\" + 0.012*\"coronavirus\" + 0.012*\"china\" + 0.011*\"january\" + 0.011*\"case\" + 0.010*\"australia\" + 0.010*\"february\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 10:36:12,678 : INFO : topic #10 (0.083): 0.013*\"people\" + 0.012*\"australia\" + 0.009*\"virus\" + 0.009*\"health\" + 0.008*\"year\" + 0.007*\"china\" + 0.007*\"australian\" + 0.006*\"also\" + 0.006*\"case\" + 0.006*\"coronavirus\"\n",
      "2020-05-08 10:36:12,680 : INFO : topic #8 (0.083): 0.014*\"coronavirus\" + 0.014*\"australia\" + 0.010*\"people\" + 0.009*\"virus\" + 0.008*\"china\" + 0.007*\"february\" + 0.006*\"wuhan\" + 0.006*\"year\" + 0.006*\"health\" + 0.006*\"case\"\n",
      "2020-05-08 10:36:12,681 : INFO : topic diff=0.746366, rho=1.000000\n",
      "2020-05-08 10:36:12,683 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:36:22,206 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:36:22,222 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:36:22,242 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:36:22,257 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:36:22,277 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:36:22,290 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:36:23,689 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:36:23,721 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:36:24,063 : INFO : using symmetric alpha at 0.07692307692307693\n",
      "2020-05-08 10:36:24,064 : INFO : using symmetric eta at 0.07692307692307693\n",
      "2020-05-08 10:36:24,064 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:36:24,068 : INFO : running online (single-pass) LDA training, 13 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:36:24,070 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:36:24,764 : INFO : -7.955 per-word bound, 248.1 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 10:36:24,764 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:36:25,207 : INFO : topic #12 (0.077): 0.016*\"february\" + 0.012*\"january\" + 0.012*\"people\" + 0.011*\"china\" + 0.011*\"virus\" + 0.010*\"australia\" + 0.010*\"coronavirus\" + 0.009*\"case\" + 0.008*\"ship\" + 0.007*\"two\"\n",
      "2020-05-08 10:36:25,209 : INFO : topic #5 (0.077): 0.017*\"australia\" + 0.014*\"january\" + 0.014*\"february\" + 0.012*\"coronavirus\" + 0.012*\"china\" + 0.010*\"virus\" + 0.010*\"people\" + 0.008*\"australian\" + 0.008*\"case\" + 0.007*\"wuhan\"\n",
      "2020-05-08 10:36:25,210 : INFO : topic #8 (0.077): 0.018*\"australia\" + 0.014*\"february\" + 0.013*\"january\" + 0.013*\"people\" + 0.010*\"coronavirus\" + 0.008*\"case\" + 0.008*\"university\" + 0.008*\"also\" + 0.007*\"australian\" + 0.007*\"could\"\n",
      "2020-05-08 10:36:25,211 : INFO : topic #11 (0.077): 0.019*\"february\" + 0.015*\"january\" + 0.012*\"coronavirus\" + 0.010*\"australian\" + 0.009*\"people\" + 0.009*\"china\" + 0.008*\"case\" + 0.007*\"virus\" + 0.007*\"australia\" + 0.007*\"health\"\n",
      "2020-05-08 10:36:25,213 : INFO : topic #3 (0.077): 0.013*\"australia\" + 0.009*\"fire\" + 0.009*\"people\" + 0.009*\"year\" + 0.009*\"coronavirus\" + 0.007*\"virus\" + 0.007*\"february\" + 0.007*\"say\" + 0.007*\"australian\" + 0.006*\"january\"\n",
      "2020-05-08 10:36:25,214 : INFO : topic diff=0.761357, rho=1.000000\n",
      "2020-05-08 10:36:25,217 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:36:34,615 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:36:34,632 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:36:34,654 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:36:34,679 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:36:34,710 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:36:34,734 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:36:36,449 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:36:36,469 : INFO : accumulated word occurrence stats for 163918 virtual documents\n",
      "2020-05-08 10:36:36,804 : INFO : using symmetric alpha at 0.07142857142857142\n",
      "2020-05-08 10:36:36,805 : INFO : using symmetric eta at 0.07142857142857142\n",
      "2020-05-08 10:36:36,806 : INFO : using serial LDA version on this node\n",
      "2020-05-08 10:36:36,811 : INFO : running online (single-pass) LDA training, 14 topics, 1 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 366 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2020-05-08 10:36:36,812 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2020-05-08 10:36:37,756 : INFO : -7.981 per-word bound, 252.7 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n",
      "2020-05-08 10:36:37,756 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 10:36:38,330 : INFO : topic #12 (0.071): 0.011*\"australian\" + 0.009*\"people\" + 0.009*\"australia\" + 0.009*\"coronavirus\" + 0.007*\"fire\" + 0.007*\"virus\" + 0.007*\"year\" + 0.007*\"case\" + 0.006*\"health\" + 0.006*\"one\"\n",
      "2020-05-08 10:36:38,331 : INFO : topic #4 (0.071): 0.016*\"coronavirus\" + 0.015*\"february\" + 0.014*\"australia\" + 0.013*\"people\" + 0.013*\"january\" + 0.013*\"china\" + 0.008*\"virus\" + 0.007*\"australian\" + 0.006*\"case\" + 0.006*\"wuhan\"\n",
      "2020-05-08 10:36:38,332 : INFO : topic #11 (0.071): 0.013*\"australia\" + 0.011*\"people\" + 0.010*\"university\" + 0.010*\"coronavirus\" + 0.009*\"february\" + 0.009*\"virus\" + 0.007*\"school\" + 0.007*\"australian\" + 0.006*\"january\" + 0.006*\"health\"\n",
      "2020-05-08 10:36:38,332 : INFO : topic #7 (0.071): 0.016*\"february\" + 0.014*\"january\" + 0.013*\"coronavirus\" + 0.010*\"case\" + 0.010*\"australia\" + 0.009*\"student\" + 0.008*\"virus\" + 0.007*\"australian\" + 0.007*\"year\" + 0.006*\"university\"\n",
      "2020-05-08 10:36:38,333 : INFO : topic #6 (0.071): 0.018*\"january\" + 0.015*\"australia\" + 0.015*\"february\" + 0.012*\"australian\" + 0.010*\"virus\" + 0.010*\"coronavirus\" + 0.009*\"people\" + 0.009*\"health\" + 0.008*\"south\" + 0.008*\"case\"\n",
      "2020-05-08 10:36:38,334 : INFO : topic diff=0.783635, rho=1.000000\n",
      "2020-05-08 10:36:38,338 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 10:36:49,508 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 10:36:49,540 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 10:36:49,574 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 10:36:49,595 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 10:36:49,617 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 10:36:49,632 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 10:36:51,742 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 10:36:51,760 : INFO : accumulated word occurrence stats for 163918 virtual documents\n"
     ]
    }
   ],
   "source": [
    "#The coherence value is calculated for 15 number of topics and incremented by 1\n",
    "\n",
    "limit=15;\n",
    "start=2;\n",
    "step=1;\n",
    "\n",
    "#coherence values are stored \n",
    "body_coherence_values=compute_coherence_values(process_dic,process_corpus,process_docs,limit,start,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "y3zRNzIhILYV",
    "outputId": "727133cb-11ee-4694-b12b-9de56bde9f66"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A graph is plotted with Number of topics versus coherence score\n",
    "x=range(2,15)\n",
    "plt.plot(x,body_coherence_values,'bo-')\n",
    "plt.xlim(2,15)\n",
    "plt.xlabel(\"Number of  Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 LDA models are built for Number of topics as <i>2 and 10</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CfNek9SBJRjz",
    "outputId": "14943def-fa94-48f4-bc77-dfb009d2d157"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:57:07,564 : INFO : using autotuned alpha, starting with [0.5, 0.5]\n",
      "2020-05-08 14:57:07,568 : INFO : using serial LDA version on this node\n",
      "2020-05-08 14:57:07,569 : INFO : running online (multi-pass) LDA training, 2 topics, 20 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2020-05-08 14:57:07,570 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 14:57:12,259 : INFO : optimized alpha [0.7413664, 0.6214323]\n",
      "2020-05-08 14:57:12,259 : INFO : topic #0 (0.741): 0.014*\"february\" + 0.013*\"january\" + 0.013*\"people\" + 0.012*\"australia\" + 0.012*\"coronavirus\" + 0.010*\"virus\" + 0.009*\"china\" + 0.008*\"health\" + 0.007*\"australian\" + 0.007*\"case\"\n",
      "2020-05-08 14:57:12,259 : INFO : topic #1 (0.621): 0.015*\"australia\" + 0.012*\"coronavirus\" + 0.009*\"australian\" + 0.009*\"people\" + 0.009*\"february\" + 0.008*\"january\" + 0.007*\"case\" + 0.006*\"china\" + 0.006*\"year\" + 0.006*\"area\"\n",
      "2020-05-08 14:57:12,262 : INFO : topic diff=0.662040, rho=1.000000\n",
      "2020-05-08 14:57:12,264 : INFO : PROGRESS: pass 1, at document #366/366\n",
      "2020-05-08 14:57:14,893 : INFO : optimized alpha [0.3135394, 0.19187364]\n",
      "2020-05-08 14:57:14,896 : INFO : topic #0 (0.314): 0.015*\"february\" + 0.014*\"january\" + 0.014*\"coronavirus\" + 0.014*\"australia\" + 0.013*\"people\" + 0.011*\"virus\" + 0.010*\"china\" + 0.008*\"health\" + 0.008*\"case\" + 0.008*\"australian\"\n",
      "2020-05-08 14:57:14,897 : INFO : topic #1 (0.192): 0.014*\"australia\" + 0.009*\"coronavirus\" + 0.008*\"australian\" + 0.008*\"people\" + 0.007*\"area\" + 0.007*\"year\" + 0.006*\"february\" + 0.006*\"one\" + 0.006*\"also\" + 0.006*\"january\"\n",
      "2020-05-08 14:57:14,899 : INFO : topic diff=0.180054, rho=0.577350\n",
      "2020-05-08 14:57:14,905 : INFO : PROGRESS: pass 2, at document #366/366\n",
      "2020-05-08 14:57:15,976 : INFO : optimized alpha [0.13323821, 0.110994354]\n",
      "2020-05-08 14:57:15,976 : INFO : topic #0 (0.133): 0.016*\"february\" + 0.015*\"coronavirus\" + 0.015*\"january\" + 0.014*\"australia\" + 0.013*\"people\" + 0.011*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:15,976 : INFO : topic #1 (0.111): 0.012*\"australia\" + 0.008*\"people\" + 0.007*\"australian\" + 0.007*\"area\" + 0.007*\"year\" + 0.007*\"also\" + 0.006*\"university\" + 0.006*\"one\" + 0.006*\"coronavirus\" + 0.006*\"say\"\n",
      "2020-05-08 14:57:15,980 : INFO : topic diff=0.125641, rho=0.500000\n",
      "2020-05-08 14:57:15,982 : INFO : PROGRESS: pass 3, at document #366/366\n",
      "2020-05-08 14:57:16,626 : INFO : optimized alpha [0.11123322, 0.090589434]\n",
      "2020-05-08 14:57:16,626 : INFO : topic #0 (0.111): 0.016*\"february\" + 0.016*\"coronavirus\" + 0.015*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:16,626 : INFO : topic #1 (0.091): 0.012*\"australia\" + 0.008*\"people\" + 0.007*\"area\" + 0.007*\"university\" + 0.007*\"year\" + 0.007*\"also\" + 0.007*\"australian\" + 0.006*\"one\" + 0.006*\"say\" + 0.006*\"fire\"\n",
      "2020-05-08 14:57:16,632 : INFO : topic diff=0.085973, rho=0.447214\n",
      "2020-05-08 14:57:16,634 : INFO : PROGRESS: pass 4, at document #366/366\n",
      "2020-05-08 14:57:17,275 : INFO : optimized alpha [0.0995703, 0.08102662]\n",
      "2020-05-08 14:57:17,277 : INFO : topic #0 (0.100): 0.017*\"february\" + 0.016*\"coronavirus\" + 0.015*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:17,279 : INFO : topic #1 (0.081): 0.011*\"australia\" + 0.008*\"university\" + 0.008*\"people\" + 0.007*\"area\" + 0.007*\"also\" + 0.007*\"year\" + 0.007*\"australian\" + 0.006*\"one\" + 0.006*\"say\" + 0.006*\"fire\"\n",
      "2020-05-08 14:57:17,280 : INFO : topic diff=0.062714, rho=0.408248\n",
      "2020-05-08 14:57:17,283 : INFO : PROGRESS: pass 5, at document #366/366\n",
      "2020-05-08 14:57:17,825 : INFO : optimized alpha [0.09267586, 0.07543575]\n",
      "2020-05-08 14:57:17,825 : INFO : topic #0 (0.093): 0.017*\"february\" + 0.016*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:17,835 : INFO : topic #1 (0.075): 0.011*\"australia\" + 0.009*\"university\" + 0.008*\"people\" + 0.008*\"area\" + 0.007*\"also\" + 0.007*\"year\" + 0.006*\"australian\" + 0.006*\"say\" + 0.006*\"one\" + 0.006*\"fire\"\n",
      "2020-05-08 14:57:17,836 : INFO : topic diff=0.048127, rho=0.377964\n",
      "2020-05-08 14:57:17,840 : INFO : PROGRESS: pass 6, at document #366/366\n",
      "2020-05-08 14:57:18,424 : INFO : optimized alpha [0.08799278, 0.072114974]\n",
      "2020-05-08 14:57:18,426 : INFO : topic #0 (0.088): 0.017*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:18,426 : INFO : topic #1 (0.072): 0.011*\"australia\" + 0.009*\"university\" + 0.008*\"also\" + 0.008*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"australian\" + 0.006*\"fire\"\n",
      "2020-05-08 14:57:18,427 : INFO : topic diff=0.038030, rho=0.353553\n",
      "2020-05-08 14:57:18,429 : INFO : PROGRESS: pass 7, at document #366/366\n",
      "2020-05-08 14:57:18,964 : INFO : optimized alpha [0.086132154, 0.07046816]\n",
      "2020-05-08 14:57:18,968 : INFO : topic #0 (0.086): 0.017*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:18,972 : INFO : topic #1 (0.070): 0.010*\"australia\" + 0.009*\"university\" + 0.008*\"also\" + 0.008*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"australian\"\n",
      "2020-05-08 14:57:18,972 : INFO : topic diff=0.031271, rho=0.333333\n",
      "2020-05-08 14:57:18,978 : INFO : PROGRESS: pass 8, at document #366/366\n",
      "2020-05-08 14:57:19,621 : INFO : optimized alpha [0.08523104, 0.06959175]\n",
      "2020-05-08 14:57:19,625 : INFO : topic #0 (0.085): 0.017*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:19,628 : INFO : topic #1 (0.070): 0.010*\"australia\" + 0.009*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"australian\"\n",
      "2020-05-08 14:57:19,629 : INFO : topic diff=0.026043, rho=0.316228\n",
      "2020-05-08 14:57:19,633 : INFO : PROGRESS: pass 9, at document #366/366\n",
      "2020-05-08 14:57:20,298 : INFO : optimized alpha [0.08495916, 0.06909533]\n",
      "2020-05-08 14:57:20,302 : INFO : topic #0 (0.085): 0.017*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:20,302 : INFO : topic #1 (0.069): 0.010*\"australia\" + 0.010*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"australian\"\n",
      "2020-05-08 14:57:20,305 : INFO : topic diff=0.021895, rho=0.301511\n",
      "2020-05-08 14:57:20,309 : INFO : PROGRESS: pass 10, at document #366/366\n",
      "2020-05-08 14:57:20,876 : INFO : optimized alpha [0.0856117, 0.06933114]\n",
      "2020-05-08 14:57:20,876 : INFO : topic #0 (0.086): 0.017*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:20,892 : INFO : topic #1 (0.069): 0.010*\"australia\" + 0.010*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:20,892 : INFO : topic diff=0.018996, rho=0.288675\n",
      "2020-05-08 14:57:20,898 : INFO : PROGRESS: pass 11, at document #366/366\n",
      "2020-05-08 14:57:21,420 : INFO : optimized alpha [0.08669554, 0.06993265]\n",
      "2020-05-08 14:57:21,423 : INFO : topic #0 (0.087): 0.017*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.011*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:21,425 : INFO : topic #1 (0.070): 0.010*\"australia\" + 0.010*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:57:21,428 : INFO : topic diff=0.016497, rho=0.277350\n",
      "2020-05-08 14:57:21,431 : INFO : PROGRESS: pass 12, at document #366/366\n",
      "2020-05-08 14:57:22,045 : INFO : optimized alpha [0.087715834, 0.07058468]\n",
      "2020-05-08 14:57:22,049 : INFO : topic #0 (0.088): 0.018*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.015*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:22,050 : INFO : topic #1 (0.071): 0.010*\"australia\" + 0.010*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:22,051 : INFO : topic diff=0.014257, rho=0.267261\n",
      "2020-05-08 14:57:22,053 : INFO : PROGRESS: pass 13, at document #366/366\n",
      "2020-05-08 14:57:22,596 : INFO : optimized alpha [0.08891782, 0.07133421]\n",
      "2020-05-08 14:57:22,596 : INFO : topic #0 (0.089): 0.018*\"february\" + 0.017*\"coronavirus\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:22,596 : INFO : topic #1 (0.071): 0.010*\"australia\" + 0.010*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:22,601 : INFO : topic diff=0.012403, rho=0.258199\n",
      "2020-05-08 14:57:22,604 : INFO : PROGRESS: pass 14, at document #366/366\n",
      "2020-05-08 14:57:23,195 : INFO : optimized alpha [0.09004822, 0.07211419]\n",
      "2020-05-08 14:57:23,199 : INFO : topic #0 (0.090): 0.018*\"february\" + 0.018*\"coronavirus\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:23,202 : INFO : topic #1 (0.072): 0.010*\"australia\" + 0.010*\"university\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:23,204 : INFO : topic diff=0.010809, rho=0.250000\n",
      "2020-05-08 14:57:23,208 : INFO : PROGRESS: pass 15, at document #366/366\n",
      "2020-05-08 14:57:23,757 : INFO : optimized alpha [0.09138006, 0.07304862]\n",
      "2020-05-08 14:57:23,757 : INFO : topic #0 (0.091): 0.018*\"february\" + 0.018*\"coronavirus\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:23,762 : INFO : topic #1 (0.073): 0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:23,763 : INFO : topic diff=0.009567, rho=0.242536\n",
      "2020-05-08 14:57:23,767 : INFO : PROGRESS: pass 16, at document #366/366\n",
      "2020-05-08 14:57:24,398 : INFO : optimized alpha [0.09267316, 0.07407278]\n",
      "2020-05-08 14:57:24,400 : INFO : topic #0 (0.093): 0.018*\"february\" + 0.018*\"coronavirus\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:24,403 : INFO : topic #1 (0.074): 0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:24,406 : INFO : topic diff=0.008433, rho=0.235702\n",
      "2020-05-08 14:57:24,409 : INFO : PROGRESS: pass 17, at document #366/366\n",
      "2020-05-08 14:57:25,045 : INFO : optimized alpha [0.09408595, 0.0750746]\n",
      "2020-05-08 14:57:25,047 : INFO : topic #0 (0.094): 0.018*\"february\" + 0.018*\"coronavirus\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.012*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:25,048 : INFO : topic #1 (0.075): 0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:25,048 : INFO : topic diff=0.007432, rho=0.229416\n",
      "2020-05-08 14:57:25,054 : INFO : PROGRESS: pass 18, at document #366/366\n",
      "2020-05-08 14:57:25,658 : INFO : optimized alpha [0.09553323, 0.076111086]\n",
      "2020-05-08 14:57:25,660 : INFO : topic #0 (0.096): 0.018*\"coronavirus\" + 0.018*\"february\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.013*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:25,661 : INFO : topic #1 (0.076): 0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:25,664 : INFO : topic diff=0.006589, rho=0.223607\n",
      "2020-05-08 14:57:25,667 : INFO : PROGRESS: pass 19, at document #366/366\n",
      "2020-05-08 14:57:26,293 : INFO : optimized alpha [0.09690195, 0.077149004]\n",
      "2020-05-08 14:57:26,294 : INFO : topic #0 (0.097): 0.018*\"coronavirus\" + 0.018*\"february\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.013*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:26,298 : INFO : topic #1 (0.077): 0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n",
      "2020-05-08 14:57:26,298 : INFO : topic diff=0.005863, rho=0.218218\n",
      "2020-05-08 14:57:26,304 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "2020-05-08 14:57:26,306 : INFO : using serial LDA version on this node\n",
      "2020-05-08 14:57:26,312 : INFO : running online (multi-pass) LDA training, 10 topics, 20 passes over the supplied corpus of 366 documents, updating model once every 366 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2020-05-08 14:57:26,315 : INFO : PROGRESS: pass 0, at document #366/366\n",
      "2020-05-08 14:57:30,978 : INFO : optimized alpha [0.07474391, 0.044889316, 0.059322648, 0.07765011, 0.050168816, 0.05120178, 0.09904821, 0.0631677, 0.07862401, 0.06752378]\n",
      "2020-05-08 14:57:30,981 : INFO : topic #1 (0.045): 0.012*\"say\" + 0.011*\"also\" + 0.010*\"one\" + 0.010*\"university\" + 0.009*\"material\" + 0.009*\"dr\" + 0.009*\"research\" + 0.009*\"could\" + 0.008*\"australia\" + 0.007*\"like\"\n",
      "2020-05-08 14:57:30,982 : INFO : topic #4 (0.050): 0.014*\"china\" + 0.012*\"coronavirus\" + 0.011*\"australia\" + 0.008*\"year\" + 0.008*\"virus\" + 0.007*\"people\" + 0.007*\"case\" + 0.006*\"chinese\" + 0.006*\"day\" + 0.006*\"january\"\n",
      "2020-05-08 14:57:30,983 : INFO : topic #3 (0.078): 0.013*\"australia\" + 0.012*\"coronavirus\" + 0.012*\"february\" + 0.011*\"people\" + 0.011*\"january\" + 0.010*\"australian\" + 0.009*\"virus\" + 0.009*\"patient\" + 0.008*\"china\" + 0.007*\"health\"\n",
      "2020-05-08 14:57:30,986 : INFO : topic #8 (0.079): 0.018*\"australia\" + 0.017*\"february\" + 0.014*\"virus\" + 0.013*\"coronavirus\" + 0.013*\"january\" + 0.010*\"people\" + 0.009*\"australian\" + 0.009*\"china\" + 0.009*\"case\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:30,987 : INFO : topic #6 (0.099): 0.022*\"february\" + 0.018*\"january\" + 0.018*\"coronavirus\" + 0.017*\"australia\" + 0.011*\"people\" + 0.009*\"australian\" + 0.008*\"south\" + 0.008*\"case\" + 0.008*\"china\" + 0.007*\"virus\"\n",
      "2020-05-08 14:57:30,988 : INFO : topic diff=1.133880, rho=1.000000\n",
      "2020-05-08 14:57:30,992 : INFO : PROGRESS: pass 1, at document #366/366\n",
      "2020-05-08 14:57:32,999 : INFO : optimized alpha [0.061992425, 0.04257572, 0.052529182, 0.06175418, 0.041774504, 0.04928974, 0.09010115, 0.054692533, 0.06936738, 0.0593637]\n",
      "2020-05-08 14:57:33,002 : INFO : topic #4 (0.042): 0.018*\"china\" + 0.014*\"coronavirus\" + 0.010*\"case\" + 0.008*\"chinese\" + 0.008*\"death\" + 0.008*\"year\" + 0.008*\"people\" + 0.008*\"virus\" + 0.007*\"wuhan\" + 0.007*\"australia\"\n",
      "2020-05-08 14:57:33,003 : INFO : topic #1 (0.043): 0.013*\"say\" + 0.013*\"university\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"research\" + 0.010*\"could\" + 0.009*\"time\" + 0.009*\"dr\" + 0.008*\"like\" + 0.008*\"material\"\n",
      "2020-05-08 14:57:33,004 : INFO : topic #0 (0.062): 0.018*\"virus\" + 0.017*\"people\" + 0.014*\"coronavirus\" + 0.011*\"case\" + 0.011*\"australia\" + 0.010*\"china\" + 0.008*\"health\" + 0.008*\"january\" + 0.007*\"australian\" + 0.007*\"outbreak\"\n",
      "2020-05-08 14:57:33,005 : INFO : topic #8 (0.069): 0.021*\"australia\" + 0.019*\"february\" + 0.015*\"january\" + 0.014*\"coronavirus\" + 0.013*\"virus\" + 0.011*\"australian\" + 0.010*\"china\" + 0.009*\"people\" + 0.009*\"case\" + 0.008*\"student\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:57:33,007 : INFO : topic #6 (0.090): 0.028*\"february\" + 0.022*\"january\" + 0.019*\"coronavirus\" + 0.018*\"australia\" + 0.011*\"people\" + 0.009*\"australian\" + 0.009*\"south\" + 0.008*\"case\" + 0.008*\"mask\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:33,008 : INFO : topic diff=0.375959, rho=0.577350\n",
      "2020-05-08 14:57:33,010 : INFO : PROGRESS: pass 2, at document #366/366\n",
      "2020-05-08 14:57:34,423 : INFO : optimized alpha [0.054589055, 0.041964903, 0.048688017, 0.051896587, 0.036699317, 0.048183568, 0.08457738, 0.050615884, 0.06203643, 0.05547158]\n",
      "2020-05-08 14:57:34,432 : INFO : topic #4 (0.037): 0.021*\"china\" + 0.016*\"coronavirus\" + 0.013*\"case\" + 0.010*\"death\" + 0.010*\"chinese\" + 0.008*\"wuhan\" + 0.008*\"people\" + 0.008*\"virus\" + 0.007*\"number\" + 0.007*\"year\"\n",
      "2020-05-08 14:57:34,434 : INFO : topic #1 (0.042): 0.014*\"university\" + 0.014*\"say\" + 0.011*\"one\" + 0.010*\"time\" + 0.010*\"also\" + 0.010*\"could\" + 0.010*\"research\" + 0.009*\"like\" + 0.008*\"dr\" + 0.008*\"work\"\n",
      "2020-05-08 14:57:34,435 : INFO : topic #9 (0.055): 0.016*\"people\" + 0.013*\"wuhan\" + 0.012*\"coronavirus\" + 0.012*\"australia\" + 0.012*\"china\" + 0.011*\"january\" + 0.011*\"virus\" + 0.009*\"flight\" + 0.009*\"passenger\" + 0.009*\"health\"\n",
      "2020-05-08 14:57:34,435 : INFO : topic #8 (0.062): 0.023*\"australia\" + 0.022*\"february\" + 0.017*\"january\" + 0.014*\"coronavirus\" + 0.012*\"australian\" + 0.012*\"china\" + 0.011*\"virus\" + 0.011*\"student\" + 0.008*\"health\" + 0.008*\"people\"\n",
      "2020-05-08 14:57:34,437 : INFO : topic #6 (0.085): 0.031*\"february\" + 0.024*\"january\" + 0.020*\"coronavirus\" + 0.018*\"australia\" + 0.012*\"people\" + 0.010*\"south\" + 0.010*\"australian\" + 0.009*\"mask\" + 0.008*\"case\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:34,438 : INFO : topic diff=0.316876, rho=0.500000\n",
      "2020-05-08 14:57:34,441 : INFO : PROGRESS: pass 3, at document #366/366\n",
      "2020-05-08 14:57:35,691 : INFO : optimized alpha [0.049699035, 0.04200949, 0.046356216, 0.045859564, 0.033200197, 0.04764406, 0.08197129, 0.048455432, 0.057456017, 0.053432804]\n",
      "2020-05-08 14:57:35,704 : INFO : topic #4 (0.033): 0.024*\"china\" + 0.018*\"coronavirus\" + 0.015*\"case\" + 0.011*\"death\" + 0.011*\"chinese\" + 0.010*\"wuhan\" + 0.009*\"people\" + 0.008*\"virus\" + 0.008*\"number\" + 0.008*\"saturday\"\n",
      "2020-05-08 14:57:35,706 : INFO : topic #1 (0.042): 0.015*\"university\" + 0.014*\"say\" + 0.011*\"one\" + 0.011*\"time\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"research\" + 0.009*\"like\" + 0.008*\"dr\" + 0.008*\"work\"\n",
      "2020-05-08 14:57:35,707 : INFO : topic #9 (0.053): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.012*\"china\" + 0.012*\"australia\" + 0.012*\"january\" + 0.012*\"virus\" + 0.010*\"flight\" + 0.010*\"passenger\" + 0.009*\"health\"\n",
      "2020-05-08 14:57:35,707 : INFO : topic #8 (0.057): 0.024*\"australia\" + 0.023*\"february\" + 0.017*\"january\" + 0.015*\"coronavirus\" + 0.013*\"australian\" + 0.013*\"student\" + 0.012*\"china\" + 0.010*\"virus\" + 0.009*\"ban\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:35,711 : INFO : topic #6 (0.082): 0.034*\"february\" + 0.026*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.012*\"people\" + 0.010*\"south\" + 0.010*\"australian\" + 0.010*\"mask\" + 0.008*\"case\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:35,711 : INFO : topic diff=0.289916, rho=0.447214\n",
      "2020-05-08 14:57:35,717 : INFO : PROGRESS: pass 4, at document #366/366\n",
      "2020-05-08 14:57:36,846 : INFO : optimized alpha [0.04629221, 0.042221446, 0.04474077, 0.04154052, 0.030669725, 0.047202773, 0.08079626, 0.0474236, 0.054421872, 0.05199168]\n",
      "2020-05-08 14:57:36,853 : INFO : topic #4 (0.031): 0.026*\"china\" + 0.019*\"coronavirus\" + 0.017*\"case\" + 0.012*\"death\" + 0.012*\"chinese\" + 0.011*\"wuhan\" + 0.009*\"number\" + 0.009*\"virus\" + 0.009*\"people\" + 0.008*\"saturday\"\n",
      "2020-05-08 14:57:36,854 : INFO : topic #3 (0.042): 0.026*\"patient\" + 0.012*\"study\" + 0.012*\"coronavirus\" + 0.011*\"mass\" + 0.010*\"would\" + 0.010*\"australia\" + 0.010*\"february\" + 0.010*\"disease\" + 0.010*\"also\" + 0.009*\"australian\"\n",
      "2020-05-08 14:57:36,856 : INFO : topic #9 (0.052): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.012*\"china\" + 0.012*\"january\" + 0.012*\"australia\" + 0.012*\"virus\" + 0.011*\"flight\" + 0.010*\"passenger\" + 0.009*\"health\"\n",
      "2020-05-08 14:57:36,858 : INFO : topic #8 (0.054): 0.025*\"australia\" + 0.023*\"february\" + 0.017*\"january\" + 0.015*\"coronavirus\" + 0.014*\"student\" + 0.013*\"australian\" + 0.013*\"china\" + 0.010*\"ban\" + 0.009*\"virus\" + 0.009*\"travel\"\n",
      "2020-05-08 14:57:36,859 : INFO : topic #6 (0.081): 0.036*\"february\" + 0.027*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.010*\"south\" + 0.010*\"australian\" + 0.010*\"mask\" + 0.008*\"case\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:36,859 : INFO : topic diff=0.275146, rho=0.408248\n",
      "2020-05-08 14:57:36,862 : INFO : PROGRESS: pass 5, at document #366/366\n",
      "2020-05-08 14:57:37,990 : INFO : optimized alpha [0.04376881, 0.042762995, 0.043602828, 0.038384747, 0.028670657, 0.046525292, 0.07980554, 0.046920966, 0.052509405, 0.051140822]\n",
      "2020-05-08 14:57:37,993 : INFO : topic #4 (0.029): 0.028*\"china\" + 0.020*\"coronavirus\" + 0.019*\"case\" + 0.013*\"death\" + 0.012*\"chinese\" + 0.011*\"wuhan\" + 0.010*\"number\" + 0.009*\"virus\" + 0.009*\"people\" + 0.009*\"sars\"\n",
      "2020-05-08 14:57:37,994 : INFO : topic #3 (0.038): 0.029*\"patient\" + 0.014*\"study\" + 0.012*\"mass\" + 0.011*\"would\" + 0.011*\"coronavirus\" + 0.011*\"disease\" + 0.010*\"also\" + 0.010*\"level\" + 0.010*\"test\" + 0.009*\"australia\"\n",
      "2020-05-08 14:57:37,994 : INFO : topic #9 (0.051): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.012*\"january\" + 0.012*\"australia\" + 0.012*\"virus\" + 0.011*\"flight\" + 0.010*\"passenger\" + 0.010*\"health\"\n",
      "2020-05-08 14:57:37,997 : INFO : topic #8 (0.053): 0.026*\"australia\" + 0.023*\"february\" + 0.017*\"january\" + 0.015*\"coronavirus\" + 0.015*\"student\" + 0.014*\"australian\" + 0.013*\"china\" + 0.010*\"ban\" + 0.009*\"travel\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:37,998 : INFO : topic #6 (0.080): 0.037*\"february\" + 0.028*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.010*\"south\" + 0.010*\"mask\" + 0.010*\"australian\" + 0.008*\"case\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:37,999 : INFO : topic diff=0.262770, rho=0.377964\n",
      "2020-05-08 14:57:38,001 : INFO : PROGRESS: pass 6, at document #366/366\n",
      "2020-05-08 14:57:38,982 : INFO : optimized alpha [0.04197628, 0.04340288, 0.042712644, 0.03611933, 0.027187021, 0.04599219, 0.07918896, 0.0467554, 0.051110387, 0.050496403]\n",
      "2020-05-08 14:57:38,990 : INFO : topic #4 (0.027): 0.029*\"china\" + 0.020*\"coronavirus\" + 0.020*\"case\" + 0.014*\"death\" + 0.013*\"chinese\" + 0.012*\"wuhan\" + 0.010*\"number\" + 0.009*\"virus\" + 0.009*\"sars\" + 0.009*\"reuters\"\n",
      "2020-05-08 14:57:38,992 : INFO : topic #3 (0.036): 0.030*\"patient\" + 0.015*\"study\" + 0.013*\"mass\" + 0.012*\"would\" + 0.012*\"disease\" + 0.011*\"also\" + 0.011*\"coronavirus\" + 0.011*\"test\" + 0.010*\"level\" + 0.010*\"normal\"\n",
      "2020-05-08 14:57:38,994 : INFO : topic #9 (0.050): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.012*\"january\" + 0.012*\"australia\" + 0.012*\"virus\" + 0.011*\"flight\" + 0.010*\"passenger\" + 0.010*\"health\"\n",
      "2020-05-08 14:57:38,996 : INFO : topic #8 (0.051): 0.027*\"australia\" + 0.024*\"february\" + 0.017*\"january\" + 0.015*\"student\" + 0.015*\"coronavirus\" + 0.014*\"australian\" + 0.013*\"china\" + 0.011*\"ban\" + 0.010*\"travel\" + 0.008*\"health\"\n",
      "2020-05-08 14:57:38,998 : INFO : topic #6 (0.079): 0.038*\"february\" + 0.028*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.011*\"south\" + 0.011*\"mask\" + 0.010*\"australian\" + 0.008*\"case\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:38,999 : INFO : topic diff=0.249400, rho=0.353553\n",
      "2020-05-08 14:57:39,005 : INFO : PROGRESS: pass 7, at document #366/366\n",
      "2020-05-08 14:57:39,987 : INFO : optimized alpha [0.040571034, 0.04409088, 0.04209993, 0.034411706, 0.026066016, 0.04548966, 0.079110935, 0.046664346, 0.04997518, 0.050439715]\n",
      "2020-05-08 14:57:39,994 : INFO : topic #4 (0.026): 0.030*\"china\" + 0.021*\"case\" + 0.021*\"coronavirus\" + 0.014*\"death\" + 0.013*\"chinese\" + 0.012*\"wuhan\" + 0.010*\"number\" + 0.010*\"reuters\" + 0.009*\"virus\" + 0.009*\"sars\"\n",
      "2020-05-08 14:57:39,995 : INFO : topic #3 (0.034): 0.032*\"patient\" + 0.016*\"study\" + 0.014*\"mass\" + 0.012*\"would\" + 0.012*\"disease\" + 0.011*\"also\" + 0.011*\"test\" + 0.011*\"level\" + 0.011*\"coronavirus\" + 0.010*\"normal\"\n",
      "2020-05-08 14:57:39,995 : INFO : topic #8 (0.050): 0.027*\"australia\" + 0.024*\"february\" + 0.017*\"january\" + 0.015*\"student\" + 0.015*\"coronavirus\" + 0.015*\"australian\" + 0.013*\"china\" + 0.011*\"ban\" + 0.010*\"travel\" + 0.008*\"health\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:57:39,995 : INFO : topic #9 (0.050): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.012*\"australia\" + 0.012*\"january\" + 0.012*\"virus\" + 0.011*\"flight\" + 0.010*\"passenger\" + 0.010*\"health\"\n",
      "2020-05-08 14:57:39,999 : INFO : topic #6 (0.079): 0.039*\"february\" + 0.029*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.011*\"south\" + 0.011*\"mask\" + 0.010*\"australian\" + 0.008*\"case\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:40,000 : INFO : topic diff=0.235364, rho=0.333333\n",
      "2020-05-08 14:57:40,007 : INFO : PROGRESS: pass 8, at document #366/366\n",
      "2020-05-08 14:57:40,980 : INFO : optimized alpha [0.039482366, 0.044859607, 0.04169744, 0.033065226, 0.025114592, 0.04505451, 0.07895058, 0.046720963, 0.0490349, 0.050597105]\n",
      "2020-05-08 14:57:40,986 : INFO : topic #4 (0.025): 0.031*\"china\" + 0.021*\"case\" + 0.021*\"coronavirus\" + 0.014*\"death\" + 0.013*\"chinese\" + 0.012*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"virus\"\n",
      "2020-05-08 14:57:40,988 : INFO : topic #3 (0.033): 0.033*\"patient\" + 0.017*\"study\" + 0.014*\"mass\" + 0.013*\"would\" + 0.013*\"disease\" + 0.012*\"also\" + 0.012*\"test\" + 0.011*\"level\" + 0.010*\"normal\" + 0.010*\"coronavirus\"\n",
      "2020-05-08 14:57:40,990 : INFO : topic #8 (0.049): 0.027*\"australia\" + 0.024*\"february\" + 0.017*\"january\" + 0.016*\"student\" + 0.015*\"coronavirus\" + 0.015*\"australian\" + 0.013*\"china\" + 0.011*\"ban\" + 0.010*\"travel\" + 0.009*\"government\"\n",
      "2020-05-08 14:57:40,991 : INFO : topic #9 (0.051): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.012*\"australia\" + 0.012*\"january\" + 0.012*\"virus\" + 0.011*\"flight\" + 0.010*\"passenger\" + 0.010*\"health\"\n",
      "2020-05-08 14:57:40,993 : INFO : topic #6 (0.079): 0.040*\"february\" + 0.029*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.011*\"south\" + 0.011*\"mask\" + 0.011*\"australian\" + 0.008*\"february_february\" + 0.008*\"case\"\n",
      "2020-05-08 14:57:40,995 : INFO : topic diff=0.220879, rho=0.316228\n",
      "2020-05-08 14:57:40,999 : INFO : PROGRESS: pass 9, at document #366/366\n",
      "2020-05-08 14:57:41,906 : INFO : optimized alpha [0.038560104, 0.04554502, 0.041314732, 0.031987574, 0.024361216, 0.04475852, 0.07888814, 0.046944536, 0.04833369, 0.05083206]\n",
      "2020-05-08 14:57:41,919 : INFO : topic #4 (0.024): 0.032*\"china\" + 0.022*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.013*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:41,921 : INFO : topic #3 (0.032): 0.033*\"patient\" + 0.018*\"study\" + 0.015*\"mass\" + 0.013*\"disease\" + 0.013*\"would\" + 0.012*\"test\" + 0.012*\"also\" + 0.012*\"level\" + 0.010*\"per\" + 0.010*\"normal\"\n",
      "2020-05-08 14:57:41,922 : INFO : topic #8 (0.048): 0.028*\"australia\" + 0.024*\"february\" + 0.017*\"january\" + 0.016*\"student\" + 0.015*\"australian\" + 0.015*\"coronavirus\" + 0.014*\"china\" + 0.011*\"ban\" + 0.010*\"travel\" + 0.009*\"government\"\n",
      "2020-05-08 14:57:41,923 : INFO : topic #9 (0.051): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.012*\"australia\" + 0.012*\"january\" + 0.012*\"virus\" + 0.011*\"flight\" + 0.010*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:41,925 : INFO : topic #6 (0.079): 0.040*\"february\" + 0.030*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.011*\"south\" + 0.011*\"mask\" + 0.011*\"australian\" + 0.008*\"february_february\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:41,925 : INFO : topic diff=0.205945, rho=0.301511\n",
      "2020-05-08 14:57:41,931 : INFO : PROGRESS: pass 10, at document #366/366\n",
      "2020-05-08 14:57:42,872 : INFO : optimized alpha [0.03780352, 0.046200596, 0.041021686, 0.031119805, 0.023722699, 0.044501487, 0.07906654, 0.04727152, 0.04782833, 0.051090777]\n",
      "2020-05-08 14:57:42,893 : INFO : topic #4 (0.024): 0.032*\"china\" + 0.022*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.013*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:42,895 : INFO : topic #3 (0.031): 0.034*\"patient\" + 0.018*\"study\" + 0.015*\"mass\" + 0.013*\"disease\" + 0.013*\"would\" + 0.013*\"test\" + 0.012*\"also\" + 0.012*\"level\" + 0.011*\"per\" + 0.011*\"normal\"\n",
      "2020-05-08 14:57:42,895 : INFO : topic #8 (0.048): 0.028*\"australia\" + 0.024*\"february\" + 0.017*\"january\" + 0.016*\"student\" + 0.015*\"australian\" + 0.015*\"coronavirus\" + 0.014*\"china\" + 0.011*\"ban\" + 0.011*\"travel\" + 0.009*\"government\"\n",
      "2020-05-08 14:57:42,895 : INFO : topic #9 (0.051): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.012*\"australia\" + 0.012*\"january\" + 0.012*\"virus\" + 0.012*\"flight\" + 0.010*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:42,900 : INFO : topic #6 (0.079): 0.041*\"february\" + 0.030*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"australian\" + 0.008*\"february_february\" + 0.008*\"virus\"\n",
      "2020-05-08 14:57:42,901 : INFO : topic diff=0.190752, rho=0.288675\n",
      "2020-05-08 14:57:42,906 : INFO : PROGRESS: pass 11, at document #366/366\n",
      "2020-05-08 14:57:43,825 : INFO : optimized alpha [0.037116263, 0.046909943, 0.040832944, 0.03044196, 0.023158083, 0.044275567, 0.07935699, 0.047525927, 0.04747288, 0.051368266]\n",
      "2020-05-08 14:57:43,829 : INFO : topic #4 (0.023): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.013*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:43,830 : INFO : topic #3 (0.030): 0.035*\"patient\" + 0.019*\"study\" + 0.016*\"mass\" + 0.014*\"disease\" + 0.013*\"would\" + 0.013*\"test\" + 0.013*\"also\" + 0.012*\"level\" + 0.012*\"per\" + 0.011*\"normal\"\n",
      "2020-05-08 14:57:43,831 : INFO : topic #7 (0.048): 0.017*\"woman\" + 0.014*\"school\" + 0.014*\"people\" + 0.013*\"university\" + 0.010*\"student\" + 0.008*\"home\" + 0.008*\"social\" + 0.007*\"health\" + 0.007*\"coronavirus\" + 0.007*\"business\"\n",
      "2020-05-08 14:57:43,832 : INFO : topic #9 (0.051): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"virus\" + 0.012*\"flight\" + 0.010*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:43,833 : INFO : topic #6 (0.079): 0.042*\"february\" + 0.030*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"people\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:43,834 : INFO : topic diff=0.175907, rho=0.277350\n",
      "2020-05-08 14:57:43,839 : INFO : PROGRESS: pass 12, at document #366/366\n",
      "2020-05-08 14:57:44,795 : INFO : optimized alpha [0.036542714, 0.047633834, 0.040636055, 0.029893529, 0.022690307, 0.044077992, 0.07975269, 0.047835078, 0.047205493, 0.051619913]\n",
      "2020-05-08 14:57:44,801 : INFO : topic #4 (0.023): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:44,802 : INFO : topic #3 (0.030): 0.035*\"patient\" + 0.019*\"study\" + 0.016*\"mass\" + 0.014*\"disease\" + 0.013*\"test\" + 0.013*\"would\" + 0.013*\"also\" + 0.013*\"level\" + 0.012*\"per\" + 0.011*\"per_cent\"\n",
      "2020-05-08 14:57:44,804 : INFO : topic #7 (0.048): 0.017*\"woman\" + 0.014*\"school\" + 0.014*\"people\" + 0.013*\"university\" + 0.010*\"student\" + 0.008*\"home\" + 0.008*\"social\" + 0.007*\"health\" + 0.007*\"coronavirus\" + 0.007*\"business\"\n",
      "2020-05-08 14:57:44,808 : INFO : topic #9 (0.052): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.012*\"virus\" + 0.010*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:44,810 : INFO : topic #6 (0.080): 0.042*\"february\" + 0.031*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"mask\" + 0.011*\"people\" + 0.011*\"south\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:44,812 : INFO : topic diff=0.161742, rho=0.267261\n",
      "2020-05-08 14:57:44,817 : INFO : PROGRESS: pass 13, at document #366/366\n",
      "2020-05-08 14:57:45,764 : INFO : optimized alpha [0.036069717, 0.0484487, 0.04046637, 0.029407162, 0.022321168, 0.043871637, 0.080309, 0.048120037, 0.047016073, 0.051937167]\n",
      "2020-05-08 14:57:45,770 : INFO : topic #4 (0.022): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:57:45,772 : INFO : topic #3 (0.029): 0.035*\"patient\" + 0.020*\"study\" + 0.016*\"mass\" + 0.014*\"disease\" + 0.013*\"test\" + 0.013*\"also\" + 0.013*\"would\" + 0.013*\"level\" + 0.013*\"per\" + 0.012*\"per_cent\"\n",
      "2020-05-08 14:57:45,775 : INFO : topic #1 (0.048): 0.016*\"university\" + 0.015*\"say\" + 0.011*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"like\" + 0.008*\"research\" + 0.008*\"work\" + 0.008*\"year\"\n",
      "2020-05-08 14:57:45,777 : INFO : topic #9 (0.052): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.012*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:45,779 : INFO : topic #6 (0.080): 0.042*\"february\" + 0.031*\"january\" + 0.020*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"people\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:45,781 : INFO : topic diff=0.148486, rho=0.258199\n",
      "2020-05-08 14:57:45,784 : INFO : PROGRESS: pass 14, at document #366/366\n",
      "2020-05-08 14:57:46,646 : INFO : optimized alpha [0.03565049, 0.04927246, 0.040347144, 0.02897238, 0.02200255, 0.043689307, 0.08087017, 0.048383646, 0.046888936, 0.052270636]\n",
      "2020-05-08 14:57:46,651 : INFO : topic #4 (0.022): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:46,655 : INFO : topic #3 (0.029): 0.036*\"patient\" + 0.020*\"study\" + 0.016*\"mass\" + 0.014*\"disease\" + 0.013*\"test\" + 0.013*\"per\" + 0.013*\"also\" + 0.013*\"level\" + 0.013*\"would\" + 0.012*\"per_cent\"\n",
      "2020-05-08 14:57:46,659 : INFO : topic #1 (0.049): 0.017*\"university\" + 0.015*\"say\" + 0.011*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"like\" + 0.008*\"work\" + 0.008*\"research\" + 0.008*\"year\"\n",
      "2020-05-08 14:57:46,662 : INFO : topic #9 (0.052): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.012*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:46,664 : INFO : topic #6 (0.081): 0.043*\"february\" + 0.031*\"january\" + 0.019*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"people\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:46,666 : INFO : topic diff=0.135906, rho=0.250000\n",
      "2020-05-08 14:57:46,672 : INFO : PROGRESS: pass 15, at document #366/366\n",
      "2020-05-08 14:57:47,562 : INFO : optimized alpha [0.03527687, 0.050142016, 0.04024465, 0.028602013, 0.02171212, 0.04355744, 0.08144268, 0.048663493, 0.046781152, 0.052578904]\n",
      "2020-05-08 14:57:47,568 : INFO : topic #4 (0.022): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:47,570 : INFO : topic #3 (0.029): 0.036*\"patient\" + 0.021*\"study\" + 0.016*\"mass\" + 0.014*\"disease\" + 0.014*\"per\" + 0.013*\"test\" + 0.013*\"level\" + 0.013*\"also\" + 0.013*\"would\" + 0.012*\"per_cent\"\n",
      "2020-05-08 14:57:47,572 : INFO : topic #1 (0.050): 0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"like\" + 0.008*\"work\" + 0.008*\"year\" + 0.008*\"research\"\n",
      "2020-05-08 14:57:47,574 : INFO : topic #9 (0.053): 0.016*\"people\" + 0.013*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:47,575 : INFO : topic #6 (0.081): 0.043*\"february\" + 0.031*\"january\" + 0.019*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"people\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:47,576 : INFO : topic diff=0.124313, rho=0.242536\n",
      "2020-05-08 14:57:47,581 : INFO : PROGRESS: pass 16, at document #366/366\n",
      "2020-05-08 14:57:48,508 : INFO : optimized alpha [0.034993146, 0.050952166, 0.040158678, 0.028287802, 0.021461317, 0.043475047, 0.082097255, 0.048996273, 0.046727076, 0.052946713]\n",
      "2020-05-08 14:57:48,515 : INFO : topic #4 (0.021): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.010*\"outbreak\"\n",
      "2020-05-08 14:57:48,516 : INFO : topic #3 (0.028): 0.036*\"patient\" + 0.021*\"study\" + 0.016*\"mass\" + 0.014*\"disease\" + 0.014*\"per\" + 0.013*\"test\" + 0.013*\"level\" + 0.013*\"also\" + 0.013*\"per_cent\" + 0.013*\"cent\"\n",
      "2020-05-08 14:57:48,517 : INFO : topic #1 (0.051): 0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.008*\"like\" + 0.008*\"work\" + 0.008*\"year\" + 0.008*\"research\"\n",
      "2020-05-08 14:57:48,520 : INFO : topic #9 (0.053): 0.016*\"people\" + 0.014*\"wuhan\" + 0.013*\"coronavirus\" + 0.013*\"china\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:48,522 : INFO : topic #6 (0.082): 0.043*\"february\" + 0.031*\"january\" + 0.019*\"coronavirus\" + 0.019*\"australia\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"people\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:48,523 : INFO : topic diff=0.113774, rho=0.235702\n",
      "2020-05-08 14:57:48,528 : INFO : PROGRESS: pass 17, at document #366/366\n",
      "2020-05-08 14:57:49,460 : INFO : optimized alpha [0.034786187, 0.051740084, 0.0400846, 0.028021252, 0.021230122, 0.043434016, 0.08268932, 0.04927134, 0.046715822, 0.05328818]\n",
      "2020-05-08 14:57:49,467 : INFO : topic #4 (0.021): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.009*\"outbreak\"\n",
      "2020-05-08 14:57:49,469 : INFO : topic #3 (0.028): 0.036*\"patient\" + 0.021*\"study\" + 0.017*\"mass\" + 0.014*\"disease\" + 0.014*\"per\" + 0.014*\"level\" + 0.014*\"test\" + 0.013*\"also\" + 0.013*\"per_cent\" + 0.013*\"cent\"\n",
      "2020-05-08 14:57:49,472 : INFO : topic #1 (0.052): 0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.008*\"like\" + 0.008*\"year\" + 0.008*\"work\" + 0.008*\"research\"\n",
      "2020-05-08 14:57:49,473 : INFO : topic #9 (0.053): 0.016*\"people\" + 0.014*\"china\" + 0.014*\"wuhan\" + 0.014*\"coronavirus\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:49,475 : INFO : topic #6 (0.083): 0.043*\"february\" + 0.031*\"january\" + 0.019*\"australia\" + 0.019*\"coronavirus\" + 0.011*\"mask\" + 0.011*\"south\" + 0.011*\"people\" + 0.011*\"australian\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:49,477 : INFO : topic diff=0.104279, rho=0.229416\n",
      "2020-05-08 14:57:49,482 : INFO : PROGRESS: pass 18, at document #366/366\n",
      "2020-05-08 14:57:50,413 : INFO : optimized alpha [0.034600418, 0.05250748, 0.040021364, 0.027778104, 0.02101671, 0.04340019, 0.08329265, 0.049528822, 0.0467117, 0.053680405]\n",
      "2020-05-08 14:57:50,419 : INFO : topic #4 (0.021): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.009*\"infection\"\n",
      "2020-05-08 14:57:50,421 : INFO : topic #3 (0.028): 0.036*\"patient\" + 0.022*\"study\" + 0.017*\"mass\" + 0.015*\"per\" + 0.015*\"disease\" + 0.014*\"level\" + 0.014*\"per_cent\" + 0.014*\"test\" + 0.014*\"cent\" + 0.013*\"also\"\n",
      "2020-05-08 14:57:50,423 : INFO : topic #1 (0.053): 0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"year\" + 0.008*\"work\" + 0.008*\"like\" + 0.008*\"research\"\n",
      "2020-05-08 14:57:50,425 : INFO : topic #9 (0.054): 0.016*\"people\" + 0.014*\"china\" + 0.014*\"coronavirus\" + 0.014*\"wuhan\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:50,426 : INFO : topic #6 (0.083): 0.044*\"february\" + 0.032*\"january\" + 0.019*\"australia\" + 0.019*\"coronavirus\" + 0.012*\"mask\" + 0.011*\"south\" + 0.011*\"australian\" + 0.011*\"people\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:50,427 : INFO : topic diff=0.095654, rho=0.223607\n",
      "2020-05-08 14:57:50,431 : INFO : PROGRESS: pass 19, at document #366/366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:57:51,365 : INFO : optimized alpha [0.034433868, 0.053296216, 0.0399433, 0.027556054, 0.020819357, 0.04337394, 0.08397366, 0.049836874, 0.04674617, 0.054048736]\n",
      "2020-05-08 14:57:51,370 : INFO : topic #4 (0.021): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.009*\"infection\"\n",
      "2020-05-08 14:57:51,372 : INFO : topic #3 (0.028): 0.037*\"patient\" + 0.022*\"study\" + 0.017*\"mass\" + 0.015*\"per\" + 0.015*\"disease\" + 0.014*\"per_cent\" + 0.014*\"cent\" + 0.014*\"level\" + 0.014*\"test\" + 0.013*\"also\"\n",
      "2020-05-08 14:57:51,374 : INFO : topic #1 (0.053): 0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"year\" + 0.008*\"work\" + 0.008*\"like\" + 0.008*\"research\"\n",
      "2020-05-08 14:57:51,376 : INFO : topic #9 (0.054): 0.016*\"people\" + 0.014*\"china\" + 0.014*\"coronavirus\" + 0.014*\"wuhan\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n",
      "2020-05-08 14:57:51,379 : INFO : topic #6 (0.084): 0.044*\"february\" + 0.032*\"january\" + 0.019*\"australia\" + 0.019*\"coronavirus\" + 0.012*\"mask\" + 0.011*\"south\" + 0.011*\"australian\" + 0.011*\"people\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:57:51,381 : INFO : topic diff=0.087952, rho=0.218218\n"
     ]
    }
   ],
   "source": [
    "model_1=model1(2,process_dic,process_corpus)\n",
    "model_2=model1(10,process_dic,process_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Analysis\n",
    "The two LDA models analysis is built for the BODY column. Based on the coherence plot, top two Num_topics is chosen to build the model.Based on the plot we could say the top two coherence score are for number of topics 2 and 10.The perplexity(measure to find the better model-lower perplexity is better) for two models are -6.57 and -6.45.The coherence score(Higher value gives better results) for the two models is 0.46 and 0.48.\n",
    "An LDA model is built for 2 and 10 topics to be found out from the context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "rdQXjJJZJR27",
    "outputId": "c39c10b6-f5cd-48c3-894b-a2d27ad67362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:59:48,295 : INFO : topic #0 (0.097): 0.018*\"coronavirus\" + 0.018*\"february\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.013*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"\n",
      "2020-05-08 14:59:48,297 : INFO : topic #1 (0.077): 0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"coronavirus\" + 0.018*\"february\" + 0.016*\"january\" + 0.016*\"australia\" + 0.013*\"people\" + 0.013*\"virus\" + 0.012*\"china\" + 0.009*\"case\" + 0.009*\"australian\" + 0.008*\"health\"'),\n",
       " (1,\n",
       "  '0.010*\"university\" + 0.010*\"australia\" + 0.008*\"also\" + 0.007*\"area\" + 0.007*\"people\" + 0.007*\"year\" + 0.007*\"say\" + 0.006*\"one\" + 0.006*\"fire\" + 0.006*\"could\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Topic Interpretation \n",
    "- Topic -1: The topic is based on corona-virus outbreak affecting people in china in January and February\n",
    "- Topic -2: This article is about the bush fires affecting people and universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "-0dB-YUEJSAL",
    "outputId": "ddeb7124-27ac-4aea-d45a-9336bcb4a90a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 14:59:57,467 : INFO : topic #0 (0.034): 0.038*\"virus\" + 0.025*\"people\" + 0.022*\"coronavirus\" + 0.018*\"case\" + 0.013*\"symptom\" + 0.013*\"spread\" + 0.012*\"china\" + 0.010*\"outbreak\" + 0.009*\"health\" + 0.009*\"wuhan\"\n",
      "2020-05-08 14:59:57,467 : INFO : topic #1 (0.053): 0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"year\" + 0.008*\"work\" + 0.008*\"like\" + 0.008*\"research\"\n",
      "2020-05-08 14:59:57,472 : INFO : topic #2 (0.040): 0.032*\"fire\" + 0.024*\"australia\" + 0.015*\"year\" + 0.013*\"bushfires\" + 0.013*\"south\" + 0.010*\"climate\" + 0.010*\"people\" + 0.008*\"million\" + 0.008*\"country\" + 0.008*\"bushfire\"\n",
      "2020-05-08 14:59:57,474 : INFO : topic #3 (0.028): 0.037*\"patient\" + 0.022*\"study\" + 0.017*\"mass\" + 0.015*\"per\" + 0.015*\"disease\" + 0.014*\"per_cent\" + 0.014*\"cent\" + 0.014*\"level\" + 0.014*\"test\" + 0.013*\"also\"\n",
      "2020-05-08 14:59:57,476 : INFO : topic #4 (0.021): 0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.009*\"infection\"\n",
      "2020-05-08 14:59:57,477 : INFO : topic #5 (0.043): 0.028*\"area\" + 0.014*\"cell\" + 0.013*\"australian\" + 0.012*\"australia\" + 0.012*\"smoke\" + 0.012*\"air\" + 0.011*\"data\" + 0.009*\"change\" + 0.008*\"specie\" + 0.008*\"climate\"\n",
      "2020-05-08 14:59:57,478 : INFO : topic #6 (0.084): 0.044*\"february\" + 0.032*\"january\" + 0.019*\"australia\" + 0.019*\"coronavirus\" + 0.012*\"mask\" + 0.011*\"south\" + 0.011*\"australian\" + 0.011*\"people\" + 0.009*\"february_february\" + 0.008*\"january_january\"\n",
      "2020-05-08 14:59:57,482 : INFO : topic #7 (0.050): 0.017*\"woman\" + 0.015*\"school\" + 0.015*\"people\" + 0.012*\"university\" + 0.009*\"student\" + 0.009*\"home\" + 0.008*\"coronavirus\" + 0.008*\"social\" + 0.008*\"health\" + 0.008*\"business\"\n",
      "2020-05-08 14:59:57,483 : INFO : topic #8 (0.047): 0.029*\"australia\" + 0.024*\"february\" + 0.017*\"student\" + 0.016*\"january\" + 0.016*\"australian\" + 0.016*\"coronavirus\" + 0.014*\"china\" + 0.012*\"ban\" + 0.011*\"travel\" + 0.009*\"government\"\n",
      "2020-05-08 14:59:57,485 : INFO : topic #9 (0.054): 0.016*\"people\" + 0.014*\"china\" + 0.014*\"coronavirus\" + 0.014*\"wuhan\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.038*\"virus\" + 0.025*\"people\" + 0.022*\"coronavirus\" + 0.018*\"case\" + 0.013*\"symptom\" + 0.013*\"spread\" + 0.012*\"china\" + 0.010*\"outbreak\" + 0.009*\"health\" + 0.009*\"wuhan\"'),\n",
       " (1,\n",
       "  '0.017*\"university\" + 0.015*\"say\" + 0.012*\"time\" + 0.011*\"one\" + 0.010*\"also\" + 0.010*\"could\" + 0.009*\"year\" + 0.008*\"work\" + 0.008*\"like\" + 0.008*\"research\"'),\n",
       " (2,\n",
       "  '0.032*\"fire\" + 0.024*\"australia\" + 0.015*\"year\" + 0.013*\"bushfires\" + 0.013*\"south\" + 0.010*\"climate\" + 0.010*\"people\" + 0.008*\"million\" + 0.008*\"country\" + 0.008*\"bushfire\"'),\n",
       " (3,\n",
       "  '0.037*\"patient\" + 0.022*\"study\" + 0.017*\"mass\" + 0.015*\"per\" + 0.015*\"disease\" + 0.014*\"per_cent\" + 0.014*\"cent\" + 0.014*\"level\" + 0.014*\"test\" + 0.013*\"also\"'),\n",
       " (4,\n",
       "  '0.033*\"china\" + 0.023*\"case\" + 0.021*\"coronavirus\" + 0.015*\"death\" + 0.014*\"chinese\" + 0.013*\"wuhan\" + 0.011*\"number\" + 0.010*\"reuters\" + 0.010*\"sars\" + 0.009*\"infection\"'),\n",
       " (5,\n",
       "  '0.028*\"area\" + 0.014*\"cell\" + 0.013*\"australian\" + 0.012*\"australia\" + 0.012*\"smoke\" + 0.012*\"air\" + 0.011*\"data\" + 0.009*\"change\" + 0.008*\"specie\" + 0.008*\"climate\"'),\n",
       " (6,\n",
       "  '0.044*\"february\" + 0.032*\"january\" + 0.019*\"australia\" + 0.019*\"coronavirus\" + 0.012*\"mask\" + 0.011*\"south\" + 0.011*\"australian\" + 0.011*\"people\" + 0.009*\"february_february\" + 0.008*\"january_january\"'),\n",
       " (7,\n",
       "  '0.017*\"woman\" + 0.015*\"school\" + 0.015*\"people\" + 0.012*\"university\" + 0.009*\"student\" + 0.009*\"home\" + 0.008*\"coronavirus\" + 0.008*\"social\" + 0.008*\"health\" + 0.008*\"business\"'),\n",
       " (8,\n",
       "  '0.029*\"australia\" + 0.024*\"february\" + 0.017*\"student\" + 0.016*\"january\" + 0.016*\"australian\" + 0.016*\"coronavirus\" + 0.014*\"china\" + 0.012*\"ban\" + 0.011*\"travel\" + 0.009*\"government\"'),\n",
       " (9,\n",
       "  '0.016*\"people\" + 0.014*\"china\" + 0.014*\"coronavirus\" + 0.014*\"wuhan\" + 0.013*\"australia\" + 0.012*\"january\" + 0.012*\"flight\" + 0.011*\"virus\" + 0.011*\"health\" + 0.010*\"passenger\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Topic interpretation\n",
    "\n",
    "- Topic -1: Corona virus outbreak in china\n",
    "- Topic -2: Article about time required in study\n",
    "- Topic -3:  This topic tells about bush fire affecting cimatic change\n",
    "- Topic -4: This is related to disease percent on patients\n",
    "- Topic -5: Corona virus in comparison with SARS\n",
    "- Topic -6: Amount of smoke in australia due to bush fires\n",
    "- Topic -7 : Sales of face masks in australia during january and february\n",
    "- Topic -8: Effect of lockdown on women and students in different sectors\n",
    "- Topic -9: Article about travel ban due to corona virus\n",
    "- Topic -10: Passengers health in january who travelled to australia from china\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perplexity & coherence for both the models\n",
    "\n",
    "Lesser perplexity and higher coherence values tends in giving a better model \n",
    "(https://cfss.uchicago.edu/notes/topic-modeling/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "godSxvIiJSHG",
    "outputId": "d90a97ee-05fe-4fde-ec9f-a9ad347cb4a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 15:00:12,337 : INFO : -6.574 per-word bound, 95.3 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity for model 1:  -6.574336694012011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 15:00:13,842 : INFO : -6.454 per-word bound, 87.7 perplexity estimate based on a held-out corpus of 366 documents with 136440 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity for model 2:  -6.453714072322285\n"
     ]
    }
   ],
   "source": [
    "#Referred from https://tedboy.github.io/nlps/generated/generated/gensim.models.LdaModel.log_perplexity.html\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity for model 1: ', model_1.log_perplexity(process_corpus))\n",
    "print('\\nPerplexity for model 2: ', model_2.log_perplexity(process_corpus))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nS4hW9L5Qapr",
    "outputId": "9e2884d5-605e-4fc3-e0cf-01bca56a86a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 15:00:13,887 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 15:00:33,004 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 15:00:33,039 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 15:00:33,062 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 15:00:33,078 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 15:00:33,101 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 15:00:33,115 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 15:00:35,341 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 15:00:35,376 : INFO : accumulated word occurrence stats for 163918 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score for model 1:  0.46169046744338527\n"
     ]
    }
   ],
   "source": [
    "#Referred from - https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=model_1, texts=process_docs, dictionary=process_dic, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score for model 1: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-08 15:00:35,549 : INFO : using ParallelWordOccurrenceAccumulator(processes=7, batch_size=64) to estimate probabilities from sliding windows\n",
      "2020-05-08 15:00:53,558 : INFO : 1 batches submitted to accumulate stats from 64 documents (20166 virtual)\n",
      "2020-05-08 15:00:53,588 : INFO : 2 batches submitted to accumulate stats from 128 documents (54220 virtual)\n",
      "2020-05-08 15:00:53,614 : INFO : 3 batches submitted to accumulate stats from 192 documents (86400 virtual)\n",
      "2020-05-08 15:00:53,647 : INFO : 4 batches submitted to accumulate stats from 256 documents (111464 virtual)\n",
      "2020-05-08 15:00:53,682 : INFO : 5 batches submitted to accumulate stats from 320 documents (145110 virtual)\n",
      "2020-05-08 15:00:53,699 : INFO : 6 batches submitted to accumulate stats from 384 documents (163861 virtual)\n",
      "2020-05-08 15:00:58,552 : INFO : 7 accumulators retrieved from output queue\n",
      "2020-05-08 15:00:58,601 : INFO : accumulated word occurrence stats for 163918 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score for model 2:  0.48057741777834995\n"
     ]
    }
   ],
   "source": [
    "#Referred from https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=model_2, texts=process_docs, dictionary=process_dic, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score for model 2: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top Topic words of  model 1 (Num-topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "colab_type": "code",
    "id": "AYbkJzubPBDX",
    "outputId": "dc7b32aa-9f17-4ca1-e6c8-01432ab1f351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -0.4158.\n",
      "[([(0.017692477, 'coronavirus'),\n",
      "   (0.01766787, 'february'),\n",
      "   (0.016268795, 'january'),\n",
      "   (0.0155811785, 'australia'),\n",
      "   (0.013353015, 'people'),\n",
      "   (0.012521321, 'virus'),\n",
      "   (0.011600798, 'china'),\n",
      "   (0.009433183, 'case'),\n",
      "   (0.009263308, 'australian'),\n",
      "   (0.008097337, 'health'),\n",
      "   (0.007546989, 'wuhan'),\n",
      "   (0.0065679317, 'chinese'),\n",
      "   (0.0065531796, 'south'),\n",
      "   (0.005301967, 'flight'),\n",
      "   (0.0052828398, 'student'),\n",
      "   (0.0052586757, 'week'),\n",
      "   (0.0052302578, 'confirmed'),\n",
      "   (0.0052273506, 'two'),\n",
      "   (0.0051445467, 'outbreak'),\n",
      "   (0.0048611593, 'mask')],\n",
      "  -0.5001039400640237),\n",
      " ([(0.010294124, 'university'),\n",
      "   (0.0100177, 'australia'),\n",
      "   (0.007908823, 'also'),\n",
      "   (0.007486366, 'area'),\n",
      "   (0.0072398772, 'people'),\n",
      "   (0.0072251493, 'year'),\n",
      "   (0.0068471124, 'say'),\n",
      "   (0.006488074, 'one'),\n",
      "   (0.0062925257, 'fire'),\n",
      "   (0.0061849467, 'could'),\n",
      "   (0.0060765096, 'time'),\n",
      "   (0.006021183, 'australian'),\n",
      "   (0.005939159, 'study'),\n",
      "   (0.005449085, 'woman'),\n",
      "   (0.004628555, 'would'),\n",
      "   (0.004597589, 'first'),\n",
      "   (0.0043302085, 'monash'),\n",
      "   (0.004207551, 'research'),\n",
      "   (0.004132953, 'like'),\n",
      "   (0.004058883, 'day')],\n",
      "  -0.7472893059381456)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model_1.top_topics(process_corpus) \n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / 3\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "#Display the top_topic words\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top Topic words of  model 2 (Num-topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WrdIGxKf2YXZ",
    "outputId": "3c9e4b9d-0f99-43e2-8b2e-e04fedf6a57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.7484.\n",
      "[([(0.043798488, 'february'),\n",
      "   (0.031658143, 'january'),\n",
      "   (0.019270081, 'australia'),\n",
      "   (0.019175407, 'coronavirus'),\n",
      "   (0.011542912, 'mask'),\n",
      "   (0.0112758055, 'south'),\n",
      "   (0.011087607, 'australian'),\n",
      "   (0.011007126, 'people'),\n",
      "   (0.008965964, 'february_february'),\n",
      "   (0.008470614, 'january_january'),\n",
      "   (0.008199743, 'virus'),\n",
      "   (0.007370031, 'case'),\n",
      "   (0.00728053, 'face'),\n",
      "   (0.0070090895, 'aedt'),\n",
      "   (0.0069617718, 'pictured'),\n",
      "   (0.0068755625, 'japan'),\n",
      "   (0.006738485, 'queensland'),\n",
      "   (0.006141372, 'western'),\n",
      "   (0.0059351046, 'one'),\n",
      "   (0.0059303762, 'told')],\n",
      "  -0.39175192083901167),\n",
      " ([(0.01567512, 'people'),\n",
      "   (0.013654446, 'china'),\n",
      "   (0.0135522885, 'coronavirus'),\n",
      "   (0.013541957, 'wuhan'),\n",
      "   (0.013204231, 'australia'),\n",
      "   (0.01226075, 'january'),\n",
      "   (0.011728818, 'flight'),\n",
      "   (0.011455796, 'virus'),\n",
      "   (0.010970281, 'health'),\n",
      "   (0.009840985, 'passenger'),\n",
      "   (0.009349359, 'hospital'),\n",
      "   (0.008793986, 'confirmed'),\n",
      "   (0.008787838, 'australian'),\n",
      "   (0.008401652, 'case'),\n",
      "   (0.007895352, 'melbourne'),\n",
      "   (0.007583699, 'two'),\n",
      "   (0.006930146, 'chinese'),\n",
      "   (0.0065140976, 'sydney'),\n",
      "   (0.0060137673, 'infected'),\n",
      "   (0.0058929385, 'south')],\n",
      "  -0.48445562619642685),\n",
      " ([(0.028837768, 'australia'),\n",
      "   (0.02403559, 'february'),\n",
      "   (0.01707526, 'student'),\n",
      "   (0.016479312, 'january'),\n",
      "   (0.016277673, 'australian'),\n",
      "   (0.015881872, 'coronavirus'),\n",
      "   (0.013965818, 'china'),\n",
      "   (0.011914738, 'ban'),\n",
      "   (0.011380902, 'travel'),\n",
      "   (0.009155416, 'government'),\n",
      "   (0.009106827, 'university'),\n",
      "   (0.0087311, 'health'),\n",
      "   (0.008580939, 'country'),\n",
      "   (0.008498642, 'chinese'),\n",
      "   (0.0084415525, 'minister'),\n",
      "   (0.007702907, 'ship'),\n",
      "   (0.0074016117, 'would'),\n",
      "   (0.0068629985, 'travel_ban'),\n",
      "   (0.006800471, 'week'),\n",
      "   (0.006531306, 'virus')],\n",
      "  -0.6384036612111686),\n",
      " ([(0.016749885, 'woman'),\n",
      "   (0.015436396, 'school'),\n",
      "   (0.01473531, 'people'),\n",
      "   (0.01218684, 'university'),\n",
      "   (0.009492889, 'student'),\n",
      "   (0.00885291, 'home'),\n",
      "   (0.008220825, 'coronavirus'),\n",
      "   (0.008050701, 'social'),\n",
      "   (0.007874604, 'health'),\n",
      "   (0.007767772, 'business'),\n",
      "   (0.0073059914, 'australia'),\n",
      "   (0.0066441395, 'online'),\n",
      "   (0.0064752246, 'child'),\n",
      "   (0.006417583, 'state'),\n",
      "   (0.006277589, 'told'),\n",
      "   (0.006172103, 'week'),\n",
      "   (0.0057029673, 'first'),\n",
      "   (0.0055068824, 'also'),\n",
      "   (0.0053165676, 'class'),\n",
      "   (0.0052448804, 'one')],\n",
      "  -0.7730214901469158),\n",
      " ([(0.03824643, 'virus'),\n",
      "   (0.024636116, 'people'),\n",
      "   (0.022291405, 'coronavirus'),\n",
      "   (0.017611315, 'case'),\n",
      "   (0.013203799, 'symptom'),\n",
      "   (0.012760004, 'spread'),\n",
      "   (0.011837973, 'china'),\n",
      "   (0.010264694, 'outbreak'),\n",
      "   (0.00948637, 'health'),\n",
      "   (0.009314199, 'wuhan'),\n",
      "   (0.008325241, 'animal'),\n",
      "   (0.008096651, 'human'),\n",
      "   (0.007826673, 'disease'),\n",
      "   (0.0076280804, 'patient'),\n",
      "   (0.007614734, 'sars'),\n",
      "   (0.007187028, 'may'),\n",
      "   (0.0065597715, 'illness'),\n",
      "   (0.006436327, 'first'),\n",
      "   (0.006385245, 'cause'),\n",
      "   (0.0060476614, 'two')],\n",
      "  -0.8072107383780971),\n",
      " ([(0.033259157, 'china'),\n",
      "   (0.023373498, 'case'),\n",
      "   (0.021258648, 'coronavirus'),\n",
      "   (0.01549435, 'death'),\n",
      "   (0.013615598, 'chinese'),\n",
      "   (0.012795012, 'wuhan'),\n",
      "   (0.011208031, 'number'),\n",
      "   (0.010095959, 'reuters'),\n",
      "   (0.009515587, 'sars'),\n",
      "   (0.009472404, 'infection'),\n",
      "   (0.00940732, 'saturday'),\n",
      "   (0.009393583, 'outbreak'),\n",
      "   (0.009382903, 'people'),\n",
      "   (0.009356843, 'hong'),\n",
      "   (0.00935449, 'kong'),\n",
      "   (0.009139046, 'hong_kong'),\n",
      "   (0.009060617, 'virus'),\n",
      "   (0.0090573225, 'reported'),\n",
      "   (0.0090148905, 'mainland'),\n",
      "   (0.008935816, 'official')],\n",
      "  -0.8363715963884724),\n",
      " ([(0.016698603, 'university'),\n",
      "   (0.014892571, 'say'),\n",
      "   (0.011589766, 'time'),\n",
      "   (0.011277398, 'one'),\n",
      "   (0.010050414, 'also'),\n",
      "   (0.009997506, 'could'),\n",
      "   (0.008574931, 'year'),\n",
      "   (0.008461216, 'work'),\n",
      "   (0.008386022, 'like'),\n",
      "   (0.00803774, 'research'),\n",
      "   (0.007767406, 'researcher'),\n",
      "   (0.007114559, 'world'),\n",
      "   (0.0070630442, 'make'),\n",
      "   (0.0066355215, 'dr'),\n",
      "   (0.006556129, 'day'),\n",
      "   (0.0065503423, 'first'),\n",
      "   (0.0063709007, 'way'),\n",
      "   (0.0063698366, 'get'),\n",
      "   (0.0062392433, 'many'),\n",
      "   (0.0056663356, 'scientist')],\n",
      "  -0.8571541778468785),\n",
      " ([(0.03232447, 'fire'),\n",
      "   (0.024260001, 'australia'),\n",
      "   (0.014505097, 'year'),\n",
      "   (0.01303941, 'bushfires'),\n",
      "   (0.012627309, 'south'),\n",
      "   (0.010386135, 'climate'),\n",
      "   (0.009869723, 'people'),\n",
      "   (0.008031927, 'million'),\n",
      "   (0.0076134037, 'country'),\n",
      "   (0.007513342, 'bushfire'),\n",
      "   (0.006666417, 'month'),\n",
      "   (0.0065788156, 'january'),\n",
      "   (0.0063229213, 'victoria'),\n",
      "   (0.0063146213, 'wale'),\n",
      "   (0.006301747, 'new_south'),\n",
      "   (0.006293658, 'australian'),\n",
      "   (0.006236177, 'weather'),\n",
      "   (0.0061880993, 'smoke'),\n",
      "   (0.00597493, 'aedt'),\n",
      "   (0.005719505, 'council')],\n",
      "  -1.071272321265662),\n",
      " ([(0.03661561, 'patient'),\n",
      "   (0.021782352, 'study'),\n",
      "   (0.01683378, 'mass'),\n",
      "   (0.015149722, 'per'),\n",
      "   (0.014607539, 'disease'),\n",
      "   (0.014009199, 'per_cent'),\n",
      "   (0.01393279, 'cent'),\n",
      "   (0.01386325, 'level'),\n",
      "   (0.013718864, 'test'),\n",
      "   (0.013465951, 'also'),\n",
      "   (0.012201575, 'would'),\n",
      "   (0.011941916, 'woman'),\n",
      "   (0.011509958, 'normal'),\n",
      "   (0.009316579, 'analysis'),\n",
      "   (0.008740092, 'hospital'),\n",
      "   (0.008675554, 'group'),\n",
      "   (0.008577548, 'health'),\n",
      "   (0.008566259, 'amp'),\n",
      "   (0.007760877, 'using'),\n",
      "   (0.0075254664, 'may')],\n",
      "  -1.2197709539100565),\n",
      " ([(0.027556133, 'area'),\n",
      "   (0.013609935, 'cell'),\n",
      "   (0.01257834, 'australian'),\n",
      "   (0.01235154, 'australia'),\n",
      "   (0.011930068, 'smoke'),\n",
      "   (0.011521787, 'air'),\n",
      "   (0.010770753, 'data'),\n",
      "   (0.008952824, 'change'),\n",
      "   (0.00809647, 'specie'),\n",
      "   (0.008077425, 'climate'),\n",
      "   (0.0071763904, 'based'),\n",
      "   (0.007144745, 'also'),\n",
      "   (0.0066704573, 'climate_change'),\n",
      "   (0.006305626, 'analysis'),\n",
      "   (0.006139379, 'well'),\n",
      "   (0.006020347, 'quality'),\n",
      "   (0.0058007194, 'open'),\n",
      "   (0.0056880615, 'melbourne'),\n",
      "   (0.0056671994, 'health'),\n",
      "   (0.0054835742, 'study')],\n",
      "  -1.662811458443619)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model_2.top_topics(process_corpus)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / 5\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "#display the top topic words\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCES \n",
    "All the topics are not related to Monash University. The topics are easily comprehensible and it is easily relatable to the article based on the top topic words. These topic words which has university or monash suggests us that those topics are either directly or indirectly to the Monash University.Based on our 2 models, Monash University is related to Bushfire,climate studies and coronavirus’travel ban affecting the students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "colab_type": "code",
    "id": "BZ062d7cJMvW",
    "outputId": "1ab7171a-ecf9-4584-d2a2-5af244d1eaaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el4074019323846925529451914640\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el4074019323846925529451914640_data = {\"mdsDat\": {\"x\": [0.10218849033117293, -0.10218849033117293], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [65.54810333251953, 34.451900482177734]}, \"tinfo\": {\"Term\": [\"coronavirus\", \"february\", \"virus\", \"january\", \"china\", \"fire\", \"university\", \"area\", \"wuhan\", \"study\", \"chinese\", \"say\", \"research\", \"climate\", \"smoke\", \"monash\", \"outbreak\", \"cell\", \"change\", \"also\", \"ship\", \"time\", \"confirmed\", \"researcher\", \"flight\", \"monash_university\", \"year\", \"could\", \"infected\", \"january_january\", \"wuhan\", \"january_january\", \"february_february\", \"cruise_ship\", \"ship\", \"diamond_princess\", \"mainland\", \"christmas\", \"confirmed_case\", \"christmas_island\", \"hubei\", \"chinese\", \"february_queensland\", \"australia_february\", \"february_western\", \"january_victoria\", \"mainland_china\", \"epicentre\", \"province\", \"quarantined\", \"hubei_province\", \"tested_positive\", \"january_february\", \"cruise\", \"gold_coast\", \"travel_ban\", \"outbreak\", \"sars\", \"face_mask\", \"evacuee\", \"virus\", \"coronavirus\", \"infected\", \"china\", \"february\", \"japan\", \"ban\", \"confirmed\", \"princess\", \"diamond\", \"january\", \"flight\", \"passenger\", \"mask\", \"queensland\", \"quarantine\", \"pictured\", \"case\", \"travel\", \"deadly\", \"student\", \"hospital\", \"man\", \"symptom\", \"people\", \"australia\", \"health\", \"spread\", \"south\", \"australian\", \"sydney\", \"week\", \"two\", \"told\", \"one\", \"day\", \"climate\", \"cell\", \"smoke\", \"climate_change\", \"analysis\", \"material\", \"author\", \"fire\", \"ai\", \"research\", \"model\", \"blaze\", \"project\", \"athe\", \"history\", \"researcher\", \"science\", \"air_quality\", \"add\", \"produced\", \"challenge\", \"quality\", \"australiaas\", \"heat\", \"annual\", \"weather\", \"ait\", \"specie\", \"average\", \"awe\", \"technology\", \"season\", \"monash_university\", \"bushfires\", \"mass\", \"study\", \"change\", \"data\", \"area\", \"monash\", \"using\", \"open\", \"scientist\", \"found\", \"university\", \"say\", \"used\", \"car\", \"work\", \"time\", \"also\", \"could\", \"year\", \"professor\", \"woman\", \"one\", \"like\", \"australia\", \"much\", \"first\", \"air\", \"many\", \"people\", \"australian\", \"would\", \"may\", \"patient\", \"day\", \"health\"], \"Freq\": [1616.0, 1617.0, 1129.0, 1513.0, 1056.0, 298.0, 723.0, 425.0, 675.0, 307.0, 589.0, 459.0, 199.0, 185.0, 176.0, 237.0, 462.0, 162.0, 209.0, 700.0, 422.0, 473.0, 474.0, 147.0, 482.0, 161.0, 663.0, 523.0, 381.0, 338.0, 674.9552001953125, 338.1707458496094, 308.4143981933594, 223.3060302734375, 420.8234558105469, 188.6488800048828, 166.87681579589844, 161.93768310546875, 188.58810424804688, 158.9581756591797, 164.86917114257812, 587.39453125, 154.9650421142578, 154.94627380371094, 152.96923828125, 152.9563751220703, 136.17930603027344, 136.1663360595703, 153.85928344726562, 126.23466491699219, 106.4645004272461, 129.1219482421875, 154.73974609375, 330.0994567871094, 91.61951446533203, 132.01312255859375, 460.0959167480469, 149.73716735839844, 164.47926330566406, 110.28473663330078, 1119.8282470703125, 1582.3038330078125, 378.6358947753906, 1037.50244140625, 1580.1031494140625, 369.905517578125, 240.985595703125, 467.7613525390625, 232.0834197998047, 215.23394775390625, 1454.978759765625, 474.174560546875, 409.55816650390625, 434.75152587890625, 376.0964660644531, 239.2659912109375, 377.48626708984375, 843.64453125, 347.6266174316406, 232.48614501953125, 472.4639587402344, 379.0892639160156, 248.828857421875, 293.97064208984375, 1194.209716796875, 1393.482666015625, 724.1748657226562, 348.7264099121094, 586.0751953125, 828.4519653320312, 405.5393371582031, 470.3028869628906, 467.5013732910156, 376.50189208984375, 433.9328308105469, 399.58270263671875, 184.56484985351562, 161.81182861328125, 175.55287170410156, 108.35974884033203, 121.11438751220703, 84.54779815673828, 73.72638702392578, 295.7871398925781, 65.63746643066406, 197.7805938720703, 49.928104400634766, 37.07917022705078, 34.14060974121094, 64.26949310302734, 54.435546875, 144.68760681152344, 64.94181823730469, 61.028377532958984, 26.1060848236084, 26.093151092529297, 36.616878509521484, 90.5637435913086, 55.755958557128906, 47.94630432128906, 24.884784698486328, 80.27648162841797, 26.691865921020508, 109.99983215332031, 62.34697723388672, 24.543359756469727, 93.04806518554688, 78.09607696533203, 150.60340881347656, 126.84054565429688, 102.26834869384766, 279.1767272949219, 186.36444091796875, 150.14540100097656, 351.9049072265625, 203.54623413085938, 126.01494598388672, 122.67371368408203, 130.314453125, 136.53363037109375, 483.88665771484375, 321.8560791015625, 130.6609344482422, 90.7013168334961, 190.7402801513672, 285.633056640625, 371.7629699707031, 290.7302551269531, 339.6261291503906, 158.51824951171875, 256.1402587890625, 304.9790954589844, 194.27401733398438, 470.8930358886719, 146.31576538085938, 216.11474609375, 160.11465454101562, 175.8970947265625, 340.31842041015625, 283.0323486328125, 217.57034301757812, 178.5616912841797, 186.7380828857422, 190.7922821044922, 172.38375854492188], \"Total\": [1616.0, 1617.0, 1129.0, 1513.0, 1056.0, 298.0, 723.0, 425.0, 675.0, 307.0, 589.0, 459.0, 199.0, 185.0, 176.0, 237.0, 462.0, 162.0, 209.0, 700.0, 422.0, 473.0, 474.0, 147.0, 482.0, 161.0, 663.0, 523.0, 381.0, 338.0, 675.7401123046875, 338.85504150390625, 309.1297607421875, 223.91790771484375, 422.0842590332031, 189.23863220214844, 167.4401397705078, 162.48634338378906, 189.23797607421875, 159.51377868652344, 165.45831298828125, 589.5346069335938, 155.5498504638672, 155.54981994628906, 153.5681610107422, 153.5681610107422, 136.7241973876953, 136.7240447998047, 154.5583038330078, 126.81554412841797, 106.99913024902344, 129.78750610351562, 155.54879760742188, 331.9152526855469, 92.1366958618164, 132.75949096679688, 462.7052917480469, 150.5936279296875, 165.45692443847656, 110.96190643310547, 1129.53466796875, 1616.0167236328125, 381.4564208984375, 1056.2039794921875, 1617.0052490234375, 373.5286560058594, 242.74053955078125, 474.5912170410156, 233.82192993164062, 216.97776794433594, 1513.93994140625, 482.51678466796875, 420.091796875, 452.7834167480469, 393.333740234375, 244.71820068359375, 396.305419921875, 940.2144165039062, 367.5699157714844, 238.77149963378906, 521.1271362304688, 413.13726806640625, 257.5953369140625, 311.09393310546875, 1534.528076171875, 1864.375732421875, 896.55859375, 382.4215087890625, 724.1793212890625, 1111.484375, 469.5914306640625, 582.5094604492188, 626.0703125, 465.608642578125, 738.9119262695312, 590.375, 185.13735961914062, 162.36546325683594, 176.2247314453125, 108.90210723876953, 121.77137756347656, 85.13878631591797, 74.24935150146484, 298.00006103515625, 66.32706451416016, 199.9827880859375, 50.48607635498047, 37.61592102050781, 34.64699172973633, 65.33525848388672, 55.43424987792969, 147.50961303710938, 66.32471466064453, 62.363487243652344, 26.72339630126953, 26.72315216064453, 37.61296463012695, 93.05440521240234, 57.4105110168457, 49.493377685546875, 25.73164939880371, 83.15482330322266, 27.711013793945312, 114.83763122558594, 65.3312759399414, 25.730304718017578, 98.00575256347656, 82.1657485961914, 161.37437438964844, 135.6308135986328, 108.89839935302734, 307.91845703125, 209.89710998535156, 168.30967712402344, 425.77044677734375, 237.6272430419922, 140.58511352539062, 136.62498474121094, 148.50904846191406, 157.42178344726562, 723.910400390625, 459.4824523925781, 155.4439697265625, 98.99714660644531, 263.39849853515625, 473.38232421875, 700.2171630859375, 523.9110717773438, 663.5811767578125, 215.86373901367188, 479.3502197265625, 738.9119262695312, 330.77264404296875, 1864.375732421875, 196.0562744140625, 469.47296142578125, 240.6328582763672, 306.0159912109375, 1534.528076171875, 1111.484375, 566.5740966796875, 342.6749267578125, 449.6790771484375, 590.375, 896.55859375], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.886600017547607, -5.577700138092041, -5.6697998046875, -5.992700099945068, -5.359000205993652, -6.161399841308594, -6.283999919891357, -6.314000129699707, -6.1616997718811035, -6.332600116729736, -6.29610013961792, -5.025599956512451, -6.358099937438965, -6.3582000732421875, -6.370999813079834, -6.371099948883057, -6.487299919128418, -6.487400054931641, -6.365200042724609, -6.5630998611450195, -6.733399868011475, -6.540500164031982, -6.359499931335449, -5.601900100708008, -6.883600234985352, -6.518400192260742, -5.269800186157227, -6.392399787902832, -6.298500061035156, -6.698200225830078, -4.380300045013428, -4.034599781036377, -5.464700222015381, -4.456699848175049, -4.035999774932861, -5.48799991607666, -5.916500091552734, -5.253300189971924, -5.95419979095459, -6.0295000076293945, -4.118500232696533, -5.239699840545654, -5.386199951171875, -5.326499938964844, -5.471399784088135, -5.923699855804443, -5.467700004577637, -4.66349983215332, -5.550099849700928, -5.952400207519531, -5.243299961090088, -5.463500022888184, -5.884500026702881, -5.717800140380859, -4.315999984741211, -4.1616997718811035, -4.816199779510498, -5.546999931335449, -5.0278000831604, -4.681700229644775, -5.395999908447266, -5.247900009155273, -5.253900051116943, -5.470300197601318, -5.328400135040283, -5.410799980163574, -5.539999961853027, -5.671599864959717, -5.590099811553955, -6.0725998878479, -5.961299896240234, -6.320700168609619, -6.457699775695801, -5.068399906158447, -6.57390022277832, -5.470900058746338, -6.847400188446045, -7.144999980926514, -7.227499961853027, -6.594900131225586, -6.761000156402588, -5.7835001945495605, -6.584499835968018, -6.646699905395508, -7.4959001541137695, -7.496399879455566, -7.15749979019165, -6.251999855041504, -6.736999988555908, -6.888000011444092, -7.543799877166748, -6.372600078582764, -7.473700046539307, -6.057600021362305, -6.62529993057251, -7.557600021362305, -6.224899768829346, -6.400100231170654, -5.7434000968933105, -5.91510009765625, -6.13040018081665, -5.126200199127197, -5.530300140380859, -5.746399879455566, -4.894700050354004, -5.4421000480651855, -5.921599864959717, -5.948500156402588, -5.8881001472473145, -5.8414998054504395, -4.576200008392334, -4.98390007019043, -5.88539981842041, -6.250500202178955, -5.5071001052856445, -5.103300094604492, -4.839799880981445, -5.085599899291992, -4.930200099945068, -5.692200183868408, -5.212299823760986, -5.037799835205078, -5.488800048828125, -4.603400230407715, -5.772299766540527, -5.382199764251709, -5.68209981918335, -5.588099956512451, -4.928199768066406, -5.112500190734863, -5.375500202178955, -5.5731000900268555, -5.528299808502197, -5.506800174713135, -5.60830020904541], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4212000072002411, 0.4203999936580658, 0.42010000348091125, 0.4196000099182129, 0.41940000653266907, 0.41929998993873596, 0.4189999997615814, 0.4189999997615814, 0.4189000129699707, 0.4189000129699707, 0.4187999963760376, 0.4187000095844269, 0.4185999929904938, 0.41850000619888306, 0.41850000619888306, 0.41839998960494995, 0.41839998960494995, 0.41830000281333923, 0.4178999960422516, 0.41780000925064087, 0.4174000024795532, 0.4171999990940094, 0.4171999990940094, 0.41690000891685486, 0.41679999232292175, 0.41670000553131104, 0.41670000553131104, 0.41670000553131104, 0.4165000021457672, 0.4162999987602234, 0.4138000011444092, 0.40130001306533813, 0.41499999165534973, 0.40450000762939453, 0.3993000090122223, 0.41260001063346863, 0.41510000824928284, 0.40790000557899475, 0.414900004863739, 0.41429999470710754, 0.38269999623298645, 0.4049000144004822, 0.3970000147819519, 0.3817000091075897, 0.3776000142097473, 0.39989998936653137, 0.37369999289512634, 0.3140000104904175, 0.36660000681877136, 0.39570000767707825, 0.32440000772476196, 0.33640000224113464, 0.387800008058548, 0.36579999327659607, 0.17159999907016754, 0.13130000233650208, 0.20890000462532043, 0.3301999866962433, 0.21080000698566437, 0.12849999964237213, 0.27570000290870667, 0.20839999616146088, 0.13030000030994415, 0.20999999344348907, -0.10989999771118164, 0.03200000151991844, 1.0625, 1.0621999502182007, 1.0618000030517578, 1.0606000423431396, 1.0601999759674072, 1.0585999488830566, 1.058500051498413, 1.0582000017166138, 1.0551999807357788, 1.0544999837875366, 1.0544999837875366, 1.051200032234192, 1.0508999824523926, 1.0492000579833984, 1.0473999977111816, 1.0463000535964966, 1.0444999933242798, 1.0440000295639038, 1.042199969291687, 1.041700005531311, 1.0388000011444092, 1.0384999513626099, 1.0363999605178833, 1.0338000059127808, 1.032099962234497, 1.030400037765503, 1.0281000137329102, 1.0226000547409058, 1.0189000368118286, 1.018399953842163, 1.013700008392334, 1.014799952507019, 0.9965000152587891, 0.9986000061035156, 1.0027999877929688, 0.9675999879837036, 0.9466999769210815, 0.9513999819755554, 0.8751000165939331, 0.9107999801635742, 0.9562000036239624, 0.9578999876976013, 0.9348999857902527, 0.9232000112533569, 0.6628000140190125, 0.7095999717712402, 0.8919000029563904, 0.9781000018119812, 0.742900013923645, 0.5604000091552734, 0.4325000047683716, 0.4767000079154968, 0.39579999446868896, 0.7567999958992004, 0.4388999938964844, 0.18070000410079956, 0.5333999991416931, -0.31040000915527344, 0.7730000019073486, 0.2897999882698059, 0.6582000255584717, 0.511900007724762, -0.4404999911785126, -0.30230000615119934, 0.10849999636411667, 0.4138000011444092, 0.1868000030517578, -0.06400000303983688, -0.5831999778747559]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.03742039203643799, 0.9729302525520325, 0.015076802112162113, 0.9950689077377319, 0.33661237359046936, 0.6649133563041687, 0.01603502407670021, 0.978136420249939, 0.036086734384298325, 0.9743418097496033, 0.4684261083602905, 0.5312637686729431, 0.00821211002767086, 0.993665337562561, 0.038862645626068115, 0.9715661406517029, 0.17380256950855255, 0.826736569404602, 0.015305671840906143, 0.9795629978179932, 0.7471669912338257, 0.2526314854621887, 0.9964653253555298, 0.006428808439522982, 0.03483682498335838, 0.9754311442375183, 0.7449497580528259, 0.2546144723892212, 0.013468131422996521, 0.9966416954994202, 0.045919813215732574, 0.9490094780921936, 0.03886467590928078, 0.9716169238090515, 0.9928296208381653, 0.00823924969881773, 0.026584487408399582, 0.9836260676383972, 0.0663565993309021, 0.9363653659820557, 0.08081041276454926, 0.9192184209823608, 0.8976675868034363, 0.10316795855760574, 0.0061589451506733894, 0.9977491497993469, 0.02658657729625702, 0.9837033748626709, 0.11434173583984375, 0.8861484527587891, 0.982764720916748, 0.01798895001411438, 0.9957006573677063, 0.0033925066236406565, 0.997006893157959, 0.006154363509267569, 0.9967790842056274, 0.006269050762057304, 0.005401394795626402, 0.9992580413818359, 0.00918255839496851, 0.9917163252830505, 0.9861118197441101, 0.014749535359442234, 0.9987424612045288, 0.005284351762384176, 0.9789502620697021, 0.021039385348558426, 0.4447319507598877, 0.5554378032684326, 0.9942296743392944, 0.006025634706020355, 0.9959006905555725, 0.004465922247618437, 0.10694572329521179, 0.8912143707275391, 0.6775354743003845, 0.3235231935977936, 0.9716402292251587, 0.025128627195954323, 0.9908849000930786, 0.009217534214258194, 0.9987390041351318, 0.005284333135932684, 0.9947043061256409, 0.0073140026070177555, 0.9913312196731567, 0.009012102149426937, 0.9911945462226868, 0.006043869070708752, 0.9771149754524231, 0.022881805896759033, 0.9963453412055969, 0.00323488749563694, 0.9964651465415955, 0.00642880704253912, 0.9963002800941467, 0.006511766463518143, 0.006711408030241728, 0.9932883977890015, 0.5389021635055542, 0.46009039878845215, 0.9823492765426636, 0.016579734161496162, 0.1333995759487152, 0.8702734708786011, 0.9985163807868958, 0.010853438638150692, 0.8075322508811951, 0.19184468686580658, 0.04040944576263428, 0.9698266983032227, 0.018039388582110405, 0.9741269946098328, 0.917370617389679, 0.08229710161685944, 0.997230052947998, 0.006043818313628435, 0.9906622767448425, 0.009345870465040207, 0.9935604333877563, 0.007864594459533691, 0.9610685110092163, 0.03897116333246231, 0.9964718818664551, 0.006428850814700127, 0.9974766969680786, 0.0029511144384741783, 0.9963002800941467, 0.006511766463518143, 0.9905532002449036, 0.010708683170378208, 0.41115856170654297, 0.5865055918693542, 0.9973713755607605, 0.00597228342667222, 0.9947032332420349, 0.007313994225114584, 0.9666324257850647, 0.034938521683216095, 0.4248144030570984, 0.5751333236694336, 0.9607242345809937, 0.03975410759449005, 0.06428010016679764, 0.9366528987884521, 0.011745528317987919, 0.9983698725700378, 0.47858768701553345, 0.5223609209060669, 0.019807441160082817, 0.9903720617294312, 0.14308123290538788, 0.8584874272346497, 0.06816447526216507, 0.9357123970985413, 0.2550288140773773, 0.7446841597557068, 0.5873501300811768, 0.412769079208374, 0.1024702787399292, 0.9002745747566223, 0.9941533207893372, 0.006483608391135931, 0.9759771823883057, 0.026184752583503723, 0.5848615169525146, 0.4158521294593811, 0.7780894041061401, 0.22156648337841034, 0.9512864947319031, 0.04794282093644142, 0.9922080636024475, 0.0085535179823637, 0.03742073476314545, 0.972939133644104, 0.264055460691452, 0.7365757822990417, 0.02886253409087658, 0.981326162815094, 0.9963877201080322, 0.006470050197094679, 0.02149280346930027, 0.9779225587844849, 0.9766335487365723, 0.02043166384100914, 0.9935690760612488, 0.007885469123721123, 0.9559311866760254, 0.043220292776823044, 0.010000860318541527, 0.9900851845741272, 0.020337658002972603, 0.9829868078231812, 0.9960581064224243, 0.006640387233346701, 0.30033791065216064, 0.7007884383201599, 0.015077335759997368, 0.9800268411636353, 0.12120473384857178, 0.8753675222396851, 0.048682086169719696, 0.9493006467819214, 0.9974311590194702, 0.0023691952228546143, 0.005674572195857763, 0.9987247586250305, 0.8091918230056763, 0.19056053459644318, 0.04353973641991615, 0.9578741788864136, 0.9126055836677551, 0.08890713006258011, 0.9057290554046631, 0.09402696043252945, 0.09418077766895294, 0.9060840606689453, 0.8645813465118408, 0.13628868758678436, 0.9450522065162659, 0.05464587360620499, 0.05101741477847099, 0.9489238858222961, 0.9939323663711548, 0.007704901974648237, 0.3971419930458069, 0.6041628122329712, 0.8096928596496582, 0.19114765524864197, 0.9467586278915405, 0.05441141873598099, 0.9942792057991028, 0.007532418239861727, 0.747519850730896, 0.2539650797843933, 0.331532746553421, 0.6685910224914551, 0.16082964837551117, 0.8427473902702332, 0.10669693350791931, 0.8962541818618774, 0.9915587902069092, 0.008853203617036343, 0.03607728332281113, 0.9620608687400818, 0.8068538308143616, 0.19227156043052673, 0.4652130901813507, 0.5340563058853149, 0.2771466076374054, 0.7251369953155518, 0.6159829497337341, 0.3847687244415283, 0.9989047646522522, 0.0014798588817939162, 0.48825979232788086, 0.5123713612556458], \"Term\": [\"add\", \"add\", \"ai\", \"ai\", \"air\", \"air\", \"air_quality\", \"air_quality\", \"ait\", \"ait\", \"also\", \"also\", \"analysis\", \"analysis\", \"annual\", \"annual\", \"area\", \"area\", \"athe\", \"athe\", \"australia\", \"australia\", \"australia_february\", \"australia_february\", \"australiaas\", \"australiaas\", \"australian\", \"australian\", \"author\", \"author\", \"average\", \"average\", \"awe\", \"awe\", \"ban\", \"ban\", \"blaze\", \"blaze\", \"bushfires\", \"bushfires\", \"car\", \"car\", \"case\", \"case\", \"cell\", \"cell\", \"challenge\", \"challenge\", \"change\", \"change\", \"china\", \"china\", \"chinese\", \"chinese\", \"christmas\", \"christmas\", \"christmas_island\", \"christmas_island\", \"climate\", \"climate\", \"climate_change\", \"climate_change\", \"confirmed\", \"confirmed\", \"confirmed_case\", \"confirmed_case\", \"coronavirus\", \"coronavirus\", \"could\", \"could\", \"cruise\", \"cruise\", \"cruise_ship\", \"cruise_ship\", \"data\", \"data\", \"day\", \"day\", \"deadly\", \"deadly\", \"diamond\", \"diamond\", \"diamond_princess\", \"diamond_princess\", \"epicentre\", \"epicentre\", \"evacuee\", \"evacuee\", \"face_mask\", \"face_mask\", \"february\", \"february\", \"february_february\", \"february_february\", \"february_queensland\", \"february_queensland\", \"february_western\", \"february_western\", \"fire\", \"fire\", \"first\", \"first\", \"flight\", \"flight\", \"found\", \"found\", \"gold_coast\", \"gold_coast\", \"health\", \"health\", \"heat\", \"heat\", \"history\", \"history\", \"hospital\", \"hospital\", \"hubei\", \"hubei\", \"hubei_province\", \"hubei_province\", \"infected\", \"infected\", \"january\", \"january\", \"january_february\", \"january_february\", \"january_january\", \"january_january\", \"january_victoria\", \"january_victoria\", \"japan\", \"japan\", \"like\", \"like\", \"mainland\", \"mainland\", \"mainland_china\", \"mainland_china\", \"man\", \"man\", \"many\", \"many\", \"mask\", \"mask\", \"mass\", \"mass\", \"material\", \"material\", \"may\", \"may\", \"model\", \"model\", \"monash\", \"monash\", \"monash_university\", \"monash_university\", \"much\", \"much\", \"one\", \"one\", \"open\", \"open\", \"outbreak\", \"outbreak\", \"passenger\", \"passenger\", \"patient\", \"patient\", \"people\", \"people\", \"pictured\", \"pictured\", \"princess\", \"princess\", \"produced\", \"produced\", \"professor\", \"professor\", \"project\", \"project\", \"province\", \"province\", \"quality\", \"quality\", \"quarantine\", \"quarantine\", \"quarantined\", \"quarantined\", \"queensland\", \"queensland\", \"research\", \"research\", \"researcher\", \"researcher\", \"sars\", \"sars\", \"say\", \"say\", \"science\", \"science\", \"scientist\", \"scientist\", \"season\", \"season\", \"ship\", \"ship\", \"smoke\", \"smoke\", \"south\", \"south\", \"specie\", \"specie\", \"spread\", \"spread\", \"student\", \"student\", \"study\", \"study\", \"sydney\", \"sydney\", \"symptom\", \"symptom\", \"technology\", \"technology\", \"tested_positive\", \"tested_positive\", \"time\", \"time\", \"told\", \"told\", \"travel\", \"travel\", \"travel_ban\", \"travel_ban\", \"two\", \"two\", \"university\", \"university\", \"used\", \"used\", \"using\", \"using\", \"virus\", \"virus\", \"weather\", \"weather\", \"week\", \"week\", \"woman\", \"woman\", \"work\", \"work\", \"would\", \"would\", \"wuhan\", \"wuhan\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el4074019323846925529451914640\", ldavis_el4074019323846925529451914640_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el4074019323846925529451914640\", ldavis_el4074019323846925529451914640_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el4074019323846925529451914640\", ldavis_el4074019323846925529451914640_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot a graph to display the intertopic distance and the most relevant terms present in the topics\n",
    "lda_display = pyLDAvis.gensim.prepare(model_1, process_corpus, process_dic, sort_topics=True)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "colab_type": "code",
    "id": "7CET43ni2ouB",
    "outputId": "450f9651-3886-4255-81fe-ca4ec493a3b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el4074019323846922964471662361\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el4074019323846922964471662361_data = {\"mdsDat\": {\"x\": [-0.13541583985183753, -0.10491454227223948, -0.10970996504667893, 0.1631273613388875, 0.02905591318610987, -0.04517131587104011, 0.19123951765772984, 0.09346164948550942, 0.09185729979750051, -0.17353007842394086], \"y\": [-0.017198306546028053, -0.10697110366728127, -0.07875581974328691, -0.005214338171752292, -0.07820064966605304, 0.13761613733725503, 0.028400480870723402, -0.13802655635370661, 0.14864108173425306, 0.10970907420587649], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [20.273149490356445, 17.709941864013672, 13.029866218566895, 10.218719482421875, 9.63489818572998, 8.261886596679688, 7.127106189727783, 6.285569190979004, 3.9269189834594727, 3.5319461822509766]}, \"tinfo\": {\"Term\": [\"february\", \"china\", \"virus\", \"patient\", \"coronavirus\", \"fire\", \"january\", \"case\", \"area\", \"wuhan\", \"australia\", \"woman\", \"student\", \"study\", \"chinese\", \"disease\", \"outbreak\", \"symptom\", \"per\", \"university\", \"ban\", \"ship\", \"school\", \"death\", \"cent\", \"test\", \"per_cent\", \"smoke\", \"people\", \"february_february\", \"say_unless\", \"raised_travel\", \"alert_level\", \"contact_someone\", \"flew\", \"victoria_january\", \"sydney_airport\", \"murphy_said\", \"evacuate\", \"gold_coast\", \"test_result\", \"officer_dr\", \"royal_melbourne\", \"diagnosed_coronavirus\", \"carrying\", \"charter\", \"officer_brendan\", \"epicentre_outbreak\", \"woman_aged\", \"plane\", \"family_member\", \"including_three\", \"unwell\", \"murphy\", \"sa\", \"department_foreign\", \"chinese_authority\", \"airline\", \"isolated\", \"nsw_health\", \"isolation\", \"diagnosed\", \"gold\", \"hubei_province\", \"flight\", \"passenger\", \"hospital\", \"wuhan\", \"man\", \"airport\", \"year_old\", \"confirmed\", \"old\", \"nsw\", \"melbourne\", \"tested\", \"authority\", \"coast\", \"arrived\", \"china\", \"province\", \"health\", \"infected\", \"people\", \"hubei\", \"virus\", \"sydney\", \"coronavirus\", \"two\", \"island\", \"january\", \"australia\", \"chinese\", \"medical\", \"symptom\", \"case\", \"australian\", \"day\", \"patient\", \"south\", \"city\", \"one\", \"week\", \"shelf\", \"japan_advertisement\", \"wearing_mask\", \"qantas_flight\", \"stock\", \"face_mask\", \"store\", \"posted\", \"empty\", \"facebook\", \"claim\", \"february_western\", \"january_victoria\", \"february_updated\", \"aedt_february\", \"sold\", \"australia_february\", \"january_february\", \"february_queensland\", \"february_february\", \"wale_january\", \"chain\", \"february\", \"customer\", \"contacted\", \"hand\", \"mask\", \"contracting\", \"cabin\", \"spring\", \"supply\", \"january_january\", \"qantas\", \"january\", \"western\", \"aedt\", \"face\", \"south_australia\", \"food\", \"advertisement\", \"published_aedt\", \"south\", \"japan\", \"coronavirus\", \"pictured\", \"australia\", \"queensland\", \"mr\", \"australian\", \"cruise\", \"people\", \"victoria\", \"told\", \"virus\", \"case\", \"outbreak\", \"one\", \"ship\", \"chinese\", \"new_south\", \"wale\", \"travel_ban\", \"medical_advice\", \"ban\", \"chinese_student\", \"extended\", \"greg_hunt\", \"semester\", \"indonesia\", \"greg\", \"hunt\", \"temporary\", \"yokohama_japan\", \"entering\", \"home_affair\", \"enter\", \"student\", \"scott_morrison\", \"travel\", \"basis\", \"accommodation\", \"arrival\", \"pandemic\", \"australian_government\", \"scott\", \"upon\", \"traveller\", \"priority\", \"health_minister\", \"prime_minister\", \"committee\", \"minister\", \"morrison\", \"foreign\", \"prime\", \"education\", \"cruise_ship\", \"australia\", \"mainland_china\", \"february\", \"government\", \"country\", \"australian\", \"ship\", \"cruise\", \"china\", \"january\", \"coronavirus\", \"chinese\", \"diamond\", \"university\", \"diamond_princess\", \"would\", \"health\", \"international\", \"week\", \"february_february\", \"pictured\", \"told\", \"medical\", \"virus\", \"south\", \"people\", \"case\", \"created\", \"ai\", \"donat\", \"york\", \"science\", \"material\", \"light\", \"technology\", \"researcher\", \"water\", \"led\", \"feel\", \"ait\", \"letter\", \"awe\", \"athe\", \"create\", \"phone\", \"add\", \"natural\", \"history\", \"london\", \"itas\", \"discovered\", \"senior\", \"real\", \"thought\", \"stress\", \"faster\", \"research\", \"body\", \"scientist\", \"team\", \"say\", \"work\", \"think\", \"find\", \"make\", \"university\", \"way\", \"time\", \"like\", \"monash_university\", \"could\", \"right\", \"help\", \"dr\", \"one\", \"also\", \"world\", \"get\", \"many\", \"year\", \"back\", \"monash\", \"first\", \"day\", \"u\", \"professor\", \"people\", \"would\", \"two\", \"distancing\", \"learning\", \"class\", \"police\", \"school\", \"shut\", \"online\", \"rule\", \"essential\", \"social\", \"closing\", \"self\", \"personal\", \"business\", \"stay_home\", \"busy\", \"restaurant\", \"daughter\", \"education\", \"close\", \"vulnerable\", \"eventually\", \"worker\", \"limit\", \"open\", \"law\", \"woman\", \"premier\", \"sense\", \"leave\", \"restriction\", \"community\", \"child\", \"parent\", \"march\", \"home\", \"covid\", \"university\", \"student\", \"service\", \"staff\", \"state\", \"people\", \"work\", \"told\", \"health\", \"week\", \"first\", \"coronavirus\", \"australia\", \"go\", \"also\", \"one\", \"would\", \"government\", \"could\", \"year\", \"common_cold\", \"respiratory_syndrome\", \"untreated\", \"syndrome\", \"cold\", \"stop_spread\", \"seem\", \"mild\", \"pneumonia\", \"severe_acute\", \"cough\", \"catch\", \"flu\", \"sars\", \"fatal\", \"typical\", \"illness\", \"fever\", \"fever_cough\", \"fatality\", \"nose\", \"acute\", \"breathe\", \"sore\", \"sore_throat\", \"animal\", \"fluid\", \"uk\", \"breath\", \"cause\", \"symptom\", \"virus\", \"type\", \"spread\", \"human\", \"respiratory\", \"common\", \"market\", \"case\", \"people\", \"outbreak\", \"severe\", \"coronavirus\", \"disease\", \"may\", \"infection\", \"china\", \"patient\", \"wuhan\", \"expert\", \"health\", \"around\", \"first\", \"world\", \"infected\", \"two\", \"one\", \"dr\", \"confirmed\", \"link\", \"cell\", \"australiaas\", \"air_quality\", \"network\", \"location\", \"specie\", \"smoke\", \"heat\", \"author\", \"area\", \"quality\", \"data\", \"site\", \"baby\", \"climate_change\", \"front\", \"causing\", \"approach\", \"largest\", \"resource\", \"exposure\", \"increase\", \"note\", \"analysis\", \"monitoring\", \"present\", \"model\", \"car\", \"heart\", \"air\", \"climate\", \"change\", \"open\", \"based\", \"term\", \"canberra\", \"event\", \"well\", \"australian\", \"result\", \"australia\", \"human\", \"research\", \"also\", \"used\", \"high\", \"study\", \"melbourne\", \"health\", \"could\", \"including\", \"fire\", \"blaze\", \"destroyed\", \"bureau\", \"bushfires\", \"summer\", \"disaster\", \"council\", \"bushfire\", \"weather\", \"fine\", \"caused\", \"annual\", \"season\", \"economic\", \"worst\", \"victorian\", \"andrew\", \"growth\", \"heavy\", \"climate\", \"average\", \"land\", \"act\", \"property\", \"agency\", \"last_year\", \"premier\", \"billion\", \"unprecedented\", \"extreme\", \"million\", \"east\", \"temperature\", \"smoke\", \"month\", \"economy\", \"year\", \"australia\", \"south\", \"country\", \"new_south\", \"wale\", \"across\", \"aedt\", \"people\", \"victoria\", \"risk\", \"per\", \"service\", \"may\", \"last\", \"australian\", \"january\", \"also\", \"state\", \"government\", \"mass\", \"immune\", \"journal\", \"normal\", \"compared\", \"sample\", \"scenario\", \"patient\", \"infectious_disease\", \"level\", \"existing\", \"amp\", \"analysis\", \"standard\", \"associated\", \"intensive_care\", \"possibility\", \"intensive\", \"study\", \"lung\", \"alone\", \"stage\", \"treatment\", \"multiple\", \"bed\", \"significantly\", \"greater\", \"lower\", \"age\", \"gathering\", \"test\", \"per_cent\", \"cent\", \"per\", \"using\", \"higher\", \"disease\", \"rate\", \"care\", \"group\", \"woman\", \"would\", \"also\", \"hospital\", \"risk\", \"may\", \"used\", \"health\", \"professor\", \"three\", \"coronavirus\", \"reuters\", \"ministry\", \"beijing\", \"shanghai\", \"taiwan\", \"pas\", \"death_toll\", \"infectious_disease\", \"toll\", \"epidemic\", \"holding\", \"death\", \"bringing\", \"fatality\", \"production\", \"sars\", \"growth\", \"stephen\", \"total_number\", \"japanese\", \"kong\", \"philippine\", \"hong\", \"hong_kong\", \"mainland_china\", \"appears\", \"mainland\", \"saturday\", \"american\", \"stay_home\", \"singapore\", \"official\", \"reported\", \"china\", \"infection\", \"hubei\", \"number\", \"case\", \"chinese\", \"coronavirus\", \"friday\", \"wuhan\", \"died\", \"outbreak\", \"japan\", \"disease\", \"virus\", \"people\", \"ship\", \"health\", \"day\"], \"Freq\": [1620.0, 1055.0, 1127.0, 443.0, 1615.0, 299.0, 1516.0, 938.0, 414.0, 676.0, 1861.0, 478.0, 519.0, 303.0, 589.0, 381.0, 462.0, 309.0, 297.0, 728.0, 241.0, 422.0, 285.0, 239.0, 260.0, 241.0, 256.0, 171.0, 1536.0, 309.0, 21.648210525512695, 23.518404006958008, 20.568830490112305, 20.93705177307129, 48.794769287109375, 18.58974266052246, 26.594350814819336, 32.249210357666016, 29.779523849487305, 78.59455108642578, 23.339487075805664, 30.563753128051758, 20.827821731567383, 40.83384323120117, 40.01118469238281, 23.853483200073242, 35.688533782958984, 36.28105163574219, 31.44486427307129, 109.54503631591797, 20.892271041870117, 23.208778381347656, 45.272701263427734, 55.70219421386719, 16.819074630737305, 17.578466415405273, 27.779813766479492, 77.5604476928711, 50.89267349243164, 31.151142120361328, 142.22982788085938, 83.65428161621094, 75.13017272949219, 76.66224670410156, 324.4275207519531, 272.2087097167969, 258.6099853515625, 374.58026123046875, 157.0477752685547, 120.07007598876953, 113.62074279785156, 243.24798583984375, 125.50990295410156, 128.04867553710938, 218.39111328125, 153.70191955566406, 123.62362670898438, 95.52189636230469, 72.96033477783203, 377.6918029785156, 89.77058410644531, 303.44586181640625, 166.34512329101562, 433.5850830078125, 93.11222076416016, 316.87554931640625, 180.1846160888672, 374.86602783203125, 209.77056884765625, 116.09584045410156, 339.1411437988281, 365.238525390625, 191.69281005859375, 146.1165008544922, 134.5106964111328, 232.39573669433594, 243.07791137695312, 160.40711975097656, 146.28927612304688, 163.00291442871094, 137.06875610351562, 149.8719940185547, 140.14492797851562, 53.29414367675781, 69.6985855102539, 24.52107810974121, 24.358749389648438, 74.04694366455078, 132.73240661621094, 92.4074935913086, 26.607318878173828, 53.6457405090332, 35.316864013671875, 40.73798370361328, 108.57965850830078, 108.36906433105469, 72.62117004394531, 71.90486145019531, 41.217132568359375, 109.29947662353516, 109.17179107666016, 109.1521987915039, 216.6488494873047, 108.17188262939453, 17.613262176513672, 1058.3236083984375, 58.72560501098633, 22.327608108520508, 84.3929214477539, 278.9168395996094, 21.908782958984375, 32.94906234741211, 24.381654739379883, 66.92587280273438, 204.67947387695312, 75.1058120727539, 764.970703125, 148.39688110351562, 169.36395263671875, 175.9228973388672, 125.31632232666016, 92.19932556152344, 87.43933868408203, 84.45226287841797, 272.462646484375, 166.13748168945312, 463.3444519042969, 168.22059631347656, 465.6321105957031, 162.82521057128906, 136.22616577148438, 267.91510009765625, 132.55441284179688, 265.9704284667969, 136.56686401367188, 143.29849243164062, 198.13427734375, 178.08555603027344, 135.1265106201172, 143.41275024414062, 123.65129852294922, 128.63485717773438, 116.04818725585938, 115.84954833984375, 122.01018524169922, 30.19989585876465, 211.8198699951172, 76.77043151855469, 43.94894027709961, 31.265823364257812, 44.38389205932617, 48.91454315185547, 31.18090057373047, 39.58407211303711, 16.746355056762695, 18.116931915283203, 20.46158218383789, 16.306793212890625, 28.97743034362793, 303.5634460449219, 58.87276077270508, 202.32933044433594, 15.204041481018066, 18.570398330688477, 17.706523895263672, 112.94703674316406, 43.85655975341797, 59.25434875488281, 24.556732177734375, 52.12482833862305, 12.51879596710205, 37.834774017333984, 66.40360260009766, 16.521575927734375, 150.07366943359375, 93.58780670166016, 60.67597961425781, 66.65055084228516, 47.77346420288086, 93.20060729980469, 512.677001953125, 60.156524658203125, 427.30401611328125, 162.76470947265625, 152.5516815185547, 289.3840026855469, 136.9420623779297, 114.27080535888672, 248.28390502929688, 292.9687194824219, 282.3474426269531, 151.08860778808594, 82.00881958007812, 161.90090942382812, 74.52639770507812, 131.58563232421875, 155.2212371826172, 85.08778381347656, 120.89857482910156, 88.47554779052734, 96.37518310546875, 97.73253631591797, 88.74516296386719, 116.11336517333984, 103.90813446044922, 106.13651275634766, 93.20765686035156, 29.755428314208984, 58.50123596191406, 49.95819854736328, 24.518943786621094, 52.11819076538086, 65.75304412841797, 46.938194274902344, 73.78022766113281, 108.29657745361328, 63.877830505371094, 23.960670471191406, 46.68960189819336, 17.671945571899414, 26.083662033081055, 16.426313400268555, 41.82828903198242, 26.449974060058594, 31.563461303710938, 16.8257999420166, 20.334592819213867, 34.38724136352539, 30.44536590576172, 50.166831970214844, 19.589876174926758, 27.378795623779297, 22.56842803955078, 34.21869659423828, 19.39680290222168, 14.745909690856934, 112.0656967163086, 52.04586410522461, 79.00253295898438, 70.3348617553711, 207.6387481689453, 117.9699935913086, 64.95911407470703, 32.559329986572266, 98.47605895996094, 232.81924438476562, 88.82588958740234, 161.589599609375, 116.92160034179688, 69.09883117675781, 139.3896026611328, 64.35408020019531, 76.55548095703125, 92.51535034179688, 157.23443603515625, 140.1272735595703, 99.19429779052734, 88.8110580444336, 86.99026489257812, 119.55545043945312, 73.54489135742188, 76.74691772460938, 91.32774353027344, 91.4084243774414, 71.6942367553711, 69.08548736572266, 77.01573181152344, 70.64569854736328, 69.39187622070312, 47.934532165527344, 25.80248260498047, 69.89091491699219, 53.752010345458984, 202.9248809814453, 37.26077651977539, 87.34300994873047, 33.2315559387207, 25.327728271484375, 105.83348083496094, 19.220380783081055, 41.36933517456055, 27.47528648376465, 102.1141357421875, 14.961477279663086, 17.06907844543457, 50.21499252319336, 23.637327194213867, 50.0586051940918, 63.54361343383789, 12.269439697265625, 13.598177909851074, 60.269466400146484, 16.469295501708984, 62.3430290222168, 24.483182907104492, 220.1918487548828, 17.59247589111328, 10.94481086730957, 47.756404876708984, 36.15693283081055, 56.46842956542969, 85.12247467041016, 31.74077606201172, 55.220760345458984, 116.37922668457031, 63.69083786010742, 160.20663452148438, 124.79230499267578, 57.48183059692383, 62.96179962158203, 84.36473083496094, 193.70851135253906, 63.14902114868164, 82.52438354492188, 103.51853942871094, 81.1376724243164, 74.9704818725586, 108.06991577148438, 96.04362487792969, 59.185665130615234, 72.39276885986328, 68.94852447509766, 63.33159637451172, 62.40062713623047, 61.33106994628906, 60.388126373291016, 33.68459701538086, 31.722412109375, 14.621649742126465, 31.098583221435547, 36.34752655029297, 18.02582359313965, 25.706501007080078, 26.893110275268555, 50.36901092529297, 24.236976623535156, 39.53364944458008, 20.526649475097656, 59.04544448852539, 85.83733367919922, 16.24547576904297, 12.6229829788208, 73.94523620605469, 41.70893478393555, 18.427778244018555, 20.851795196533203, 21.134849548339844, 23.584348678588867, 14.17382526397705, 17.09417152404785, 14.653935432434082, 93.84654235839844, 12.96725082397461, 46.77648162841797, 11.448139190673828, 71.9778823852539, 148.84024047851562, 431.1341247558594, 30.117761611938477, 143.83755493164062, 91.26976013183594, 51.33237838745117, 40.950653076171875, 61.713375091552734, 198.5241241455078, 277.7113952636719, 115.70909118652344, 44.64504623413086, 251.28057861328125, 88.22642517089844, 81.01600646972656, 64.21814727783203, 133.44393920898438, 85.98778533935547, 104.9946060180664, 64.23953247070312, 106.93540954589844, 66.51123046875, 72.55370330810547, 66.84915924072266, 63.58224868774414, 68.17245483398438, 63.39179611206055, 51.629981994628906, 51.35786437988281, 27.576274871826172, 132.34622192382812, 42.79462814331055, 45.09823226928711, 44.33082962036133, 32.5213737487793, 78.73198699951172, 116.01080322265625, 31.940034866333008, 46.87446212768555, 267.96234130859375, 58.543277740478516, 104.73735046386719, 51.4140510559082, 28.038171768188477, 64.86510467529297, 21.93507957458496, 14.81033706665039, 26.854936599731445, 21.10553550720215, 38.106475830078125, 31.16825294494629, 39.73160171508789, 14.851152420043945, 61.31739807128906, 16.006303787231445, 20.967613220214844, 25.624696731567383, 49.770999908447266, 21.24146270751953, 112.04058074951172, 78.54679107666016, 87.05937957763672, 56.40756607055664, 69.78491973876953, 45.392181396484375, 37.93339538574219, 41.4019775390625, 59.70077133178711, 122.31475067138672, 52.37369155883789, 120.10929107666016, 52.542789459228516, 49.40156173706055, 69.47718811035156, 45.61727523803711, 48.4106330871582, 53.323570251464844, 55.31205368041992, 55.10918426513672, 49.63404083251953, 46.19016647338867, 277.2159729003906, 34.037010192871094, 28.114898681640625, 27.478422164916992, 111.8265151977539, 45.16352462768555, 23.51046371459961, 49.05070877075195, 64.43473052978516, 53.48170852661133, 37.0942497253418, 31.357656478881836, 13.748492240905762, 43.88819885253906, 31.859970092773438, 38.649356842041016, 25.752519607543945, 16.760046005249023, 15.748289108276367, 15.503081321716309, 89.0719223022461, 31.15660285949707, 28.094886779785156, 24.01426124572754, 15.064448356628418, 24.71511459350586, 29.31616973876953, 16.452022552490234, 22.687591552734375, 14.042668342590332, 32.06433868408203, 68.88213348388672, 30.636932373046875, 40.92479705810547, 53.069393157958984, 57.17146301269531, 33.791873931884766, 124.39630126953125, 208.0547637939453, 108.29232025146484, 65.29286193847656, 54.04404067993164, 54.154449462890625, 46.78044891357422, 51.241241455078125, 84.64314270019531, 54.22563171386719, 47.40388107299805, 46.82347106933594, 40.3055419921875, 46.1119270324707, 44.996116638183594, 53.97467041015625, 56.42019271850586, 45.55583190917969, 42.630611419677734, 43.58075714111328, 90.1936264038086, 35.53466796875, 22.828983306884766, 61.66914367675781, 34.20304489135742, 23.285808563232422, 15.411731719970703, 196.18260192871094, 19.720478057861328, 74.27783966064453, 13.67303466796875, 45.897117614746094, 49.91725540161133, 14.630265235900879, 14.628776550292969, 17.648473739624023, 8.60579776763916, 20.2871036529541, 116.70755004882812, 32.64875793457031, 26.69529151916504, 39.78920364379883, 30.980545043945312, 22.619308471679688, 24.83156967163086, 12.183846473693848, 12.118885040283203, 17.708721160888672, 18.594743728637695, 15.534829139709473, 73.50423431396484, 75.059814453125, 74.65042114257812, 81.17061614990234, 41.58196258544922, 28.263168334960938, 78.26566314697266, 30.729938507080078, 34.764808654785156, 46.48270797729492, 63.98353576660156, 65.374755859375, 72.14915466308594, 46.828495025634766, 38.51901626586914, 40.32065963745117, 31.872066497802734, 45.95759963989258, 32.9389762878418, 31.24668312072754, 31.609817504882812, 48.65235900878906, 23.53655242919922, 32.020320892333984, 22.82954216003418, 13.233650207519531, 11.697794914245605, 23.173908233642578, 16.549734115600586, 29.80108070373535, 25.278255462646484, 9.384330749511719, 74.66717529296875, 15.475488662719727, 12.07223129272461, 8.540224075317383, 45.855552673339844, 9.612451553344727, 6.528823375701904, 9.529685020446777, 19.45097541809082, 45.079227447509766, 10.403596878051758, 45.09056854248047, 44.0410041809082, 35.54610061645508, 8.836339950561523, 43.44269943237305, 45.33381652832031, 23.72955322265625, 7.269323348999023, 19.00149154663086, 43.06163787841797, 43.647178649902344, 160.27566528320312, 45.64745330810547, 33.07585144042969, 54.01143264770508, 112.63673400878906, 65.61347961425781, 102.4452896118164, 33.411678314208984, 61.65908432006836, 27.09663200378418, 45.267616271972656, 35.771339416503906, 35.716941833496094, 43.663055419921875, 45.216148376464844, 34.55121612548828, 32.6687126159668, 30.51605224609375], \"Total\": [1620.0, 1055.0, 1127.0, 443.0, 1615.0, 299.0, 1516.0, 938.0, 414.0, 676.0, 1861.0, 478.0, 519.0, 303.0, 589.0, 381.0, 462.0, 309.0, 297.0, 728.0, 241.0, 422.0, 285.0, 239.0, 260.0, 241.0, 256.0, 171.0, 1536.0, 309.0, 22.80255126953125, 24.784833908081055, 21.80948257446289, 22.796449661254883, 53.547054290771484, 20.804773330688477, 30.711105346679688, 37.677982330322266, 34.81100845336914, 92.19810485839844, 27.766403198242188, 37.64077377319336, 25.743106842041016, 50.574161529541016, 49.581417083740234, 29.749303817749023, 44.585872650146484, 45.61723327636719, 39.67854309082031, 139.61900329589844, 26.760103225708008, 29.742578506469727, 58.409725189208984, 72.35332489013672, 22.597566604614258, 23.8167724609375, 37.655357360839844, 105.22544860839844, 69.40953063964844, 42.659820556640625, 196.36026000976562, 115.90772247314453, 104.05570220947266, 106.98277282714844, 483.6818542480469, 420.55096435546875, 411.9308776855469, 676.0655517578125, 258.2555236816406, 191.19007873535156, 180.48043823242188, 475.1048583984375, 214.984375, 227.33328247070312, 451.1500244140625, 290.97125244140625, 226.1166229248047, 162.8881072998047, 114.07135772705078, 1055.64697265625, 154.6502685546875, 892.5096435546875, 380.95037841796875, 1536.0880126953125, 165.5423583984375, 1127.3477783203125, 469.285400390625, 1615.57470703125, 627.221923828125, 236.79380798339844, 1516.9014892578125, 1861.7490234375, 589.638671875, 357.0787048339844, 309.8406982421875, 938.5936889648438, 1107.0408935546875, 592.544677734375, 443.2485046386719, 726.050048828125, 359.7166442871094, 742.5244750976562, 582.7381591796875, 62.62287139892578, 84.54020690917969, 29.86071014404297, 29.8414363861084, 91.47058868408203, 166.1750946044922, 118.3521957397461, 35.84297561645508, 72.71046447753906, 48.816978454589844, 56.69224548339844, 153.91567993164062, 153.914306640625, 103.33087158203125, 102.3334732055664, 58.66515350341797, 155.8932647705078, 155.89170837402344, 155.8983612060547, 309.8000183105469, 154.90069580078125, 26.627178192138672, 1620.0233154296875, 90.54249572753906, 34.776100158691406, 136.75404357910156, 454.11376953125, 35.67332458496094, 53.71806716918945, 39.788082122802734, 109.44043731689453, 339.53546142578125, 125.30445861816406, 1516.9014892578125, 261.8678894042969, 308.8533020019531, 327.36871337890625, 236.34396362304688, 162.61947631835938, 152.92698669433594, 147.9320068359375, 726.050048828125, 374.2282409667969, 1615.57470703125, 396.8188171386719, 1861.7490234375, 393.9690246582031, 320.7636413574219, 1107.0408935546875, 332.14813232421875, 1536.0880126953125, 411.96514892578125, 466.03070068359375, 1127.3477783203125, 938.5936889648438, 462.6315612792969, 742.5244750976562, 422.21160888671875, 589.638671875, 318.73992919921875, 322.723876953125, 131.88916015625, 33.460365295410156, 241.2890167236328, 93.5794677734375, 58.08954620361328, 42.328758239746094, 61.12773132324219, 68.91979217529297, 46.23601531982422, 60.15803527832031, 25.645126342773438, 28.538515090942383, 32.45881652832031, 27.626325607299805, 49.38214874267578, 519.3919677734375, 103.57273864746094, 366.09185791015625, 27.73169708251953, 34.562320709228516, 33.6042366027832, 215.84375, 83.84305572509766, 113.5086441040039, 47.05161666870117, 101.72711181640625, 24.70486831665039, 75.01529693603516, 133.37745666503906, 33.36933898925781, 305.4792175292969, 191.2812957763672, 128.35569763183594, 145.2935791015625, 102.83820343017578, 223.82334899902344, 1861.7490234375, 136.63787841796875, 1620.0233154296875, 489.75469970703125, 468.6221008300781, 1107.0408935546875, 422.21160888671875, 332.14813232421875, 1055.64697265625, 1516.9014892578125, 1615.57470703125, 589.638671875, 216.88345336914062, 728.9431762695312, 189.10775756835938, 565.6055297851562, 892.5096435546875, 248.1369171142578, 582.7381591796875, 309.8000183105469, 396.8188171386719, 466.03070068359375, 357.0787048339844, 1127.3477783203125, 726.050048828125, 1536.0880126953125, 938.5936889648438, 34.62681579589844, 68.21297454833984, 61.01692581176758, 31.495065689086914, 67.5695571899414, 86.58201599121094, 62.011268615722656, 99.97158813476562, 149.63043212890625, 93.34365844726562, 35.49986267089844, 73.6965560913086, 28.047393798828125, 41.49482345581055, 26.206436157226562, 66.81362915039062, 42.275840759277344, 50.54826736450195, 27.197250366210938, 33.083335876464844, 56.389957427978516, 50.270774841308594, 84.45382690429688, 33.13408279418945, 47.39749526977539, 39.18362045288086, 59.5505256652832, 34.063079833984375, 26.162073135375977, 200.7449188232422, 96.30575561523438, 149.72604370117188, 137.65586853027344, 465.0805969238281, 267.003173828125, 135.72412109375, 59.31330108642578, 242.3414306640625, 728.9431762695312, 215.72293090820312, 477.32989501953125, 333.2658996582031, 162.78981018066406, 525.430908203125, 160.4657745361328, 212.86781311035156, 297.2559814453125, 742.5244750976562, 700.6107788085938, 377.65673828125, 305.98980712890625, 308.3257141113281, 666.7732543945312, 212.67355346679688, 238.78231811523438, 471.53521728515625, 592.544677734375, 230.76419067382812, 216.8594512939453, 1536.0880126953125, 565.6055297851562, 627.221923828125, 51.64223098754883, 31.702823638916016, 94.08131408691406, 73.66883087158203, 285.5936279296875, 52.715091705322266, 126.51184844970703, 52.53657150268555, 41.64083480834961, 179.57012939453125, 33.68946075439453, 75.3570556640625, 51.36710739135742, 200.40115356445312, 29.647865295410156, 33.92781066894531, 101.3080825805664, 48.51716613769531, 102.83820343017578, 132.7233428955078, 25.738037109375, 28.748249053955078, 129.24464416503906, 35.43089294433594, 134.63279724121094, 53.03605270385742, 478.8731994628906, 38.78193283081055, 24.892789840698242, 111.26600646972656, 87.08982849121094, 140.4384307861328, 240.92013549804688, 76.6595687866211, 150.81715393066406, 415.2974853515625, 190.38047790527344, 728.9431762695312, 519.3919677734375, 178.6080322265625, 204.84608459472656, 335.6408386230469, 1536.0880126953125, 267.003173828125, 466.03070068359375, 892.5096435546875, 582.7381591796875, 471.53521728515625, 1615.57470703125, 1861.7490234375, 238.80628967285156, 700.6107788085938, 742.5244750976562, 565.6055297851562, 489.75469970703125, 525.430908203125, 666.7732543945312, 36.41398620605469, 44.419456481933594, 20.697818756103516, 45.36745071411133, 54.21612548828125, 27.611040115356445, 39.52973556518555, 42.36335754394531, 79.86722564697266, 38.53274917602539, 64.1581802368164, 33.593231201171875, 99.43496704101562, 150.33309936523438, 28.719707489013672, 22.652408599853516, 134.99288940429688, 78.04025268554688, 34.55522155761719, 39.483543395996094, 40.33756637573242, 45.2874641418457, 27.451025009155273, 33.612178802490234, 29.621540069580078, 190.38011169433594, 26.575483322143555, 96.34083557128906, 23.610767364501953, 148.55780029296875, 309.8406982421875, 1127.3477783203125, 65.6446533203125, 381.6740417480469, 232.26953125, 127.57530212402344, 101.07984924316406, 176.70339965820312, 938.5936889648438, 1536.0880126953125, 462.6315612792969, 117.44168090820312, 1615.57470703125, 381.2929382324219, 342.4580993652344, 234.1964111328125, 1055.64697265625, 443.2485046386719, 676.0655517578125, 250.28091430664062, 892.5096435546875, 332.3294982910156, 471.53521728515625, 377.65673828125, 380.95037841796875, 627.221923828125, 742.5244750976562, 297.2559814453125, 475.1048583984375, 32.45926284790039, 156.45223999023438, 55.736572265625, 60.49644088745117, 60.4532585144043, 45.098777770996094, 111.42821502685547, 171.53346252441406, 48.45270538330078, 71.51121520996094, 414.7476806640625, 91.01079559326172, 162.97103881835938, 81.06263732910156, 44.34585952758789, 106.564697265625, 36.84864807128906, 25.223648071289062, 46.66144561767578, 37.72077560424805, 68.65052795410156, 56.19961929321289, 73.34027862548828, 28.01388931274414, 117.5714111328125, 30.999685287475586, 40.66218948364258, 49.70184326171875, 97.73260498046875, 42.79689407348633, 236.4490509033203, 182.83905029296875, 206.9390106201172, 134.63279724121094, 189.01905822753906, 112.99250793457031, 88.56725311279297, 108.1332778930664, 220.76487731933594, 1107.0408935546875, 200.27806091308594, 1861.7490234375, 232.26953125, 200.7449188232422, 700.6107788085938, 154.0709686279297, 193.3253631591797, 303.4311218261719, 451.1500244140625, 892.5096435546875, 525.430908203125, 312.2196044921875, 299.4952697753906, 37.74998092651367, 31.86131477355957, 31.852651596069336, 135.66355895996094, 57.40299606323242, 34.45420455932617, 72.6064453125, 96.61393737792969, 83.98428344726562, 65.759521484375, 56.62028503417969, 25.727867126464844, 82.18367767333984, 61.4754638671875, 75.31204986572266, 51.73025131225586, 33.694801330566406, 31.86363983154297, 31.593463897705078, 182.83905029296875, 64.91100311279297, 58.621726989746094, 51.63352966308594, 32.65635681152344, 55.39645004272461, 67.33741760253906, 38.78193283081055, 54.285945892333984, 33.710208892822266, 77.83903503417969, 178.61410522460938, 75.41493225097656, 106.47573852539062, 171.53346252441406, 203.21261596679688, 95.25990295410156, 666.7732543945312, 1861.7490234375, 726.050048828125, 468.6221008300781, 318.73992919921875, 322.723876953125, 235.37496948242188, 308.8533020019531, 1536.0880126953125, 411.96514892578125, 288.7994384765625, 297.4869079589844, 178.6080322265625, 342.4580993652344, 332.9359130859375, 1107.0408935546875, 1516.9014892578125, 700.6107788085938, 335.6408386230469, 489.75469970703125, 106.05142974853516, 58.930419921875, 40.913482666015625, 111.8775405883789, 69.31952667236328, 48.33721923828125, 33.07832717895508, 443.2485046386719, 45.05859375, 173.60205078125, 32.0214729309082, 107.92879486083984, 117.5714111328125, 35.08531188964844, 35.963111877441406, 43.90971755981445, 21.415752410888672, 50.78595733642578, 303.4311218261719, 85.49540710449219, 70.42018127441406, 108.10826110839844, 84.2874526977539, 61.8498420715332, 68.48580169677734, 33.89878463745117, 34.37773895263672, 51.56172561645508, 55.438636779785156, 48.1231803894043, 241.36521911621094, 256.89422607421875, 260.8750305175781, 297.4869079589844, 138.03858947753906, 94.14686584472656, 381.2929382324219, 117.43751525878906, 144.3563232421875, 258.28131103515625, 478.8731994628906, 565.6055297851562, 700.6107788085938, 411.9308776855469, 288.7994384765625, 342.4580993652344, 154.0709686279297, 892.5096435546875, 216.8594512939453, 318.7893371582031, 1615.57470703125, 70.9623031616211, 43.80116271972656, 74.62696838378906, 54.62376403808594, 31.803430557250977, 29.679161071777344, 61.55674362182617, 45.05859375, 87.21664428710938, 75.01557922363281, 27.865474700927734, 239.0537109375, 49.77997589111328, 39.483543395996094, 27.9940242767334, 150.33309936523438, 31.86363983154297, 21.758060455322266, 32.66498565673828, 68.50496673583984, 159.0904541015625, 36.74183654785156, 160.04434204101562, 158.08912658691406, 136.63787841796875, 33.98096466064453, 167.44970703125, 180.64144897460938, 95.84217071533203, 29.647865295410156, 77.51187896728516, 195.52713012695312, 210.75762939453125, 1055.64697265625, 234.1964111328125, 165.5423583984375, 321.2685852050781, 938.5936889648438, 589.638671875, 1615.57470703125, 212.3670196533203, 676.0655517578125, 150.84266662597656, 462.6315612792969, 374.2282409667969, 381.2929382324219, 1127.3477783203125, 1536.0880126953125, 422.21160888671875, 892.5096435546875, 592.544677734375], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.1528000831604, -7.070000171661377, -7.203999996185303, -7.186200141906738, -6.340099811553955, -7.305200099945068, -6.9471001625061035, -6.754300117492676, -6.833899974822998, -5.863500118255615, -7.077600002288818, -6.808000087738037, -7.191500186920166, -6.5183000564575195, -6.538599967956543, -7.055799961090088, -6.652900218963623, -6.636499881744385, -6.7795000076293945, -5.531400203704834, -7.188399791717529, -7.083199977874756, -6.41510009765625, -6.207699775695801, -7.405300140380859, -7.361100196838379, -6.903500080108643, -5.876699924468994, -6.297999858856201, -6.788899898529053, -5.270299911499023, -5.80109977722168, -5.9085001945495605, -5.888400077819824, -4.445700168609619, -4.621200084686279, -4.672399997711182, -4.302000045776367, -5.171199798583984, -5.439700126647949, -5.494900226593018, -4.733699798583984, -5.395400047302246, -5.375400066375732, -4.8414998054504395, -5.192800045013428, -5.4105000495910645, -5.668399810791016, -5.937900066375732, -4.293700218200684, -5.730500221252441, -4.512599945068359, -5.113699913024902, -4.155700206756592, -5.693999767303467, -4.469299793243408, -5.03380012512207, -4.301199913024902, -4.881800174713135, -5.473400115966797, -4.401400089263916, -4.327199935913086, -4.97189998626709, -5.2434000968933105, -5.326099872589111, -4.779300212860107, -4.734399795532227, -5.150100231170654, -5.242199897766113, -5.133999824523926, -5.307300090789795, -5.2179999351501465, -5.285099983215332, -6.116799831390381, -5.848400115966797, -6.893099784851074, -6.899700164794922, -5.787899971008301, -5.2042999267578125, -5.566400051116943, -6.811399936676025, -6.110199928283691, -6.528200149536133, -6.38539981842041, -5.405099868774414, -5.407100200653076, -5.807300090789795, -5.817299842834473, -6.373700141906738, -5.398499965667725, -5.399700164794922, -5.399899959564209, -4.714300155639648, -5.408899784088135, -7.223899841308594, -3.128200054168701, -6.019700050354004, -6.986800193786621, -5.657100200653076, -4.461699962615967, -7.00570011138916, -6.597599983215332, -6.898799896240234, -5.888999938964844, -4.771200180053711, -5.77370023727417, -3.4528000354766846, -5.092700004577637, -4.9604997634887695, -4.922599792480469, -5.2617998123168945, -5.568600177764893, -5.621699810028076, -5.656400203704834, -4.485099792480469, -4.979800224304199, -3.9540998935699463, -4.967299938201904, -3.949199914932251, -4.999899864196777, -5.178299903869629, -4.5019001960754395, -5.205599784851074, -4.509200096130371, -5.17579984664917, -5.127699851989746, -4.803699970245361, -4.910299777984619, -5.186399936676025, -5.1269001960754395, -5.275100231170654, -5.235599994659424, -5.338600158691406, -5.3403000831604, -4.981599807739258, -6.377900123596191, -4.429999828338623, -5.444900035858154, -6.002699851989746, -6.343200206756592, -5.992800235748291, -5.895599842071533, -6.345900058746338, -6.1072998046875, -6.96750020980835, -6.888899803161621, -6.767199993133545, -6.994100093841553, -6.4191999435424805, -4.070099830627441, -5.710299968719482, -4.475800037384033, -7.064199924468994, -6.864099979400635, -6.911799907684326, -5.058800220489502, -6.004799842834473, -5.70389986038208, -6.584700107574463, -5.832099914550781, -7.258500099182129, -6.152500152587891, -5.590000152587891, -6.980999946594238, -4.774600028991699, -5.246799945831299, -5.680200099945068, -5.586299896240234, -5.9191999435424805, -5.250999927520752, -3.546099901199341, -5.688799858093262, -3.7281999588012695, -4.693399906158447, -4.758200168609619, -4.118000030517578, -4.866199970245361, -5.047100067138672, -4.271100044250488, -4.105599880218506, -4.142600059509277, -4.7677998542785645, -5.378900051116943, -4.698699951171875, -5.474599838256836, -4.906099796295166, -4.740900039672852, -5.3420000076293945, -4.990799903869629, -5.302999973297119, -5.21750020980835, -5.203499794006348, -5.299900054931641, -5.031099796295166, -5.142199993133545, -5.120999813079834, -5.250899791717529, -6.149700164794922, -5.473599910736084, -5.631499767303467, -6.343200206756592, -5.589200019836426, -5.356800079345703, -5.693900108337402, -5.241600036621094, -4.857800006866455, -5.385700225830078, -6.366300106048584, -5.69920015335083, -6.6707000732421875, -6.281400203704834, -6.743800163269043, -5.809100151062012, -6.267399787902832, -6.090700149536133, -6.719799995422363, -6.530399799346924, -6.005000114440918, -6.126800060272217, -5.627299785614014, -6.567699909210205, -6.232900142669678, -6.42609977722168, -6.009900093078613, -6.577600002288818, -6.8516998291015625, -4.823599815368652, -5.59060001373291, -5.1732001304626465, -5.289400100708008, -4.206900119781494, -4.772299766540527, -5.368899822235107, -6.059599876403809, -4.952899932861328, -4.092400074005127, -5.056000232696533, -4.457600116729736, -4.781199932098389, -5.307199954986572, -4.605400085449219, -5.378300189971924, -5.204699993133545, -5.0152997970581055, -4.485000133514404, -4.600100040435791, -4.9456000328063965, -5.05620002746582, -5.076900005340576, -4.758900165557861, -5.244800090789795, -5.202199935913086, -5.028200149536133, -5.027400016784668, -5.270299911499023, -5.307300090789795, -5.198699951171875, -5.284999847412109, -5.3028998374938965, -5.613999843597412, -6.233399868011475, -5.2368998527526855, -5.499499797821045, -4.171000003814697, -5.865900039672852, -5.013999938964844, -5.980400085449219, -6.251999855041504, -4.822000026702881, -6.527900218963623, -5.761300086975098, -6.170599937438965, -4.857800006866455, -6.77839994430542, -6.646599769592285, -5.567500114440918, -6.321000099182129, -5.570700168609619, -5.332099914550781, -6.976799964904785, -6.873899936676025, -5.385000228881836, -6.682400226593018, -5.351200103759766, -6.285900115966797, -4.089399814605713, -6.616399765014648, -7.091000080108643, -5.617700099945068, -5.895999908447266, -5.450200080871582, -5.03980016708374, -6.026299953460693, -5.472499847412109, -4.7270002365112305, -5.329800128936768, -4.407400131225586, -4.657199859619141, -5.432400226593018, -5.341300010681152, -5.048699855804443, -4.21750020980835, -5.338399887084961, -5.070799827575684, -4.844099998474121, -5.087699890136719, -5.166800022125244, -4.80109977722168, -4.919099807739258, -5.403200149536133, -5.2017998695373535, -5.250500202178955, -5.3354997634887695, -5.350299835205078, -5.367599964141846, -5.3831000328063965, -5.8130998611450195, -5.8730998039245605, -6.647600173950195, -5.89300012588501, -5.736999988555908, -6.438300132751465, -6.083399772644043, -6.038300037384033, -5.410699844360352, -6.142199993133545, -5.6529998779296875, -6.3084001541137695, -5.251800060272217, -4.877699851989746, -6.542300224304199, -6.794600009918213, -5.026800155639648, -5.599400043487549, -6.416299819946289, -6.292699813842773, -6.279200077056885, -6.16949987411499, -6.678699970245361, -6.491399765014648, -6.645400047302246, -4.78849983215332, -6.7677001953125, -5.4847002029418945, -6.892300128936768, -5.053800106048584, -4.327300071716309, -3.263700008392334, -5.925000190734863, -4.361400127410889, -4.816299915313721, -5.3917999267578125, -5.617800235748291, -5.207600116729736, -4.0391998291015625, -3.7035000324249268, -4.578999996185303, -5.531400203704834, -3.8036000728607178, -4.850200176239014, -4.935500144958496, -5.167799949645996, -4.436399936676025, -4.875899791717529, -4.676199913024902, -5.167500019073486, -4.657899856567383, -5.132800102233887, -5.04580020904541, -5.127699851989746, -5.177800178527832, -5.108099937438965, -5.180799961090088, -5.386000156402588, -5.391300201416016, -5.8653998374938965, -4.296999931335449, -5.426000118255615, -5.373499870300293, -5.390699863433838, -5.700500011444092, -4.816299915313721, -4.428699970245361, -5.718500137329102, -5.33489990234375, -3.5915000438690186, -5.112599849700928, -4.530900001525879, -5.242499828338623, -5.848800182342529, -5.0100998878479, -6.094299793243408, -6.487100124359131, -5.891900062561035, -6.132800102233887, -5.541999816894531, -5.743000030517578, -5.500199794769287, -6.484300136566162, -5.066299915313721, -6.40939998626709, -6.139400005340576, -5.938799858093262, -5.274899959564209, -6.126399993896484, -4.463500022888184, -4.818699836730957, -4.715799808502197, -5.149799823760986, -4.936999797821045, -5.367000102996826, -5.546500205993652, -5.459000110626221, -5.0929999351501465, -4.375800132751465, -5.223999977111816, -4.394000053405762, -5.220699787139893, -5.282400131225586, -4.941400051116943, -5.362100124359131, -5.302700042724609, -5.205999851226807, -5.169400215148926, -5.173099994659424, -5.277699947357178, -5.349599838256836, -3.4319000244140625, -5.529300212860107, -5.720399856567383, -5.743299961090088, -4.339799880981445, -5.246399879455566, -5.8993000984191895, -5.163899898529053, -4.89109992980957, -5.077400207519531, -5.443299770355225, -5.611299991607666, -6.435800075531006, -5.275100231170654, -5.595399856567383, -5.402200222015381, -5.808199882507324, -6.23769998550415, -6.300000190734863, -6.315700054168701, -4.567299842834473, -5.617700099945068, -5.721099853515625, -5.8780999183654785, -6.344399929046631, -5.849299907684326, -5.678599834442139, -6.25629997253418, -5.934899806976318, -6.414599895477295, -5.589000225067139, -4.8242998123168945, -5.634500026702881, -5.34499979019165, -5.085100173950195, -5.010700225830078, -5.536499977111816, -4.23330020904541, -3.718899965286255, -4.3719000816345215, -4.877799987792969, -5.06689977645874, -5.064899921417236, -5.211299896240234, -5.120200157165527, -4.618299961090088, -5.063600063323975, -5.197999954223633, -5.210299968719482, -5.360199928283691, -5.2256999015808105, -5.250199794769287, -5.06820011138916, -5.023900032043457, -5.237800121307373, -5.304200172424316, -5.282100200653076, -4.084400177001953, -5.0157999992370605, -5.4583001136779785, -4.4644999504089355, -5.053999900817871, -5.438499927520752, -5.851200103759766, -3.307300090789795, -5.604700088500977, -4.278500080108643, -5.970900058746338, -4.759900093078613, -4.676000118255615, -5.903200149536133, -5.903299808502197, -5.715700149536133, -6.433899879455566, -5.576300144195557, -3.82669997215271, -5.100500106811523, -5.301799774169922, -4.902699947357178, -5.1529998779296875, -5.46750020980835, -5.374199867248535, -6.08620023727417, -6.091599941253662, -5.712299823760986, -5.663400173187256, -5.843200206756592, -4.289000034332275, -4.26800012588501, -4.273499965667725, -4.189799785614014, -4.858699798583984, -5.244800090789795, -4.226200103759766, -5.161099910736084, -5.037700176239014, -4.747200012207031, -4.427700042724609, -4.406199932098389, -4.307600021362305, -4.739799976348877, -4.935200214385986, -4.889500141143799, -5.124599933624268, -4.758600234985352, -5.091700077056885, -5.144400119781494, -5.132900238037109, -4.595600128173828, -5.321800231933594, -5.013999938964844, -5.35230016708374, -5.897600173950195, -6.020899772644043, -5.337299823760986, -5.673999786376953, -5.0858001708984375, -5.250400066375732, -6.241300106048584, -4.167300224304199, -5.741099834442139, -5.9893999099731445, -6.3354997634887695, -4.654799938201904, -6.217299938201904, -6.604100227355957, -6.225900173187256, -5.512400150299072, -4.671899795532227, -6.138199806213379, -4.671599864959717, -4.695199966430664, -4.9095001220703125, -6.301400184631348, -4.708899974822998, -4.666299819946289, -5.313600063323975, -6.496699810028076, -5.535799980163574, -4.717700004577637, -4.70419979095459, -3.40339994430542, -4.65939998626709, -4.981500148773193, -4.491099834442139, -3.756200075149536, -4.296500205993652, -3.8510000705718994, -4.971399784088135, -4.358699798583984, -5.1809000968933105, -4.667699813842773, -4.903200149536133, -4.904699802398682, -4.703800201416016, -4.668900012969971, -4.937900066375732, -4.993899822235107, -5.062099933624268], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5439000129699707, 1.5434000492095947, 1.5372999906539917, 1.5108000040054321, 1.5029000043869019, 1.483299970626831, 1.4519000053405762, 1.4402999877929688, 1.4398000240325928, 1.4362000226974487, 1.4221999645233154, 1.3875999450683594, 1.3839999437332153, 1.3818999528884888, 1.3813999891281128, 1.375, 1.3732999563217163, 1.3668999671936035, 1.3632999658584595, 1.3532999753952026, 1.3482999801635742, 1.3478000164031982, 1.3410999774932861, 1.3343000411987305, 1.3005000352859497, 1.292199969291687, 1.291700005531311, 1.2907999753952026, 1.285599946975708, 1.281499981880188, 1.2733999490737915, 1.2697999477386475, 1.2702000141143799, 1.2625999450683594, 1.1964999437332153, 1.1608999967575073, 1.1303000450134277, 1.0053999423980713, 1.0985000133514404, 1.1306999921798706, 1.1331000328063965, 0.9264000058174133, 1.0577000379562378, 1.0219000577926636, 0.8704000115394592, 0.9577000141143799, 0.9921000003814697, 1.0621999502182007, 1.1490000486373901, 0.5680000185966492, 1.0520000457763672, 0.5170000195503235, 0.767300009727478, 0.3310000002384186, 1.0204999446868896, 0.32679998874664307, 0.6385999917984009, 0.13500000536441803, 0.5005999803543091, 0.8830999732017517, 0.09790000319480896, -0.03280000016093254, 0.4722999930381775, 0.7023000121116638, 0.7615000009536743, 0.19990000128746033, 0.07980000227689743, 0.2892000079154968, 0.48730000853538513, 0.10199999809265137, 0.6309999823570251, -0.004399999976158142, 0.17080000042915344, 1.569700002670288, 1.5379999876022339, 1.534000039100647, 1.527999997138977, 1.519700050354004, 1.5062999725341797, 1.4836000204086304, 1.4330999851226807, 1.4270000457763672, 1.4072999954223633, 1.4005999565124512, 1.382099986076355, 1.3802000284194946, 1.3783999681472778, 1.3782000541687012, 1.378100037574768, 1.3760000467300415, 1.3747999668121338, 1.3746000528335571, 1.3733999729156494, 1.371999979019165, 1.3178000450134277, 1.305299997329712, 1.2980999946594238, 1.2878999710083008, 1.2482999563217163, 1.2436000108718872, 1.243499994277954, 1.242300033569336, 1.2412999868392944, 1.2391999959945679, 1.2249000072479248, 1.2192000150680542, 1.0464999675750732, 1.163100004196167, 1.1302000284194946, 1.1100000143051147, 1.09660005569458, 1.163599967956543, 1.1720000505447388, 1.1705000400543213, 0.7508999705314636, 0.9190000295639038, 0.4821000099182129, 0.8727999925613403, 0.3452000021934509, 0.8474000096321106, 0.8747000098228455, 0.3122999966144562, 0.8125, -0.022600000724196434, 0.6269000172615051, 0.5516999959945679, -0.007600000128149986, 0.06889999657869339, 0.5002999901771545, 0.08669999986886978, 0.503000020980835, 0.2084999978542328, 0.7207000255584717, 0.7064999938011169, 1.9601000547409058, 1.9354000091552734, 1.9076999425888062, 1.839900016784668, 1.7589999437332153, 1.7350000143051147, 1.7178000211715698, 1.695099949836731, 1.6440000534057617, 1.6194000244140625, 1.611799955368042, 1.5835000276565552, 1.5765000581741333, 1.510699987411499, 1.5048999786376953, 1.5009000301361084, 1.4730000495910645, 1.4449000358581543, 1.436900019645691, 1.416700005531311, 1.3971999883651733, 1.3903000354766846, 1.3898999691009521, 1.3878999948501587, 1.3876999616622925, 1.3693000078201294, 1.358199954032898, 1.3535000085830688, 1.340499997138977, 1.3350000381469727, 1.3272000551223755, 1.323099970817566, 1.288699984550476, 1.2585999965667725, 1.2711999416351318, 1.1618000268936157, 0.7483000159263611, 1.2174999713897705, 0.7052000164985657, 0.9362999796867371, 0.9156000018119812, 0.6962000131607056, 0.9120000004768372, 0.9708999991416931, 0.5906000137329102, 0.3935999870300293, 0.2935999929904938, 0.6762999892234802, 1.0654000043869019, 0.53329998254776, 1.1067999601364136, 0.5796999931335449, 0.28870001435279846, 0.9675999879837036, 0.4650999903678894, 0.7846999764442444, 0.6226999759674072, 0.47589999437332153, 0.6456999778747559, -0.23510000109672546, 0.09380000084638596, -0.6342999935150146, -0.27160000801086426, 2.129300117492676, 2.1273999214172363, 2.0810000896453857, 2.030600070953369, 2.0213000774383545, 2.0058000087738037, 2.002500057220459, 1.9772000312805176, 1.9577000141143799, 1.9016000032424927, 1.8877999782562256, 1.8244999647140503, 1.819000005722046, 1.8166999816894531, 1.8137999773025513, 1.812600016593933, 1.812000036239624, 1.809999942779541, 1.8006999492645264, 1.7941999435424805, 1.7862999439239502, 1.7795000076293945, 1.76010000705719, 1.7553999423980713, 1.732100009918213, 1.729200005531311, 1.7268999814987183, 1.7178000211715698, 1.7075999975204468, 1.6979999542236328, 1.6655000448226929, 1.6416000127792358, 1.6095000505447388, 1.4744999408721924, 1.4641000032424927, 1.544100046157837, 1.6812000274658203, 1.3803999423980713, 1.1396000385284424, 1.3935999870300293, 1.1978000402450562, 1.2335000038146973, 1.4240000247955322, 0.9539999961853027, 1.367300033569336, 1.2582999467849731, 1.113700032234192, 0.728600025177002, 0.671500027179718, 0.9440000057220459, 1.0439000129699707, 1.0155999660491943, 0.5623000264167786, 1.219099998474121, 1.145900011062622, 0.6394000053405762, 0.41190001368522644, 1.1119999885559082, 1.1369999647140503, -0.7120000123977661, 0.20069999992847443, 0.07940000295639038, 2.2653000354766846, 2.1338000297546387, 2.04259991645813, 2.024600028991699, 1.9980000257492065, 1.992799997329712, 1.9693000316619873, 1.8818000555038452, 1.8425999879837036, 1.8111000061035156, 1.7785999774932861, 1.7401000261306763, 1.7141000032424927, 1.6655000448226929, 1.655900001525879, 1.6527999639511108, 1.6378999948501587, 1.6207000017166138, 1.6197999715805054, 1.6031999588012695, 1.5988999605178833, 1.5910999774932861, 1.5769000053405762, 1.573699951171875, 1.5699000358581543, 1.5667999982833862, 1.5628000497817993, 1.549299955368042, 1.5181000232696533, 1.49399995803833, 1.4607000350952148, 1.4286999702453613, 1.299399971961975, 1.4579999446868896, 1.3350000381469727, 1.0676000118255615, 1.2447999715805054, 0.8245999813079834, 0.9138000011444092, 1.2060999870300293, 1.159999966621399, 0.958899974822998, 0.26910001039505005, 0.8980000019073486, 0.6086000204086304, 0.18549999594688416, 0.36820000410079956, 0.5008999705314636, -0.36489999294281006, -0.6247000098228455, 0.9448000192642212, 0.06989999860525131, -0.03689999878406525, 0.15029999613761902, 0.2793999910354614, 0.19179999828338623, -0.061900001019239426, 2.415600061416626, 2.156899929046631, 2.1459999084472656, 2.1159000396728516, 2.0936999320983887, 2.0671000480651855, 2.063199996948242, 2.039099931716919, 2.0325000286102295, 2.029900074005127, 2.0092999935150146, 2.0009000301361084, 1.9723000526428223, 1.9330999851226807, 1.923699975013733, 1.9088000059127808, 1.8916000127792358, 1.8669999837875366, 1.864799976348877, 1.8551000356674194, 1.8472000360488892, 1.8410999774932861, 1.8324999809265137, 1.8173999786376953, 1.7897000312805176, 1.7862000465393066, 1.7760000228881836, 1.7710000276565552, 1.7696000337600708, 1.7689000368118286, 1.7603000402450562, 1.5322999954223633, 1.714400053024292, 1.5176000595092773, 1.559399962425232, 1.5830999612808228, 1.590000033378601, 1.441499948501587, 0.9399999976158142, 0.7831000089645386, 1.107699990272522, 1.5262999534606934, 0.6326000094413757, 1.0298999547958374, 1.0520000457763672, 1.1995999813079834, 0.4253000020980835, 0.853600025177002, 0.6310999989509583, 1.1335999965667725, 0.3716999888420105, 0.8848000168800354, 0.6219000220298767, 0.7620000243186951, 0.7031999826431274, 0.2743000090122223, 0.03280000016093254, 0.7429999709129333, 0.2687999904155731, 2.4781999588012695, 2.473900079727173, 2.377000093460083, 2.3475000858306885, 2.3310999870300293, 2.314300060272217, 2.2939000129699707, 2.250200033187866, 2.2244999408721924, 2.218899965286255, 2.204400062561035, 2.2000999450683594, 2.1991000175476074, 2.186000108718872, 2.182800054550171, 2.1447999477386475, 2.122499942779541, 2.108799934387207, 2.0887999534606934, 2.0606000423431396, 2.0525999069213867, 2.051800012588501, 2.0283000469207764, 2.0065999031066895, 1.9903000593185425, 1.980299949645996, 1.9788999557495117, 1.9788000583648682, 1.9665000438690186, 1.9407999515533447, 1.8944000005722046, 1.7963999509811401, 1.7754000425338745, 1.771299958229065, 1.6447999477386475, 1.7293000221252441, 1.7933000326156616, 1.6812000274658203, 1.3335000276565552, 0.438400000333786, 1.2999999523162842, -0.09960000216960907, 1.1549999713897705, 1.2391999959945679, 0.3303000032901764, 1.4241000413894653, 1.256600022315979, 0.9024999737739563, 0.5425000190734863, -0.14350000023841858, 0.2816999852657318, 0.7303000092506409, 2.6895999908447266, 2.6633999347686768, 2.6417999267578125, 2.6191999912261963, 2.573699951171875, 2.527100086212158, 2.384700059890747, 2.3747000694274902, 2.361799955368042, 2.3155999183654785, 2.1944000720977783, 2.1760001182556152, 2.1403000354766846, 2.1396000385284424, 2.109600067138672, 2.0998001098632812, 2.0694000720977783, 2.0685999393463135, 2.0622000694274902, 2.055000066757202, 2.047800064086914, 2.032900094985962, 2.031399965286255, 2.0013999938964844, 1.9931999444961548, 1.9598000049591064, 1.9352999925613403, 1.9093999862670898, 1.8945000171661377, 1.8911999464035034, 1.8799999952316284, 1.8141000270843506, 1.8660999536514282, 1.8107000589370728, 1.5937000513076782, 1.4987000226974487, 1.7304999828338623, 1.0879000425338745, 0.5753999948501587, 0.8640999794006348, 0.7960000038146973, 0.9922999739646912, 0.9819999933242798, 1.1512000560760498, 0.9706000089645386, -0.1316000074148178, 0.7390999794006348, 0.9599000215530396, 0.917900025844574, 1.2782000303268433, 0.7617999911308289, 0.765500009059906, -0.2540000081062317, -0.5246999859809875, 0.033900000154972076, 0.7034000158309937, 0.3476000130176544, 3.0752999782562256, 2.7314999103546143, 2.653899908065796, 2.641700029373169, 2.530900001525879, 2.506999969482422, 2.473599910736084, 2.4221999645233154, 2.4110000133514404, 2.388400077819824, 2.3863000869750977, 2.382200002670288, 2.3805999755859375, 2.362600088119507, 2.3378000259399414, 2.3257999420166016, 2.3255999088287354, 2.319700002670288, 2.2818000316619873, 2.2746999263763428, 2.2672998905181885, 2.237799882888794, 2.2363998889923096, 2.2314000129699707, 2.2228000164031982, 2.2139999866485596, 2.194700002670288, 2.168600082397461, 2.14490008354187, 2.106600046157837, 2.04830002784729, 2.0069000720977783, 1.9860999584197998, 1.9385000467300415, 2.037400007247925, 2.0339999198913574, 1.6539000272750854, 1.8966000080108643, 1.813599944114685, 1.5223000049591064, 1.2244999408721924, 1.0795999765396118, 0.9641000032424927, 1.062999963760376, 1.2226999998092651, 1.0980000495910645, 1.6615999937057495, 0.2709999978542328, 1.3526999950408936, 0.9146999716758728, -0.6966999769210815, 2.96589994430542, 2.7221999168395996, 2.4972000122070312, 2.470900058746338, 2.4665000438690186, 2.4123001098632812, 2.3664000034332275, 2.3417000770568848, 2.2695000171661377, 2.2555999755859375, 2.255000114440918, 2.1796998977661133, 2.174999952316284, 2.1582999229431152, 2.156100034713745, 2.1559998989105225, 2.14490008354187, 2.1396000385284424, 2.1113998889923096, 2.0843000411987305, 2.0822999477386475, 2.0815999507904053, 2.0764999389648438, 2.0652999877929688, 1.9967999458312988, 1.996399998664856, 1.9940999746322632, 1.9608999490737915, 1.9472999572753906, 1.937600016593933, 1.937399983406067, 1.830299973487854, 1.7688000202178955, 1.458299994468689, 1.7080999612808228, 1.7329000234603882, 1.5601999759674072, 1.223099946975708, 1.1476000547409058, 0.5852000117301941, 1.493899941444397, 0.9487000107765198, 1.6265000104904175, 1.0190000534057617, 0.9955999851226807, 0.9753999710083008, 0.09220000356435776, -0.18219999969005585, 0.8403000235557556, 0.0357000008225441, 0.37709999084472656]}, \"token.table\": {\"Topic\": [1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 6, 9, 10, 4, 6, 7, 8, 1, 2, 3, 5, 8, 9, 1, 2, 3, 5, 8, 9, 2, 3, 8, 9, 1, 2, 4, 5, 6, 7, 9, 1, 2, 3, 6, 8, 9, 4, 5, 7, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 2, 7, 8, 1, 2, 3, 8, 1, 2, 3, 4, 6, 8, 4, 5, 6, 7, 10, 1, 1, 2, 3, 5, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 5, 7, 9, 10, 2, 4, 5, 7, 9, 2, 5, 7, 9, 10, 1, 2, 5, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 5, 6, 7, 8, 4, 5, 6, 7, 8, 10, 1, 4, 5, 7, 8, 10, 1, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 4, 8, 1, 3, 4, 7, 8, 9, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 5, 7, 9, 1, 2, 3, 5, 6, 8, 9, 10, 1, 4, 7, 8, 4, 5, 7, 8, 10, 1, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 7, 10, 2, 4, 5, 7, 9, 10, 1, 2, 3, 4, 10, 2, 3, 4, 5, 7, 8, 7, 8, 2, 4, 5, 6, 7, 9, 1, 6, 7, 1, 4, 6, 7, 1, 2, 3, 4, 5, 7, 10, 2, 3, 8, 2, 3, 7, 8, 1, 2, 3, 6, 7, 8, 1, 2, 3, 5, 6, 7, 8, 9, 10, 2, 4, 5, 6, 1, 2, 2, 3, 4, 7, 8, 9, 2, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 6, 1, 3, 4, 6, 7, 8, 9, 10, 1, 3, 4, 5, 7, 8, 9, 2, 3, 4, 7, 8, 4, 6, 7, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 7, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 9, 10, 1, 3, 6, 10, 1, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 5, 7, 8, 9, 1, 2, 3, 5, 6, 7, 4, 7, 8, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 5, 6, 7, 8, 2, 3, 5, 6, 7, 9, 1, 4, 5, 6, 7, 9, 1, 6, 1, 2, 3, 5, 6, 7, 8, 9, 1, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 6, 1, 2, 3, 2, 3, 6, 9, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 6, 9, 3, 4, 6, 7, 8, 9, 1, 4, 7, 1, 2, 3, 4, 5, 9, 10, 1, 2, 3, 9, 10, 2, 3, 5, 6, 1, 3, 6, 7, 8, 9, 1, 2, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 10, 1, 2, 2, 7, 8, 1, 2, 3, 6, 9, 10, 1, 2, 3, 6, 10, 1, 2, 3, 9, 1, 2, 3, 9, 1, 2, 3, 5, 6, 8, 10, 3, 6, 7, 8, 2, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 3, 5, 1, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 2, 3, 5, 7, 8, 2, 3, 5, 7, 8, 10, 1, 2, 3, 5, 6, 1, 2, 4, 5, 9, 2, 3, 4, 5, 7, 1, 2, 3, 5, 6, 7, 1, 2, 3, 6, 10, 1, 2, 3, 6, 9, 10, 2, 5, 6, 8, 9, 1, 4, 1, 2, 4, 5, 7, 8, 9, 10, 1, 3, 5, 8, 10, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 7, 8, 9, 2, 3, 5, 7, 8, 10, 2, 3, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 6, 2, 4, 5, 6, 7, 1, 3, 5, 4, 5, 6, 9, 1, 2, 4, 6, 8, 1, 3, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 9, 1, 2, 3, 2, 3, 8, 9, 1, 2, 3, 1, 3, 4, 5, 7, 1, 2, 6, 1, 6, 1, 2, 3, 4, 5, 6, 7, 9, 2, 4, 5, 7, 8, 10, 2, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 1, 2, 3, 4, 6, 8, 10, 1, 2, 3, 6, 9, 1, 4, 6, 9, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 5, 6, 7, 8, 10, 1, 2, 3, 5, 6, 8, 9, 10, 2, 4, 5, 7, 1, 3, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 7, 8, 9, 1, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 9, 1, 2, 4, 5, 7, 9, 2, 4, 7, 8, 9, 3, 4, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 6, 7, 8, 9, 10, 3, 4, 5, 7, 8, 9, 1, 2, 4, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 1, 2, 3, 5, 9, 10, 1, 2, 3, 5, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 6, 10, 1, 2, 3, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 9, 1, 2, 3, 5, 6, 7, 8, 9, 10, 3, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 10, 3, 5, 7, 8, 9, 10, 1, 2, 3, 5, 6, 1, 2, 3, 5, 6, 9, 10, 1, 2, 3, 5, 6, 7, 9, 10, 1, 3, 9, 10, 1, 3, 5, 9, 1, 3, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 8, 10, 1, 2, 3, 5, 9, 1, 2, 3, 5, 6, 10, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 1, 2, 3, 6, 9, 1, 2, 3, 1, 2, 3, 4, 6, 9, 10, 2, 3, 1, 2, 3, 7, 10, 4, 6, 7, 9, 1, 2, 3, 5, 10, 1, 4, 7, 8, 10, 1, 2, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 2, 4, 5, 8, 1, 5, 6, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 4, 5, 8, 10, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 7, 8, 9, 2, 5, 7, 2, 5, 7, 9, 1, 2, 4, 5, 6, 7, 9, 2, 5, 6, 7, 8, 9, 10, 1, 3, 6, 7, 8, 9, 1, 2, 3, 10, 1, 2, 3, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 3, 4, 5, 7, 8, 9, 3, 4, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 5, 10, 4, 5, 7, 9, 10, 1, 2, 4, 5, 6, 7, 8, 9, 10, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 8, 9, 1, 2, 3, 6, 1, 2, 3, 6, 2, 4, 7, 1, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 9, 10, 2, 4, 5, 6, 7, 9, 1, 3, 5, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 9, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 6, 1, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 10, 1, 2, 4, 5, 6, 1, 2, 4, 6, 7, 10, 1, 2, 3, 5, 7, 10, 1, 2, 3, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 5, 7, 9, 1, 2, 5, 7, 10, 1, 2, 4, 5, 7, 1, 2, 3, 5, 6, 8, 9, 1, 2, 4, 6, 7, 10, 1, 6, 7, 10, 2, 4, 5, 6, 8, 10, 1, 3, 5, 6, 7, 9, 1, 2, 5, 8, 1, 3, 5, 6, 8, 10, 2, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 1, 2, 3, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 9, 2, 4, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 7, 8, 1, 2, 3, 6, 10, 1, 2, 3, 5, 8, 9, 1, 2, 3, 8, 1, 2, 3, 2, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 8, 9, 1, 1, 3, 5, 6, 7, 8, 9, 10, 1, 2, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 9, 2, 4, 5, 7, 8, 9, 1, 3, 4, 5, 7, 9, 1, 2, 3, 6, 7, 8, 9, 10, 1, 6, 10, 1, 2, 5, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 1, 2, 3, 4, 5, 8, 9, 1, 7, 9, 1, 4, 6, 7, 9, 1, 2, 3, 6, 10, 1, 2, 3, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 7, 10, 1, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 7, 8, 2, 3, 4, 7, 8, 1, 4, 6, 7, 1, 2, 3, 5, 9, 1, 3, 5, 3, 4, 5, 6, 7, 9, 10, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 4, 6, 7, 8, 9, 10, 1, 6, 10, 1, 2, 4, 7, 9, 10, 2, 3, 5, 7, 1, 2, 3, 5, 9, 10, 1, 2, 4, 5, 8, 2, 4, 6, 7, 8, 9, 1, 2, 3, 5, 6, 8, 10, 1, 2, 3, 4, 6, 7, 8, 2, 7, 8, 2, 3, 4, 5, 6, 7, 8, 10, 2, 3, 5, 6, 10, 1, 2, 4, 6, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 8, 9, 4, 6, 7, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 9, 1, 2, 4, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 5, 6, 9, 10, 2, 4, 5, 6, 7, 9, 10, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 6, 2, 4, 5, 6, 7, 10, 1, 4, 5, 7, 9, 1, 2, 3, 5, 6, 8, 9, 3, 4, 5, 6, 7, 8, 9, 2, 3, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 1, 3, 6, 7, 9, 10, 1, 6, 9, 10, 1, 2, 6, 10, 1, 2, 3, 4, 5, 6, 7, 9, 4, 5, 6, 7, 9, 1, 2, 4, 6, 7, 8, 9, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 9, 10, 1, 2, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 5, 6, 7, 8, 9, 10, 1, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 6, 7, 8, 1, 5, 6, 1, 3, 6, 2, 3, 5, 7, 2, 3, 4, 6, 7, 8, 9, 1, 2, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 3, 1, 2, 3, 5, 8, 1, 2, 3, 5, 6, 9, 10, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 8, 2, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 8, 2, 4, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 3, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 8, 9, 10, 1, 2, 3, 9, 4, 5, 6, 8], \"Freq\": [0.26039919257164, 0.05786648392677307, 0.5497316122055054, 0.11573296785354614, 0.03823686018586159, 0.13170474767684937, 0.08072226494550705, 0.07647372037172318, 0.21242700517177582, 0.05947956070303917, 0.1444503664970398, 0.1996813863515854, 0.0042485399171710014, 0.06372810155153275, 0.019367260858416557, 0.019367260858416557, 0.05810178071260452, 0.17430533468723297, 0.11620356142520905, 0.019367260858416557, 0.13557082414627075, 0.4648142457008362, 0.1104058250784874, 0.5299479961395264, 0.1324869990348816, 0.2208116501569748, 0.6250631809234619, 0.18384210765361786, 0.07353684306144714, 0.11030527204275131, 0.026156272739171982, 0.5688989162445068, 0.1307813674211502, 0.07846882194280624, 0.14385950565338135, 0.045773476362228394, 0.032377831637859344, 0.5471853613853455, 0.12951132655143738, 0.07446900755167007, 0.16512693464756012, 0.04856674745678902, 0.7035821080207825, 0.19543947279453278, 0.06840381771326065, 0.019543947651982307, 0.05411388352513313, 0.03607592359185219, 0.3787972033023834, 0.10822776705026627, 0.018037961795926094, 0.05411388352513313, 0.34272128343582153, 0.1263618916273117, 0.07220679521560669, 0.07220679521560669, 0.18051698803901672, 0.4512924551963806, 0.09025849401950836, 0.8649380803108215, 0.05863986909389496, 0.02931993454694748, 0.01465996727347374, 0.02931993454694748, 0.20723280310630798, 0.1141895055770874, 0.0042292410507798195, 0.0380631685256958, 0.012687723152339458, 0.4736749827861786, 0.13533571362495422, 0.008458482101559639, 0.0042292410507798195, 0.03305979445576668, 0.7438454031944275, 0.19835877418518066, 0.7412655353546143, 0.15205447375774384, 0.028510212898254395, 0.08553063869476318, 0.6276476383209229, 0.07322555780410767, 0.14122071862220764, 0.01569119095802307, 0.11506873369216919, 0.026151984930038452, 0.6417708396911621, 0.035653937608003616, 0.035653937608003616, 0.2139236181974411, 0.035653937608003616, 0.9628838896751404, 0.2414080649614334, 0.07100237160921097, 0.05680190026760101, 0.1846061646938324, 0.04260142520070076, 0.38341280817985535, 0.014200475066900253, 0.11418608576059341, 0.15843318402767181, 0.08135758340358734, 0.19982564449310303, 0.1027674749493599, 0.044247105717659, 0.09848549962043762, 0.06565699726343155, 0.1027674749493599, 0.031401172280311584, 0.2921469807624817, 0.2921469807624817, 0.04173528030514717, 0.020867640152573586, 0.10433820635080338, 0.2504116892814636, 0.09265367686748505, 0.04632683843374252, 0.05559220910072327, 0.3798801004886627, 0.42620691657066345, 0.008505469188094139, 0.025516407564282417, 0.5188336372375488, 0.42527344822883606, 0.008505469188094139, 0.029678169637918472, 0.029678169637918472, 0.3264598548412323, 0.059356339275836945, 0.5045288801193237, 0.029678169637918472, 0.026263248175382614, 0.06303179264068604, 0.03676854819059372, 0.01575794816017151, 0.49374905228614807, 0.1628321409225464, 0.14707419276237488, 0.01575794816017151, 0.03676854819059372, 0.2720785140991211, 0.038868360221385956, 0.11660508066415787, 0.5441570281982422, 0.2942824065685272, 0.08828472346067429, 0.20599769055843353, 0.029428239911794662, 0.058856479823589325, 0.26485416293144226, 0.06429290771484375, 0.17144775390625, 0.06429290771484375, 0.5786361694335938, 0.02143096923828125, 0.10715484619140625, 0.0892108678817749, 0.09885528683662415, 0.014466626569628716, 0.07233313471078873, 0.019288836047053337, 0.6461759805679321, 0.05786650627851486, 0.10531716048717499, 0.21063432097434998, 0.0962899774312973, 0.17452558875083923, 0.09027185291051865, 0.2016071379184723, 0.03309968113899231, 0.04513592645525932, 0.006018123589456081, 0.03911780193448067, 0.1785489171743393, 0.26782336831092834, 0.5356467366218567, 0.6399502754211426, 0.14026308059692383, 0.16656240820884705, 0.026299327611923218, 0.026299327611923218, 0.13903135061264038, 0.08341880887746811, 0.05561254173517227, 0.19464388489723206, 0.08341880887746811, 0.41709405183792114, 0.6286142468452454, 0.11973605304956436, 0.07483503222465515, 0.014967006631195545, 0.1496700644493103, 0.014967006631195545, 0.1960522085428238, 0.250302255153656, 0.2755473554134369, 0.031153500080108643, 0.05156441405415535, 0.008056939579546452, 0.06445551663637161, 0.1117229014635086, 0.011279716156423092, 0.006414645351469517, 0.6991963386535645, 0.28224438428878784, 0.03588308393955231, 0.10764924436807632, 0.07176616787910461, 0.7714862823486328, 0.21950408816337585, 0.24208681285381317, 0.2610563039779663, 0.037938978523015976, 0.03703567013144493, 0.0063231629319489, 0.11020369827747345, 0.04877868667244911, 0.026195960119366646, 0.010839708149433136, 0.3578113913536072, 0.0477081835269928, 0.5247900485992432, 0.0119270458817482, 0.0119270458817482, 0.0357811376452446, 0.01398382056504488, 0.657239556312561, 0.3216278851032257, 0.5483895540237427, 0.09287242591381073, 0.053069960325956345, 0.066337451338768, 0.10613992065191269, 0.03537997230887413, 0.004422496538609266, 0.09287242591381073, 0.03081141784787178, 0.13865137100219727, 0.3389256000518799, 0.47757697105407715, 0.610537052154541, 0.038158565759658813, 0.11447569727897644, 0.15263426303863525, 0.038158565759658813, 0.27060022950172424, 0.09020008146762848, 0.6314005255699158, 0.12225309759378433, 0.2868245542049408, 0.11284901201725006, 0.34795111417770386, 0.07993471622467041, 0.004702042322605848, 0.009404084645211697, 0.03291429579257965, 0.009404084645211697, 0.0207220371812582, 0.0207220371812582, 0.8786143660545349, 0.0704549252986908, 0.008288814686238766, 0.08464755117893219, 0.005290471948683262, 0.13226179778575897, 0.08993802219629288, 0.07406660169363022, 0.07406660169363022, 0.3703330159187317, 0.04761424660682678, 0.08993802219629288, 0.026452358812093735, 0.07211963832378387, 0.5408973097801208, 0.21635891497135162, 0.07211963832378387, 0.03605981916189194, 0.17521880567073822, 0.37964072823524475, 0.014601566828787327, 0.014601566828787327, 0.3650391697883606, 0.029203133657574654, 0.33499953150749207, 0.08039988577365875, 0.10719985514879227, 0.040199942886829376, 0.42879942059516907, 0.036841947585344315, 0.2947355806827545, 0.05526292324066162, 0.036841947585344315, 0.14736779034137726, 0.42368239164352417, 0.07947023957967758, 0.9006627202033997, 0.10383595526218414, 0.539946973323822, 0.04153438284993172, 0.19728831946849823, 0.09345235675573349, 0.01038359571248293, 0.3811820149421692, 0.4658891260623932, 0.0847071185708046, 0.21857106685638428, 0.03642851114273071, 0.50999915599823, 0.18214255571365356, 0.08035359531641006, 0.2410607784986496, 0.04017679765820503, 0.14061878621578217, 0.10044199228286743, 0.08035359531641006, 0.3013259768486023, 0.031394559890031815, 0.06278911978006363, 0.8476531505584717, 0.07245331257581711, 0.04140189290046692, 0.21735994517803192, 0.6624302864074707, 0.007371176034212112, 0.007371176034212112, 0.007371176034212112, 0.014742352068424225, 0.13268117606639862, 0.8255717158317566, 0.10977980494499207, 0.1646697074174881, 0.08981984108686447, 0.508979082107544, 0.004989991430193186, 0.02494995668530464, 0.03492993861436844, 0.004989991430193186, 0.04989991337060928, 0.26526910066604614, 0.14737172424793243, 0.501063883304596, 0.05894869193434715, 0.3723142147064209, 0.6143184304237366, 0.11290854960680008, 0.15807196497917175, 0.011290854774415493, 0.429052472114563, 0.25968965888023376, 0.011290854774415493, 0.17394399642944336, 0.23533599078655243, 0.07162399590015411, 0.5116000175476074, 0.10390954464673996, 0.04849112033843994, 0.31865593791007996, 0.0900549367070198, 0.08312764018774033, 0.062345728278160095, 0.04849112033843994, 0.2424556016921997, 0.8067538738250732, 0.06050654128193855, 0.06050654128193855, 0.06050654128193855, 0.24717830121517181, 0.1896454244852066, 0.09908440709114075, 0.011719660833477974, 0.05859830603003502, 0.21201932430267334, 0.046878643333911896, 0.0021308474242687225, 0.012785084545612335, 0.12039288133382797, 0.05953580141067505, 0.20837530493736267, 0.1190716028213501, 0.6251259446144104, 0.026925547048449516, 0.11443357169628143, 0.12789635360240936, 0.4846598505973816, 0.07404525578022003, 0.013462773524224758, 0.12789635360240936, 0.02019415982067585, 0.1766151487827301, 0.03532303124666214, 0.10596908628940582, 0.01766151562333107, 0.07064606249332428, 0.5475069284439087, 0.03532303124666214, 0.11893600970506668, 0.07929067313671112, 0.15858134627342224, 0.5946800112724304, 0.03964533656835556, 0.051133815199136734, 0.03195863589644432, 0.8437079787254333, 0.07030899822711945, 0.04216578230261803, 0.04216578230261803, 0.25299468636512756, 0.007666505873203278, 0.05749879404902458, 0.1571633666753769, 0.15333011746406555, 0.2874939739704132, 0.11266683787107468, 0.6760010123252869, 0.03755561262369156, 0.1877780705690384, 0.04832341521978378, 0.05798809975385666, 0.1401379108428955, 0.0628204420208931, 0.0628204420208931, 0.4204137325286865, 0.1642996221780777, 0.038658734411001205, 0.8067415952682495, 0.13445693254470825, 0.06722846627235413, 0.24904519319534302, 0.1328240931034088, 0.0207537654787302, 0.1494271159172058, 0.3528140187263489, 0.0332060232758522, 0.012452259659767151, 0.045658282935619354, 0.35807424783706665, 0.10799064487218857, 0.23492702841758728, 0.005683718249201775, 0.0037891454994678497, 0.12598909437656403, 0.0009472863748669624, 0.0009472863748669624, 0.009472863748669624, 0.151565819978714, 0.32562315464019775, 0.21877805888652802, 0.2560890316963196, 0.01865549199283123, 0.067838154733181, 0.0016959538916125894, 0.11193295568227768, 0.7435860633850098, 0.053113292902708054, 0.10622658580541611, 0.10622658580541611, 0.12823325395584106, 0.822830080986023, 0.032058313488960266, 0.3808553218841553, 0.13621832430362701, 0.03891952335834503, 0.013899829238653183, 0.05837928503751755, 0.1334383636713028, 0.07783904671669006, 0.07227911055088043, 0.022239727899432182, 0.0667191818356514, 0.7232029438018799, 0.10583458095788956, 0.017639096826314926, 0.05291729047894478, 0.05291729047894478, 0.05291729047894478, 0.07440372556447983, 0.03188731148838997, 0.07440372556447983, 0.7440372109413147, 0.02125820703804493, 0.05314551666378975, 0.07657007873058319, 0.43207401037216187, 0.48676690459251404, 0.07507176697254181, 0.6099581122398376, 0.3096710443496704, 0.1883617341518402, 0.06027575582265854, 0.03767234832048416, 0.03013787791132927, 0.4822060465812683, 0.12808598577976227, 0.04520681872963905, 0.03013787791132927, 0.20778010785579681, 0.20778010785579681, 0.5639746189117432, 0.5893616080284119, 0.04911346733570099, 0.0920877531170845, 0.024556733667850494, 0.024556733667850494, 0.006139183416962624, 0.21487142145633698, 0.05533409118652344, 0.05533409118652344, 0.036889392882585526, 0.11066818237304688, 0.6640090942382812, 0.018444696441292763, 0.036889392882585526, 0.02996763028204441, 0.5094497203826904, 0.11987052112817764, 0.20977340638637543, 0.05993526056408882, 0.05993526056408882, 0.06925217807292938, 0.05935901030898094, 0.02967950515449047, 0.40561991930007935, 0.3759404122829437, 0.0494658425450325, 0.054923951625823975, 0.9337071776390076, 0.09968781471252441, 0.12817004323005676, 0.04984390735626221, 0.39875125885009766, 0.09256725758314133, 0.07120557874441147, 0.13529060781002045, 0.02136167325079441, 0.0721297487616539, 0.02885189838707447, 0.08655569702386856, 0.11540759354829788, 0.04327784851193428, 0.15868544578552246, 0.49048230051994324, 0.5114660263061523, 0.2062702476978302, 0.07998234033584595, 0.0042095971293747425, 0.023152783513069153, 0.10734472423791885, 0.0042095971293747425, 0.0021047985646873713, 0.05893435701727867, 0.9211961030960083, 0.04386648163199425, 0.2012876719236374, 0.6326183676719666, 0.11502151936292648, 0.6167073249816895, 0.1121286004781723, 0.2242572009563446, 0.028032150119543076, 0.23211553692817688, 0.28658533096313477, 0.1745508909225464, 0.0006189747946336865, 0.06684927642345428, 0.15536266565322876, 0.0006189747946336865, 0.01980719342827797, 0.06313543021678925, 0.2961430549621582, 0.07793238759040833, 0.6234591007232666, 0.15415918827056885, 0.041870396584272385, 0.1636751890182495, 0.2645447850227356, 0.11609518527984619, 0.060902394354343414, 0.09515999257564545, 0.036160796880722046, 0.05138639360666275, 0.013322398997843266, 0.05509152635931969, 0.027545763179659843, 0.19282034039497375, 0.027545763179659843, 0.6748712062835693, 0.21125763654708862, 0.053347889333963394, 0.32648909091949463, 0.014937409199774265, 0.11949927359819412, 0.038410481065511703, 0.04054439440369606, 0.13870450854301453, 0.010669577866792679, 0.04694614186882973, 0.026263197883963585, 0.3834426701068878, 0.33616891503334045, 0.20485293865203857, 0.04202111437916756, 0.09461668878793716, 0.6150084733963013, 0.02365417219698429, 0.09461668878793716, 0.1182708591222763, 0.02365417219698429, 0.08663805574178696, 0.8663805723190308, 0.028879351913928986, 0.15956735610961914, 0.40042373538017273, 0.3432203531265259, 0.003010704880580306, 0.003010704880580306, 0.006021409761160612, 0.084299735724926, 0.16977675259113312, 0.3529569208621979, 0.4155062437057495, 0.004467809107154608, 0.05361371114850044, 0.6516277194023132, 0.0662672221660614, 0.2650688886642456, 0.011044537648558617, 0.061360593885183334, 0.01840817928314209, 0.04295241832733154, 0.6442862749099731, 0.07363271713256836, 0.15340149402618408, 0.26794639229774475, 0.10305630415678024, 0.041222523897886276, 0.4946702718734741, 0.10305630415678024, 0.27002182602882385, 0.1434490978717804, 0.13669855892658234, 0.15357491374015808, 0.08269418776035309, 0.047253821045160294, 0.05400436744093895, 0.05400436744093895, 0.005062909331172705, 0.052316728979349136, 0.06693056225776672, 0.17150957882404327, 0.1129453256726265, 0.02509896270930767, 0.09202952682971954, 0.17987589538097382, 0.01673264056444168, 0.00418316014111042, 0.012549481354653835, 0.31373703479766846, 0.1786969155073166, 0.16245174407958984, 0.08122587203979492, 0.048735521733760834, 0.1462065577507019, 0.37363898754119873, 0.7557699084281921, 0.20993608236312866, 0.06277205049991608, 0.03138602524995804, 0.8788086771965027, 0.724714457988739, 0.12941329181194305, 0.034510210156440735, 0.017255105078220367, 0.0517653152346611, 0.04313776269555092, 0.8106906414031982, 0.09886471182107925, 0.05931882932782173, 0.01977294310927391, 0.01977294310927391, 0.24898165464401245, 0.36425092816352844, 0.3780832588672638, 0.0046107713133096695, 0.25382354855537415, 0.33843138813972473, 0.39659926295280457, 0.005287990439683199, 0.21214157342910767, 0.14584733545780182, 0.06629423797130585, 0.12595905363559723, 0.16573560237884521, 0.0928119346499443, 0.17899444699287415, 0.02902403473854065, 0.02902403473854065, 0.2321922779083252, 0.6965768337249756, 0.06036080792546272, 0.6036080718040466, 0.21126282215118408, 0.09054121375083923, 0.03018040396273136, 0.03018040396273136, 0.1494913548231125, 0.16784994304180145, 0.08130232244729996, 0.0026226553600281477, 0.031471867114305496, 0.23079368472099304, 0.03671717643737793, 0.20456711947917938, 0.09441559761762619, 0.058091990649700165, 0.9294718503952026, 0.03277778998017311, 0.8194447755813599, 0.03277778998017311, 0.016388894990086555, 0.03277778998017311, 0.049166686832904816, 0.20184622704982758, 0.06728208065032959, 0.06728208065032959, 0.3128616511821747, 0.06391797214746475, 0.17493340373039246, 0.05718976631760597, 0.043733350932598114, 0.016820520162582397, 0.2519395053386688, 0.05303989350795746, 0.013259973376989365, 0.05303989350795746, 0.15911968052387238, 0.02651994675397873, 0.41105917096138, 0.02651994675397873, 0.06506660580635071, 0.24399977922439575, 0.13013321161270142, 0.032533302903175354, 0.5205328464508057, 0.041990384459495544, 0.26243990659713745, 0.09447836875915527, 0.020995192229747772, 0.3569182753562927, 0.2204495221376419, 0.009724012576043606, 0.01944802515208721, 0.4667526185512543, 0.48620063066482544, 0.01944802515208721, 0.09627225250005722, 0.7426716685295105, 0.05501271411776543, 0.06876589357852936, 0.027506357058882713, 0.1620018631219864, 0.5872567296028137, 0.0405004657804966, 0.14175163209438324, 0.0405004657804966, 0.06161653995513916, 0.1540413498878479, 0.6161653995513916, 0.06161653995513916, 0.06161653995513916, 0.06161653995513916, 0.7891754508018494, 0.04384307935833931, 0.06576462090015411, 0.021921539679169655, 0.06576462090015411, 0.07998338341712952, 0.02666112780570984, 0.22661958634853363, 0.2132890224456787, 0.09331394731998444, 0.3332641124725342, 0.14408932626247406, 0.6003721952438354, 0.16810421645641327, 0.02401488833129406, 0.02401488833129406, 0.8617963194847107, 0.1149061769247055, 0.009247846901416779, 0.05548708140850067, 0.05548708140850067, 0.20345263183116913, 0.3791617155075073, 0.12022200971841812, 0.12022200971841812, 0.036991387605667114, 0.17392364144325256, 0.17392364144325256, 0.4869861900806427, 0.03478472679853439, 0.10435418039560318, 0.03122904524207115, 0.1249161809682846, 0.09368713200092316, 0.09368713200092316, 0.21860331296920776, 0.4372066259384155, 0.08390571922063828, 0.019977552816271782, 0.1118742898106575, 0.1118742898106575, 0.0599326565861702, 0.2557126581668854, 0.04794612526893616, 0.1198653131723404, 0.07991021126508713, 0.1118742898106575, 0.1601434350013733, 0.035587430000305176, 0.10676229000091553, 0.053381145000457764, 0.5516051650047302, 0.035587430000305176, 0.053381145000457764, 0.017214801162481308, 0.7574512362480164, 0.12050361186265945, 0.034429602324962616, 0.017214801162481308, 0.051644403487443924, 0.14131727814674377, 0.051388099789619446, 0.1670113205909729, 0.17985834181308746, 0.41110479831695557, 0.038541074842214584, 0.1771702617406845, 0.5376201272010803, 0.07331182807683945, 0.012218638323247433, 0.11302240937948227, 0.021382616832852364, 0.054983872920274734, 0.012218638323247433, 0.003054659580811858, 0.09026623517274857, 0.8003606200218201, 0.07221298664808273, 0.030088745057582855, 0.7169636487960815, 0.08193870633840561, 0.14339272677898407, 0.020484676584601402, 0.040969353169202805, 0.7847503423690796, 0.07473812997341156, 0.11210718750953674, 0.5733490586280823, 0.0764465406537056, 0.3057861626148224, 0.0382232703268528, 0.13927718997001648, 0.10445788502693176, 0.06963859498500824, 0.5571087598800659, 0.10445788502693176, 0.025327008217573166, 0.10130803287029266, 0.5318671464920044, 0.05065401643514633, 0.3039240837097168, 0.04629563167691231, 0.6530770063400269, 0.2635764479637146, 0.0006172750727273524, 0.0024691002909094095, 0.004938200581818819, 0.0012345501454547048, 0.015431876294314861, 0.011110951192677021, 0.0012345501454547048, 0.009683666750788689, 0.7004518508911133, 0.2840542197227478, 0.0032278888393193483, 0.012828871607780457, 0.6991735100746155, 0.2758207321166992, 0.7064684629440308, 0.20323064923286438, 0.07742119580507278, 0.019355298951268196, 0.006497063674032688, 0.7081799507141113, 0.27937373518943787, 0.02713830955326557, 0.17639902234077454, 0.6377502679824829, 0.10855323821306229, 0.02713830955326557, 0.3459753096103668, 0.11532510071992874, 0.5381838083267212, 0.4340877830982208, 0.5209053754806519, 0.06743849813938141, 0.050578873604536057, 0.06743849813938141, 0.5563676357269287, 0.06743849813938141, 0.10115774720907211, 0.050578873604536057, 0.033719249069690704, 0.1064484640955925, 0.04562076926231384, 0.2281038463115692, 0.030413847416639328, 0.5626561641693115, 0.015206923708319664, 0.0033389509189873934, 0.013355803675949574, 0.053423214703798294, 0.9248893857002258, 0.1696585863828659, 0.07846710085868835, 0.09543295949697495, 0.1929866522550583, 0.1590549349784851, 0.1548134684562683, 0.04877684637904167, 0.04029391333460808, 0.008482929319143295, 0.05301830917596817, 0.9150829911231995, 0.01867516338825226, 0.056025490164756775, 0.6698617935180664, 0.2191523164510727, 0.039282020181417465, 0.010337373241782188, 0.00826989859342575, 0.020674746483564377, 0.031012119725346565, 0.15085236728191376, 0.08045459538698196, 0.11062506586313248, 0.5933526158332825, 0.060340944677591324, 0.3010293245315552, 0.0376286655664444, 0.48917266726493835, 0.1505146622657776, 0.030746623873710632, 0.5657379031181335, 0.06764257699251175, 0.11683717370033264, 0.15373311936855316, 0.061493247747421265, 0.006149325054138899, 0.280470609664917, 0.07011765241622925, 0.47524186968803406, 0.007790850009769201, 0.038954250514507294, 0.031163400039076805, 0.007790850009769201, 0.1012810543179512, 0.10359424352645874, 0.23073261976242065, 0.2684032618999481, 0.10830307006835938, 0.009417657740414143, 0.11301189661026001, 0.004708828870207071, 0.1553913652896881, 0.2442423403263092, 0.10855215042829514, 0.027138037607073784, 0.5970368385314941, 0.041560012847185135, 0.06234002113342285, 0.41560012102127075, 0.041560012847185135, 0.3324801027774811, 0.1246800422668457, 0.07516590505838394, 0.19608496129512787, 0.15359988808631897, 0.2908593714237213, 0.13072331249713898, 0.08823823183774948, 0.013072330504655838, 0.04575315862894058, 0.0032680826261639595, 0.12562483549118042, 0.16749978065490723, 0.15912479162216187, 0.24287468194961548, 0.24706217646598816, 0.033499956130981445, 0.004187494516372681, 0.004187494516372681, 0.004187494516372681, 0.008374989032745361, 0.7207677960395813, 0.12493308633565903, 0.07688190042972565, 0.057661425322294235, 0.019220475107431412, 0.8568505644798279, 0.05423105135560036, 0.07592347264289856, 0.191932812333107, 0.06533883512020111, 0.3328196704387665, 0.006125515326857567, 0.12659399211406708, 0.07963170111179352, 0.05104596167802811, 0.08984089642763138, 0.010209192521870136, 0.04492044821381569, 0.029088592156767845, 0.029088592156767845, 0.11635436862707138, 0.17453154921531677, 0.029088592156767845, 0.05817718431353569, 0.23270873725414276, 0.34906309843063354, 0.1946534514427185, 0.6704729795455933, 0.04325632378458977, 0.0648844838142395, 0.04325632378458977, 0.21262140572071075, 0.7323626279830933, 0.0472492016851902, 0.2400483340024948, 0.15099814534187317, 0.054204463958740234, 0.07356320321559906, 0.19358737766742706, 0.03871747478842735, 0.06581970304250717, 0.003871747525408864, 0.1781003773212433, 0.06276746839284897, 0.12553493678569794, 0.5021397471427917, 0.31383734941482544, 0.014624795876443386, 0.6142414212226868, 0.007312397938221693, 0.16087275743484497, 0.0731239840388298, 0.08774877339601517, 0.029249591752886772, 0.007312397938221693, 0.33949214220046997, 0.08627358078956604, 0.17366759479045868, 0.007843052968382835, 0.11652535200119019, 0.11988665908575058, 0.06162398308515549, 0.006722616497427225, 0.051540058106184006, 0.03697438910603523, 0.43991026282310486, 0.5065633654594421, 0.026661228388547897, 0.013330614194273949, 0.07009854167699814, 0.09346472471952438, 0.210295632481575, 0.023366181179881096, 0.49068981409072876, 0.11683090776205063, 0.0619160458445549, 0.20638681948184967, 0.660437822341919, 0.041277363896369934, 0.020638681948184967, 0.1266084611415863, 0.09495634585618973, 0.18991269171237946, 0.5064338445663452, 0.06330423057079315, 0.11274602264165878, 0.05167526379227638, 0.07046626508235931, 0.3617268204689026, 0.07986176759004593, 0.21609655022621155, 0.046977512538433075, 0.05167526379227638, 0.009395502507686615, 0.031035762280225754, 0.11897042393684387, 0.06207152456045151, 0.1706966906785965, 0.06724414974451065, 0.11897042393684387, 0.24828609824180603, 0.04138101637363434, 0.12931567430496216, 0.010345254093408585, 0.02124340459704399, 0.05310851335525513, 0.06373021751642227, 0.14870382845401764, 0.2549208700656891, 0.010621702298521996, 0.2974076569080353, 0.14870382845401764, 0.017733654007315636, 0.6029442548751831, 0.07093461602926254, 0.053200963884592056, 0.14186923205852509, 0.08866827189922333, 0.2512069046497345, 0.21532021462917328, 0.10766010731458664, 0.07177340239286423, 0.3229803144931793, 0.24801498651504517, 0.11798771470785141, 0.08186902105808258, 0.07223737239837646, 0.27931785583496094, 0.00963164959102869, 0.012039562687277794, 0.09872440993785858, 0.04093451052904129, 0.03611868619918823, 0.32577621936798096, 0.5791577100753784, 0.03619735687971115, 0.4811166524887085, 0.16870324313640594, 0.031241342425346375, 0.02499307319521904, 0.00624826829880476, 0.2811720669269562, 0.48706701397895813, 0.17078973352909088, 0.031627729535102844, 0.025302182883024216, 0.2783240079879761, 0.6287462711334229, 0.10438644886016846, 0.05340701714158058, 0.0072827753610908985, 0.014565550722181797, 0.04612424224615097, 0.00971036683768034, 0.11409681290388107, 0.021848326548933983, 0.5617897510528564, 0.0060407500714063644, 0.1268557459115982, 0.09665200114250183, 0.19934475421905518, 0.7197420597076416, 0.009347299113869667, 0.14020949602127075, 0.06543109565973282, 0.06543109565973282, 0.0731908306479454, 0.012916029430925846, 0.012916029430925846, 0.107633575797081, 0.038748085498809814, 0.39178621768951416, 0.22818318009376526, 0.030137401074171066, 0.0731908306479454, 0.03444274514913559, 0.24934324622154236, 0.016622884199023247, 0.6649153232574463, 0.033245768398046494, 0.033245768398046494, 0.14815595746040344, 0.06667017936706543, 0.14074815809726715, 0.03703898936510086, 0.5481770038604736, 0.014815595000982285, 0.007407797500491142, 0.014815595000982285, 0.022223392501473427, 0.15272247791290283, 0.1357533186674118, 0.10181498527526855, 0.6108899116516113, 0.2594327926635742, 0.1633465588092804, 0.07046322524547577, 0.06726034730672836, 0.05765172839164734, 0.11530345678329468, 0.14733219146728516, 0.02882586419582367, 0.06405747681856155, 0.02882586419582367, 0.7733021378517151, 0.10086549818515778, 0.10086549818515778, 0.06817536056041718, 0.20452608168125153, 0.5454028844833374, 0.040905218571424484, 0.09544550627470016, 0.040905218571424484, 0.02901924028992653, 0.043528858572244644, 0.7109713554382324, 0.02901924028992653, 0.18862506747245789, 0.4357523024082184, 0.17062589526176453, 0.11550060659646988, 0.010500054806470871, 0.16800087690353394, 0.03937520831823349, 0.05775030329823494, 0.2860846519470215, 0.07258864492177963, 0.04269920289516449, 0.04269920289516449, 0.27327489852905273, 0.008539840579032898, 0.07685856521129608, 0.19641633331775665, 0.13315995037555695, 0.04438664764165878, 0.443866491317749, 0.37728652358055115, 0.11814289540052414, 0.3150477111339569, 0.137833371758461, 0.39380964636802673, 0.09109600633382797, 0.38715803623199463, 0.09109600633382797, 0.40993204712867737, 0.19344158470630646, 0.0564204640686512, 0.3425528109073639, 0.1652313619852066, 0.08463069796562195, 0.06851056218147278, 0.01612013205885887, 0.01612013205885887, 0.03224026411771774, 0.024180198088288307, 0.4898776710033417, 0.3505159318447113, 0.059123165905475616, 0.046453919261693954, 0.03800775110721588, 0.01266925036907196, 0.7347694039344788, 0.0864434614777565, 0.014407243579626083, 0.12966519594192505, 0.028814487159252167, 0.7231605648994446, 0.08148287981748581, 0.08148287981748581, 0.10185360163450241, 0.005092679988592863, 0.005092679988592863, 0.04736315831542015, 0.5920394659042358, 0.14208947122097015, 0.023681579157710075, 0.13024868071079254, 0.04736315831542015, 0.22348187863826752, 0.5043175220489502, 0.1931569129228592, 0.006592385936528444, 0.0006592386052943766, 0.025051066651940346, 0.03691736236214638, 0.009229340590536594, 0.006414709147065878, 0.6992033123970032, 0.2822472155094147, 0.14726002514362335, 0.6037660837173462, 0.244451642036438, 0.00294520054012537, 0.00294520054012537, 0.006497121881693602, 0.7016891837120056, 0.27937623858451843, 0.19774028658866882, 0.4435795545578003, 0.23247843980789185, 0.008016497828066349, 0.016032995656132698, 0.008016497828066349, 0.09619797766208649, 0.8280083537101746, 0.1656016707420349, 0.36493703722953796, 0.233559712767601, 0.07298740744590759, 0.029194964095950127, 0.27735215425491333, 0.14665092527866364, 0.21997638046741486, 0.07332546263933182, 0.5621618628501892, 0.48400139808654785, 0.17600050568580627, 0.031428661197423935, 0.025142928585410118, 0.2828579545021057, 0.2047022581100464, 0.08529260754585266, 0.08529260754585266, 0.4776386022567749, 0.11940965056419373, 0.23859530687332153, 0.15906353294849396, 0.026510588824748993, 0.5567224025726318, 0.11113250255584717, 0.2763294577598572, 0.132157564163208, 0.1381647288799286, 0.06007162109017372, 0.039046552032232285, 0.0690823644399643, 0.1351611465215683, 0.009010743349790573, 0.02703223004937172, 0.1188046783208847, 0.05940233916044235, 0.044551752507686615, 0.08910350501537323, 0.16335642337799072, 0.05940233916044235, 0.4306669533252716, 0.044551752507686615, 0.07542039453983307, 0.20740608870983124, 0.4525223672389984, 0.24511627852916718, 0.06308586150407791, 0.8201162219047546, 0.031542930752038956, 0.06308586150407791, 0.13481205701828003, 0.1437995284795761, 0.07189976423978806, 0.05392482504248619, 0.4313986003398895, 0.10784965008497238, 0.04493735358119011, 0.008987470529973507, 0.028169123455882072, 0.6760589480400085, 0.14084561169147491, 0.08450736850500107, 0.028169123455882072, 0.09639756381511688, 0.09639756381511688, 0.6265841722488403, 0.14459635317325592, 0.02409939095377922, 0.16128841042518616, 0.028801502659916878, 0.03456180542707443, 0.1036854088306427, 0.011520600877702236, 0.005760300438851118, 0.14400751888751984, 0.06336330622434616, 0.4262622594833374, 0.023041201755404472, 0.12900881469249725, 0.016126101836562157, 0.7579267621040344, 0.016126101836562157, 0.08063050359487534, 0.09601942449808121, 0.14702974259853363, 0.06601335108280182, 0.3510710299015045, 0.045009106397628784, 0.07201457023620605, 0.0780157819390297, 0.0780157819390297, 0.06001213937997818, 0.009001821279525757, 0.028223957866430283, 0.22579166293144226, 0.4515833258628845, 0.19756770133972168, 0.056447915732860565, 0.028223957866430283, 0.030807847157120705, 0.09242354333400726, 0.8626196980476379, 0.08869419991970062, 0.13304129242897034, 0.731727123260498, 0.04434709995985031, 0.039784546941518784, 0.019892273470759392, 0.5967682003974915, 0.07956909388303757, 0.11935363709926605, 0.019892273470759392, 0.11935363709926605, 0.038788460195064545, 0.07757692039012909, 0.15515384078025818, 0.17454807460308075, 0.019394230097532272, 0.3490961492061615, 0.15515384078025818, 0.11696534603834152, 0.10526881366968155, 0.2573237717151642, 0.11696534603834152, 0.011696535162627697, 0.3859856426715851, 0.26873740553855896, 0.08957913517951965, 0.37026041746139526, 0.2567935287952423, 0.22687706351280212, 0.06586753576993942, 0.439116895198822, 0.2634701430797577, 0.09490741789340973, 0.15267714858055115, 0.03713768720626831, 0.4043881297111511, 0.08665460348129272, 0.09078101068735123, 0.06189614534378052, 0.03713768720626831, 0.024758458137512207, 0.004126409534364939, 0.6079250574111938, 0.25943297147750854, 0.0038721340242773294, 0.0038721340242773294, 0.03484920784831047, 0.03484920784831047, 0.007744268048554659, 0.0038721340242773294, 0.04259347543120384, 0.1427062302827835, 0.08108308166265488, 0.019459940493106842, 0.2821691334247589, 0.12973293662071228, 0.11675964295864105, 0.07783976197242737, 0.08756972849369049, 0.06486646831035614, 0.07293599843978882, 0.09945818036794662, 0.14587199687957764, 0.04641382023692131, 0.3646799921989441, 0.05304436385631561, 0.006630545482039452, 0.16576363146305084, 0.04641382023692131, 0.0962064117193222, 0.13582082092761993, 0.08488801121711731, 0.06225120648741722, 0.04527360573410988, 0.35087043046951294, 0.01131840143352747, 0.12450241297483444, 0.09054721146821976, 0.2069965898990631, 0.6143834590911865, 0.06606274098157883, 0.00220209127292037, 0.011010456830263138, 0.030829278752207756, 0.019818821921944618, 0.04624391719698906, 0.0188587736338377, 0.047146935015916824, 0.00942938681691885, 0.047146935015916824, 0.0188587736338377, 0.8486448526382446, 0.011549742892384529, 0.7622830271720886, 0.17324614524841309, 0.046198971569538116, 0.18980424106121063, 0.026280587539076805, 0.005840130615979433, 0.13724306225776672, 0.09928222000598907, 0.2365252822637558, 0.04088091477751732, 0.13432300090789795, 0.11680261045694351, 0.008760196156799793, 0.40887343883514404, 0.03360603749752045, 0.24924476444721222, 0.014002515003085136, 0.036406539380550385, 0.11202012002468109, 0.03360603749752045, 0.06161106750369072, 0.05040905624628067, 0.05977221205830574, 0.8965831398963928, 0.4832095503807068, 0.0509808249771595, 0.04654770717024803, 0.03324836492538452, 0.13077689707279205, 0.00886623002588749, 0.12191066890954971, 0.07536295801401138, 0.024382133036851883, 0.019949018955230713, 0.21244774758815765, 0.09442122280597687, 0.6373432278633118, 0.047210611402988434, 0.12876921892166138, 0.016795985400676727, 0.016795985400676727, 0.05038795620203018, 0.005598661955446005, 0.07278260588645935, 0.19595317542552948, 0.3863076865673065, 0.005598661955446005, 0.12317056208848953, 0.19968625903129578, 0.04255608469247818, 0.4910317659378052, 0.13094180822372437, 0.009820635430514812, 0.003273545065894723, 0.12112116813659668, 0.003273545065894723, 0.2283044457435608, 0.02283044345676899, 0.20547400414943695, 0.5479306578636169, 0.3017996847629547, 0.040239956229925156, 0.5231194496154785, 0.12071987241506577, 0.020119978114962578, 0.0293154027312994, 0.0041879150085151196, 0.32246944308280945, 0.2303353101015091, 0.06281872093677521, 0.15495285391807556, 0.12563744187355042, 0.033503320068120956, 0.04187914729118347, 0.42385944724082947, 0.20271539688110352, 0.0061428905464708805, 0.15357226133346558, 0.11057203263044357, 0.03685734421014786, 0.06757179647684097, 0.12903356552124023, 0.2258087396621704, 0.09677517414093018, 0.5161342620849609, 0.15747053921222687, 0.18207530677318573, 0.059051450341939926, 0.14762863516807556, 0.10826099663972855, 0.00984190870076418, 0.05413049831986427, 0.2804943919181824, 0.1045580506324768, 0.04182322323322296, 0.4914228618144989, 0.16206498444080353, 0.0261395126581192, 0.06273483484983444, 0.10978595912456512, 0.20264142751693726, 0.4239881932735443, 0.2275819033384323, 0.031175604090094566, 0.06546876579523087, 0.00935268122702837, 0.006235120818018913, 0.03429316356778145, 0.01616819016635418, 0.06467276066541672, 0.21018646657466888, 0.19401827454566956, 0.08084095269441605, 0.04850456863641739, 0.371868371963501, 0.773979663848877, 0.09674745798110962, 0.09674745798110962, 0.027642128989100456, 0.849302351474762, 0.07962209731340408, 0.02654069848358631, 0.02654069848358631, 0.1511334925889969, 0.6045339703559875, 0.21158689260482788, 0.18195876479148865, 0.06616682559251785, 0.7278350591659546, 0.19451594352722168, 0.3639330565929413, 0.16314241290092468, 0.015686770901083946, 0.05960972607135773, 0.009412062354385853, 0.003137354040518403, 0.1694171130657196, 0.021961478516459465, 0.09832178801298141, 0.044691722840070724, 0.044691722840070724, 0.08938344568014145, 0.05363006517291069, 0.06256841123104095, 0.5541773438453674, 0.05363006517291069, 0.19832628965377808, 0.04958157241344452, 0.04958157241344452, 0.520606517791748, 0.1239539310336113, 0.02479078620672226, 0.21417947113513947, 0.03569657728075981, 0.10708973556756973, 0.5354486703872681, 0.03569657728075981, 0.07139315456151962, 0.5630499720573425, 0.061583589762449265, 0.013196484185755253, 0.21554256975650787, 0.013196484185755253, 0.008797655813395977, 0.12316717952489853, 0.0043988279066979885, 0.7266790866851807, 0.21097135543823242, 0.023441260680556297, 0.046882521361112595, 0.13384439051151276, 0.09960513561964035, 0.16808366775512695, 0.012450641952455044, 0.14629504084587097, 0.11828109622001648, 0.12450641393661499, 0.00933798123151064, 0.021788623183965683, 0.16808366775512695, 0.807430624961853, 0.04485725983977318, 0.1121431440114975, 0.02242862991988659, 0.8235750198364258, 0.13283467292785645, 0.02656693570315838, 0.3017483949661255, 0.08183007687330246, 0.05114379897713661, 0.025571899488568306, 0.04091503843665123, 0.14320263266563416, 0.025571899488568306, 0.10740197449922562, 0.21991832554340363, 0.5860891342163086, 0.1441965252161026, 0.04651500657200813, 0.10698451846837997, 0.051166508346796036, 0.013954502530395985, 0.004651500843465328, 0.04651500657200813, 0.2020135372877121, 0.1925862431526184, 0.08215217292308807, 0.21144084632396698, 0.09292622655630112, 0.08484568446874619, 0.05252351984381676, 0.04578973725438118, 0.03232216835021973, 0.004040271043777466, 0.07113958150148392, 0.10275717079639435, 0.015808796510100365, 0.6876826286315918, 0.007904398255050182, 0.10275717079639435, 0.007904398255050182, 0.007427610456943512, 0.04456566274166107, 0.014855220913887024, 0.04456566274166107, 0.46051186323165894, 0.41594618558883667, 0.20318543910980225, 0.2918088734149933, 0.14482367038726807, 0.004323094617575407, 0.2507394850254059, 0.0021615473087877035, 0.0021615473087877035, 0.09726963192224503, 0.013898943550884724, 0.08802664279937744, 0.5235268473625183, 0.0370638482272625, 0.0648617371916771, 0.1575213521718979, 0.0833936557173729, 0.0370638482272625, 0.13044686615467072, 0.3522065281867981, 0.05217874422669411, 0.41742995381355286, 0.039134059101343155, 0.16846837103366852, 0.16846837103366852, 0.06738734990358353, 0.03369367495179176, 0.13477469980716705, 0.40432408452033997, 0.6467705965042114, 0.23540547490119934, 0.06657932698726654, 0.009511332027614117, 0.016644831746816635, 0.02140049822628498, 0.32938632369041443, 0.015792494639754295, 0.0045121414586901665, 0.0022560707293450832, 0.19402208924293518, 0.44218987226486206, 0.011280354112386703, 0.2825358808040619, 0.1731671541929245, 0.06900646537542343, 0.050127334892749786, 0.12629485130310059, 0.18097920715808868, 0.02278515323996544, 0.05533537268638611, 0.011067073792219162, 0.029295196756720543, 0.10420626401901245, 0.03361492604017258, 0.21513551473617554, 0.013445969671010971, 0.07395283132791519, 0.131098210811615, 0.15799014270305634, 0.27228090167045593, 0.04671183228492737, 0.035033874213695526, 0.2491297721862793, 0.007785305380821228, 0.05838979035615921, 0.15959875285625458, 0.15181344747543335, 0.29194894433021545, 0.07787084579467773, 0.19467711448669434, 0.0584031343460083, 0.5256282091140747, 0.09733855724334717, 0.019467711448669434, 0.3266031742095947, 0.08165079355239868, 0.272169291973114, 0.02721692994236946, 0.272169291973114, 0.01978307217359543, 0.19783072173595428, 0.6330583095550537, 0.09891536086797714, 0.03956614434719086, 0.24192401766777039, 0.4233670234680176, 0.24192401766777039, 0.06300104409456253, 0.002520041773095727, 0.020160334184765816, 0.005040083546191454, 0.7878583669662476, 0.050136443227529526, 0.021487046033143997, 0.02864939533174038, 0.05729879066348076, 0.050136443227529526, 0.2253740429878235, 0.6260390281677246, 0.02504156157374382, 0.10016624629497528, 0.040722787380218506, 0.040722787380218506, 0.7330101132392883, 0.013574262149631977, 0.09501983225345612, 0.09501983225345612, 0.233473002910614, 0.04669459909200668, 0.14008380472660065, 0.09338919818401337, 0.09338919818401337, 0.42025139927864075, 0.027899470180273056, 0.7532856464385986, 0.11159788072109222, 0.08369840681552887, 0.025785202160477638, 0.025785202160477638, 0.4641336500644684, 0.025785202160477638, 0.4125632345676422, 0.025785202160477638, 0.024592870846390724, 0.14755722880363464, 0.0983714833855629, 0.024592870846390724, 0.5164502859115601, 0.024592870846390724, 0.17215010523796082, 0.11700448393821716, 0.08947401493787766, 0.46113529801368713, 0.1995958834886551, 0.020647849887609482, 0.01376523356884718, 0.08947401493787766, 0.05998015031218529, 0.08997022360563278, 0.4948362410068512, 0.2024330049753189, 0.029990075156092644, 0.014995037578046322, 0.09746774286031723, 0.08095570653676987, 0.16191141307353973, 0.5262120962142944, 0.08095570653676987, 0.08095570653676987, 0.08095570653676987, 0.040477853268384933, 0.1428876370191574, 0.3572190999984741, 0.0714438185095787, 0.10716573148965836, 0.3214971721172333, 0.027667690068483353, 0.004611281678080559, 0.07378050684928894, 0.3181784451007843, 0.13372716307640076, 0.1613948494195938, 0.027667690068483353, 0.06455793976783752, 0.1521722972393036, 0.03689025342464447, 0.15310955047607422, 0.15310955047607422, 0.21435336768627167, 0.45932865142822266, 0.5819582343101501, 0.0711282342672348, 0.15518887341022491, 0.045263420790433884, 0.1422564685344696, 0.02703944966197014, 0.5678284168243408, 0.135197252035141, 0.08111834526062012, 0.135197252035141, 0.04731903597712517, 0.2873002290725708, 0.5985421538352966, 0.06384449452161789, 0.039902810007333755, 0.03351045027375221, 0.8042508363723755, 0.10053135454654694, 0.03296312317252159, 0.13185249269008636, 0.03296312317252159, 0.6482747197151184, 0.1428401917219162, 0.30205419659614563, 0.41373810172080994, 0.20813819766044617, 0.0025382705498486757, 0.03299751877784729, 0.007614811882376671, 0.03299751877784729, 0.0025382705498486757, 0.9683340787887573, 0.03406066447496414, 0.0596061646938324, 0.06812132894992828, 0.298030823469162, 0.07663650065660477, 0.0596061646938324, 0.26397016644477844, 0.15327300131320953, 0.05104173719882965, 0.22968780994415283, 0.5869799852371216, 0.15312521159648895, 0.03321350738406181, 0.10913009196519852, 0.12810924649238586, 0.05693744122982025, 0.08066137135028839, 0.22300498187541962, 0.004744786769151688, 0.052192654460668564, 0.09964051842689514, 0.20877061784267426, 0.0049814460799098015, 0.0049814460799098015, 0.5579219460487366, 0.009962892159819603, 0.03985156863927841, 0.24409085512161255, 0.13449904322624207, 0.006683132611215115, 0.7217783331871033, 0.006683132611215115, 0.2004939764738083, 0.006683132611215115, 0.05346506088972092, 0.07283265143632889, 0.0873991847038269, 0.11653224378824234, 0.07283265143632889, 0.5535281300544739, 0.10196571052074432, 0.19596269726753235, 0.023515522480010986, 0.0627080649137497, 0.39976391196250916, 0.1254161298274994, 0.015677016228437424, 0.054869554936885834, 0.10973910987377167, 0.06753797084093094, 0.7204050421714783, 0.2026139199733734, 0.23690113425254822, 0.1875467300415039, 0.4935440421104431, 0.0690961629152298, 0.20668314397335052, 0.02296479418873787, 0.2755775451660156, 0.41336628794670105, 0.0688943862915039, 0.26962512731552124, 0.04493752494454384, 0.07988893240690231, 0.054923638701438904, 0.02496528998017311, 0.059916697442531586, 0.25963902473449707, 0.029958348721265793, 0.1398056298494339, 0.029958348721265793, 0.014091989025473595, 0.05636795610189438, 0.22547182440757751, 0.014091989025473595, 0.6905074715614319, 0.05608672648668289, 0.05608672648668289, 0.07478230446577072, 0.39883893728256226, 0.27420178055763245, 0.04362300783395767, 0.04362300783395767, 0.05608672648668289, 0.006231858395040035, 0.15581747889518738, 0.12119137495756149, 0.11772876232862473, 0.051939159631729126, 0.09695309400558472, 0.034626107662916183, 0.09349048882722855, 0.1627427041530609, 0.13504181802272797, 0.031163495033979416, 0.8157523274421692, 0.15538139641284943, 0.11420615762472153, 0.019034359604120255, 0.13324052095413208, 0.03806871920824051, 0.6281338930130005, 0.019034359604120255, 0.057103078812360764, 0.7522934079170227, 0.13275766372680664, 0.0885051041841507, 0.10343995690345764, 0.041375983506441116, 0.12412795424461365, 0.2275679111480713, 0.4758238196372986, 0.05986705422401428, 0.033259473741054535, 0.026607580482959747, 0.5720629692077637, 0.3059871792793274, 0.3376855254173279, 0.10518073290586472, 0.21589729189872742, 0.005535827949643135, 0.08303742110729218, 0.24911226332187653, 0.09245709329843521, 0.062354784458875656, 0.030102308839559555, 0.44723430275917053, 0.08385643362998962, 0.1010577529668808, 0.07740593701601028, 0.04730362817645073, 0.01290098950266838, 0.049453794956207275, 0.9648042917251587, 0.09069382399320602, 0.030231274664402008, 0.2720814645290375, 0.09069382399320602, 0.4534691274166107, 0.014005914330482483, 0.06302661448717117, 0.08053401112556458, 0.024510350078344345, 0.7108001708984375, 0.014005914330482483, 0.0070029571652412415, 0.024510350078344345, 0.05602365732192993, 0.0070029571652412415, 0.7695773243904114, 0.17759476602077484, 0.029599128291010857, 0.013357729651033878, 0.5276303291320801, 0.25379687547683716, 0.18700821697711945, 0.013357729651033878, 0.026429705321788788, 0.07047921419143677, 0.5197842121124268, 0.04404950886964798, 0.14976832270622253, 0.035239607095718384, 0.035239607095718384, 0.07928911596536636, 0.035239607095718384, 0.019310100004076958, 0.07724040001630783, 0.5696479678153992, 0.1641358584165573, 0.038620200008153915, 0.038620200008153915, 0.09655050188302994, 0.07300719618797302, 0.012167866341769695, 0.1581822633743286, 0.21902158856391907, 0.5353861451148987, 0.05059482529759407, 0.1770818829536438, 0.6577327251434326, 0.07589223235845566, 0.132701575756073, 0.17251205444335938, 0.09289110451936722, 0.5440764427185059, 0.03981047123670578, 0.14723268151283264, 0.7198042273521423, 0.1145143136382103, 0.02109816111624241, 0.5696503520011902, 0.18988345563411713, 0.08439264446496964, 0.02109816111624241, 0.02109816111624241, 0.06329448521137238, 0.0803445503115654, 0.0803445503115654, 0.2812059223651886, 0.4418950378894806, 0.0401722751557827, 0.0803445503115654, 0.17356441915035248, 0.03919196501374245, 0.16236671805381775, 0.02799426205456257, 0.31913459300994873, 0.01679655723273754, 0.005598852410912514, 0.22395409643650055, 0.022395409643650055, 0.05960405245423317, 0.1617824286222458, 0.01702972874045372, 0.38316890597343445, 0.00851486437022686, 0.20435674488544464, 0.06811891496181488, 0.09366350620985031, 0.10380779951810837, 0.6228468418121338, 0.23356755077838898, 0.31121987104415894, 0.14645640552043915, 0.03661410138010979, 0.03661410138010979, 0.03661410138010979, 0.421062171459198, 0.8463361263275146, 0.07984303683042526, 0.015968605875968933, 0.031937211751937866, 0.29606008529663086, 0.29369160532951355, 0.3244818449020386, 0.0023684806656092405, 0.0023684806656092405, 0.08289682120084763, 0.11381939798593521, 0.09484949707984924, 0.03793979808688164, 0.7018862962722778, 0.03793979808688164, 0.029499582946300507, 0.05899916589260101, 0.17699749767780304, 0.29499581456184387, 0.05899916589260101, 0.3539949953556061, 0.399938702583313, 0.20641997456550598, 0.012901248410344124, 0.025802496820688248, 0.06450624018907547, 0.03870374336838722, 0.2451237142086029, 0.08635297417640686, 0.11102525889873505, 0.01233613956719637, 0.04934455826878548, 0.08635297417640686, 0.6291431188583374, 0.02467227913439274, 0.01165953278541565, 0.6762529015541077, 0.3089776039123535, 0.11137709766626358, 0.011137709952890873, 0.17820335924625397, 0.590298593044281, 0.016706565394997597, 0.03898198530077934, 0.0055688549764454365, 0.05011969432234764, 0.6988816857337952, 0.017045894637703896, 0.03409178927540779, 0.15341304242610931, 0.06818357855081558, 0.3867645859718323, 0.029751120135188103, 0.029751120135188103, 0.5057690739631653, 0.47262904047966003, 0.506388247013092, 0.22450242936611176, 0.37462982535362244, 0.1432408094406128, 0.023414364084601402, 0.0358102023601532, 0.028923625126481056, 0.00826389342546463, 0.14875008165836334, 0.012395840138196945, 0.22848054766654968, 0.5288901925086975, 0.1861693412065506, 0.004231121391057968, 0.04231121391057968, 0.004231121391057968, 0.053846325725317, 0.23333407938480377, 0.7089766263961792, 0.2096029371023178, 0.1545821726322174, 0.09956139326095581, 0.0026200367137789726, 0.09170128405094147, 0.37728527188301086, 0.02096029371023178, 0.015720220282673836, 0.02358032949268818, 0.05026630684733391, 0.6031957268714905, 0.10053261369466782, 0.05026630684733391, 0.07539946585893631, 0.025133153423666954, 0.07539946585893631, 0.2636125683784485, 0.28802111744880676, 0.0634622797369957, 0.04393542557954788, 0.30754798650741577, 0.034171998500823975, 0.05549992248415947, 0.009249987080693245, 0.1664997637271881, 0.12949982285499573, 0.21274970471858978, 0.05549992248415947, 0.3699994683265686, 0.028501955792307854, 0.08550586551427841, 0.14250977337360382, 0.08550586551427841, 0.19951368868350983, 0.028501955792307854, 0.42752933502197266, 0.23239126801490784, 0.04171125218272209, 0.12811313569545746, 0.04469062760472298, 0.25026750564575195, 0.02383500151336193, 0.06852562725543976, 0.12811313569545746, 0.020855626091361046, 0.06554625183343887, 0.03372924029827118, 0.5059385895729065, 0.03372924029827118, 0.1686462014913559, 0.23610468208789825, 0.04595997929573059, 0.04595997929573059, 0.18383991718292236, 0.22979989647865295, 0.09191995859146118, 0.04595997929573059, 0.32171985507011414, 0.05466238036751747, 0.8090032339096069, 0.032797425985336304, 0.02186495251953602, 0.01093247625976801, 0.02186495251953602, 0.04372990503907204, 0.03621739521622658, 0.21730437874794006, 0.07243479043245316, 0.6519131660461426, 0.7773408889770508, 0.008449357002973557, 0.09294293075799942, 0.02534807287156582, 0.033797428011894226, 0.059145502746105194, 0.20550109446048737, 0.5577886700630188, 0.029357299208641052, 0.14678649604320526, 0.058714598417282104, 0.155951589345932, 0.007701312657445669, 0.5852997899055481, 0.24066603183746338, 0.007701312657445669, 0.0019253281643614173, 0.0019253281643614173, 0.14171256124973297, 0.17796461284160614, 0.03295641019940376, 0.08239102363586426, 0.17466896772384644, 0.003295640926808119, 0.38558998703956604, 0.017420694231987, 0.034841388463974, 0.017420694231987, 0.1219448521733284, 0.7839311957359314, 0.06396172940731049, 0.6122051477432251, 0.06396172940731049, 0.036549560725688934, 0.0548243410885334, 0.009137390181422234, 0.009137390181422234, 0.036549560725688934, 0.0274121705442667, 0.09137390553951263, 0.383561909198761, 0.2024354487657547, 0.1789955496788025, 0.006392698269337416, 0.10867587476968765, 0.02130899392068386, 0.03622528910636902, 0.05327248573303223, 0.00852359738200903, 0.8791608214378357, 0.09768453240394592, 0.43570777773857117, 0.019364789128303528, 0.48089227080345154, 0.025819718837738037, 0.0032274648547172546, 0.0355021134018898, 0.06612670421600342, 0.6833092570304871, 0.044084470719099045, 0.19838011264801025, 0.37731778621673584, 0.09432944655418396, 0.09432944655418396, 0.4087609350681305, 0.29784417152404785, 0.05085144564509392, 0.02905796840786934, 0.5085144639015198, 0.02905796840786934, 0.007264492101967335, 0.05811593681573868, 0.02905796840786934, 0.7402102947235107, 0.05001420900225639, 0.08002273738384247, 0.11003126204013824, 0.010002842172980309, 0.1690526008605957, 0.01878362149000168, 0.00939181074500084, 0.2629707157611847, 0.12209354341030121, 0.3850642442703247, 0.028175432235002518, 0.6628940105438232, 0.15597505867481232, 0.15597505867481232, 0.0442507229745388, 0.01770028844475746, 0.09735158830881119, 0.0885014459490776, 0.1327521651983261, 0.16815273463726044, 0.39825648069381714, 0.00885014422237873, 0.026550432667136192, 0.00885014422237873, 0.37702199816703796, 0.008286197669804096, 0.004143098834902048, 0.06628958135843277, 0.12843607366085052, 0.05386028811335564, 0.3065893352031708, 0.05386028811335564, 0.8283392190933228, 0.03601474687457085, 0.0720294937491417, 0.5292618870735168, 0.1305970996618271, 0.13747061789035797, 0.006873531267046928, 0.024057358503341675, 0.03436765447258949, 0.017183827236294746, 0.010310296900570393, 0.04124118760228157, 0.06873530894517899, 0.0736788734793663, 0.20630083978176117, 0.05894309654831886, 0.4789126515388489, 0.08841464668512344, 0.014735774137079716, 0.04420732334256172, 0.007367887068539858, 0.02210366167128086, 0.007367887068539858, 0.13433970510959625, 0.08396231383085251, 0.5709437131881714, 0.03358492627739906, 0.15113216638565063, 0.01679246313869953, 0.367013543844223, 0.06901109218597412, 0.02195807360112667, 0.07214795798063278, 0.1411590427160263, 0.02195807360112667, 0.0470530167222023, 0.11292724311351776, 0.09724289923906326, 0.0470530167222023, 0.07122956216335297, 0.1110343188047409, 0.102654367685318, 0.3393879234790802, 0.11941426992416382, 0.09846439957618713, 0.07122956216335297, 0.05237467959523201, 0.01256992295384407, 0.020949872210621834, 0.13518422842025757, 0.3068467378616333, 0.21028657257556915, 0.030040938407182693, 0.1780998557806015, 0.015020469203591347, 0.023603595793247223, 0.02574937604367733, 0.021457813680171967, 0.05149875208735466, 0.1490541249513626, 0.1605198234319687, 0.11465701460838318, 0.011465701274573803, 0.04586280509829521, 0.1031913161277771, 0.05732850730419159, 0.011465701274573803, 0.34397104382514954, 0.15306910872459412, 0.275524377822876, 0.06122764199972153, 0.09184145927429199, 0.030613820999860764, 0.06122764199972153, 0.030613820999860764, 0.30613821744918823, 0.21852439641952515, 0.027315549552440643, 0.5517740845680237, 0.010926219634711742, 0.04370487853884697, 0.1256515234708786, 0.0027315549086779356, 0.013657774776220322, 0.0027315549086779356, 0.015164248645305634, 0.015164248645305634, 0.9250191450119019, 0.037910621613264084, 0.007582124322652817, 0.17694397270679474, 0.03932088613510132, 0.5111715197563171, 0.14745332300662994, 0.06881155073642731, 0.03932088613510132, 0.24914740025997162, 0.14236994087696075, 0.04745664820075035, 0.0949132964015007, 0.011864162050187588, 0.011864162050187588, 0.07118497043848038, 0.36778903007507324, 0.33480972051620483, 0.16262187063694, 0.08609393239021301, 0.11000891029834747, 0.08449959754943848, 0.10841457545757294, 0.05261295661330223, 0.01434898842126131, 0.009565992280840874, 0.038263969123363495, 0.07616766542196274, 0.09140119701623917, 0.030467066913843155, 0.4570060074329376, 0.18280239403247833, 0.015233533456921577, 0.09140119701623917, 0.030467066913843155, 0.35316333174705505, 0.5738903880119324, 0.04414541646838188, 0.11266912519931793, 0.08666855841875076, 0.25133880972862244, 0.31200680136680603, 0.06500142067670822, 0.09533541649580002, 0.017333712428808212, 0.039000850170850754, 0.004333428107202053, 0.017333712428808212, 0.01037981454282999, 0.134937584400177, 0.2075962871313095, 0.12455777078866959, 0.4878512918949127, 0.01037981454282999, 0.031139442697167397, 0.060361359268426895, 0.005487396381795406, 0.22223953902721405, 0.3196408152580261, 0.21949584782123566, 0.037039924412965775, 0.052130263298749924, 0.03292437642812729, 0.037039924412965775, 0.015090339817106724, 0.14832301437854767, 0.2076522260904312, 0.059329207986593246, 0.14832301437854767, 0.4153044521808624, 0.19325707852840424, 0.04831426963210106, 0.7247140407562256, 0.7704196572303772, 0.01712043583393097, 0.20544524490833282, 0.19127929210662842, 0.5313313603401184, 0.10626627504825592, 0.170026034116745, 0.13630081713199615, 0.0389430932700634, 0.29207319021224976, 0.012981031090021133, 0.29856371879577637, 0.0194715466350317, 0.20769649744033813, 0.021733053028583527, 0.05071045830845833, 0.13764266669750214, 0.014488701708614826, 0.09417656064033508, 0.3187514543533325, 0.057954806834459305, 0.30426275730133057, 0.29128676652908325, 0.33255240321159363, 0.10437776148319244, 0.002427389845252037, 0.10437776148319244, 0.009709559381008148, 0.014564339071512222, 0.1310790479183197, 0.007282169535756111, 0.9132519364356995, 0.04806589335203171, 0.17397943139076233, 0.07732419669628143, 0.03866209834814072, 0.21264153718948364, 0.5026072859764099, 0.28119096159935, 0.1756334751844406, 0.10289637744426727, 0.01330556534230709, 0.38231325149536133, 0.005322226323187351, 0.03902965784072876, 0.1554120033979416, 0.0388530008494854, 0.11655900627374649, 0.46623602509498596, 0.1554120033979416, 0.19521331787109375, 0.359440416097641, 0.1611284613609314, 0.01859174482524395, 0.05887385830283165, 0.009295872412621975, 0.0030986240599304438, 0.1673257052898407, 0.02478899247944355, 0.006455748807638884, 0.6972208619117737, 0.28405293822288513, 0.006455748807638884, 0.16069650650024414, 0.685638427734375, 0.07499170303344727, 0.07499170303344727, 0.06953363865613937, 0.07416921108961105, 0.09734709560871124, 0.41256624460220337, 0.05099133402109146, 0.004635575693100691, 0.11588939279317856, 0.13443170487880707, 0.041720181703567505, 0.06697764247655869, 0.8372205495834351, 0.03348882123827934, 0.06697764247655869, 0.02381397970020771, 0.2381397932767868, 0.0595349483191967, 0.6310704350471497, 0.011906989850103855, 0.011906989850103855, 0.24024511873722076, 0.18361590802669525, 0.20764042437076569, 0.04290091618895531, 0.13899897038936615, 0.054913170635700226, 0.03775280341506004, 0.046332988888025284, 0.001716036582365632, 0.044616952538490295, 0.09512382745742798, 0.14495059847831726, 0.06341588497161865, 0.1313614696264267, 0.15401001274585724, 0.018118824809789658, 0.27178236842155457, 0.022648530080914497, 0.09965353459119797, 0.08019310981035233, 0.5651704668998718, 0.2634916305541992, 0.034368474036455154, 0.015274877659976482, 0.030549755319952965, 0.0038187194149941206, 0.2589412033557892, 0.07935294508934021, 0.029235295951366425, 0.02714706026017666, 0.4594117999076843, 0.008352941833436489, 0.0020882354583591223, 0.0020882354583591223, 0.13364706933498383, 0.781278669834137, 0.025202538818120956, 0.15121522545814514, 0.014981095679104328, 0.11610348522663116, 0.04868856072425842, 0.4419423043727875, 0.2359522581100464, 0.05617910623550415, 0.05243383347988129, 0.007490547839552164, 0.011235821060836315, 0.014981095679104328, 0.2321179360151291, 0.13927076756954193, 0.061898116022348404, 0.038686323910951614, 0.4642358720302582, 0.015474529005587101, 0.0077372645027935505, 0.038686323910951614, 0.1562265306711197, 0.07414140552282333, 0.14563488960266113, 0.2621428072452545, 0.03177488595247269, 0.17740978300571442, 0.04766232892870903, 0.03707070276141167, 0.06619767844676971, 0.15933705866336823, 0.14605896174907684, 0.06639043986797333, 0.013278087601065636, 0.5178453922271729, 0.07966852933168411, 0.10431298613548279, 0.14144133031368256, 0.23337820172309875, 0.1255291849374771, 0.1113850474357605, 0.019448183476924896, 0.05834455043077469, 0.06895264983177185, 0.11492108553647995, 0.021216200664639473, 0.5546799302101135, 0.140518918633461, 0.05324927344918251, 0.15531037747859955, 0.004437439609318972, 0.09170708060264587, 0.17997123301029205, 0.11398177593946457, 0.08998561650514603, 0.17997123301029205, 0.08998561650514603, 0.05249160900712013, 0.0644896924495697, 0.1859702616930008, 0.010498321615159512, 0.03149496391415596, 0.6316474080085754, 0.17176376283168793, 0.03878536820411682, 0.06648919731378555, 0.022163067013025284, 0.005540766753256321, 0.011081533506512642, 0.05540766566991806, 0.21024219691753387, 0.0700807273387909, 0.6307265758514404, 0.0700807273387909, 0.7937751412391663, 0.09525301307439804, 0.06350201368331909, 0.031751006841659546], \"Term\": [\"accommodation\", \"accommodation\", \"accommodation\", \"accommodation\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"acute\", \"acute\", \"acute\", \"acute\", \"add\", \"add\", \"add\", \"add\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertisement\", \"aedt\", \"aedt\", \"aedt\", \"aedt\", \"aedt\", \"aedt\", \"aedt_february\", \"aedt_february\", \"aedt_february\", \"aedt_february\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"age\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"agency\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air\", \"air_quality\", \"air_quality\", \"air_quality\", \"airline\", \"airline\", \"airline\", \"airline\", \"airport\", \"airport\", \"airport\", \"airport\", \"airport\", \"airport\", \"ait\", \"ait\", \"ait\", \"ait\", \"ait\", \"alert_level\", \"alone\", \"alone\", \"alone\", \"alone\", \"alone\", \"alone\", \"alone\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"andrew\", \"andrew\", \"andrew\", \"andrew\", \"andrew\", \"andrew\", \"animal\", \"animal\", \"animal\", \"animal\", \"animal\", \"animal\", \"animal\", \"animal\", \"animal\", \"annual\", \"annual\", \"annual\", \"annual\", \"appears\", \"appears\", \"appears\", \"appears\", \"appears\", \"appears\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"around\", \"arrival\", \"arrival\", \"arrival\", \"arrived\", \"arrived\", \"arrived\", \"arrived\", \"arrived\", \"associated\", \"associated\", \"associated\", \"associated\", \"associated\", \"associated\", \"athe\", \"athe\", \"athe\", \"athe\", \"athe\", \"athe\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia_february\", \"australia_february\", \"australia_february\", \"australiaas\", \"australiaas\", \"australiaas\", \"australiaas\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian_government\", \"australian_government\", \"australian_government\", \"australian_government\", \"australian_government\", \"australian_government\", \"author\", \"author\", \"author\", \"authority\", \"authority\", \"authority\", \"authority\", \"authority\", \"authority\", \"authority\", \"authority\", \"average\", \"average\", \"average\", \"average\", \"awe\", \"awe\", \"awe\", \"awe\", \"awe\", \"baby\", \"baby\", \"baby\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"ban\", \"ban\", \"ban\", \"ban\", \"ban\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"basis\", \"basis\", \"basis\", \"basis\", \"basis\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"beijing\", \"beijing\", \"beijing\", \"beijing\", \"beijing\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"blaze\", \"blaze\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"breath\", \"breath\", \"breath\", \"breathe\", \"breathe\", \"breathe\", \"breathe\", \"bringing\", \"bringing\", \"bringing\", \"bringing\", \"bringing\", \"bringing\", \"bringing\", \"bureau\", \"bureau\", \"bureau\", \"bushfire\", \"bushfire\", \"bushfire\", \"bushfire\", \"bushfires\", \"bushfires\", \"bushfires\", \"bushfires\", \"bushfires\", \"bushfires\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"busy\", \"busy\", \"busy\", \"busy\", \"cabin\", \"cabin\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"canberra\", \"car\", \"car\", \"car\", \"car\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"carrying\", \"carrying\", \"carrying\", \"carrying\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"catch\", \"catch\", \"catch\", \"catch\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"caused\", \"caused\", \"caused\", \"caused\", \"caused\", \"caused\", \"caused\", \"causing\", \"causing\", \"causing\", \"causing\", \"causing\", \"cell\", \"cell\", \"cell\", \"cell\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"chain\", \"chain\", \"chain\", \"chain\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"charter\", \"charter\", \"charter\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese_authority\", \"chinese_authority\", \"chinese_authority\", \"chinese_authority\", \"chinese_student\", \"chinese_student\", \"chinese_student\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"climate\", \"climate\", \"climate\", \"climate_change\", \"climate_change\", \"climate_change\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"closing\", \"closing\", \"closing\", \"coast\", \"coast\", \"coast\", \"coast\", \"coast\", \"coast\", \"coast\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"cold\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common\", \"common_cold\", \"common_cold\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"compared\", \"compared\", \"compared\", \"compared\", \"compared\", \"compared\", \"compared\", \"confirmed\", \"confirmed\", \"confirmed\", \"confirmed\", \"confirmed\", \"confirmed\", \"confirmed\", \"confirmed\", \"confirmed\", \"contact_someone\", \"contact_someone\", \"contacted\", \"contacted\", \"contacted\", \"contracting\", \"contracting\", \"contracting\", \"contracting\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"cough\", \"cough\", \"cough\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"council\", \"council\", \"council\", \"council\", \"council\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"created\", \"created\", \"created\", \"cruise\", \"cruise\", \"cruise\", \"cruise\", \"cruise\", \"cruise\", \"cruise\", \"cruise_ship\", \"cruise_ship\", \"cruise_ship\", \"cruise_ship\", \"cruise_ship\", \"customer\", \"customer\", \"customer\", \"customer\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"daughter\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death_toll\", \"death_toll\", \"death_toll\", \"death_toll\", \"death_toll\", \"death_toll\", \"department_foreign\", \"department_foreign\", \"destroyed\", \"destroyed\", \"destroyed\", \"diagnosed\", \"diagnosed\", \"diagnosed\", \"diagnosed\", \"diagnosed\", \"diagnosed\", \"diagnosed_coronavirus\", \"diagnosed_coronavirus\", \"diagnosed_coronavirus\", \"diagnosed_coronavirus\", \"diagnosed_coronavirus\", \"diamond\", \"diamond\", \"diamond\", \"diamond\", \"diamond_princess\", \"diamond_princess\", \"diamond_princess\", \"diamond_princess\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"died\", \"disaster\", \"disaster\", \"disaster\", \"disaster\", \"discovered\", \"discovered\", \"discovered\", \"discovered\", \"discovered\", \"discovered\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"disease\", \"distancing\", \"distancing\", \"donat\", \"donat\", \"donat\", \"donat\", \"donat\", \"donat\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"dr\", \"east\", \"east\", \"east\", \"east\", \"east\", \"east\", \"east\", \"east\", \"economic\", \"economic\", \"economic\", \"economic\", \"economic\", \"economy\", \"economy\", \"economy\", \"economy\", \"economy\", \"economy\", \"education\", \"education\", \"education\", \"education\", \"education\", \"empty\", \"empty\", \"empty\", \"empty\", \"empty\", \"enter\", \"enter\", \"enter\", \"enter\", \"enter\", \"entering\", \"entering\", \"entering\", \"entering\", \"entering\", \"entering\", \"epicentre_outbreak\", \"epicentre_outbreak\", \"epicentre_outbreak\", \"epicentre_outbreak\", \"epicentre_outbreak\", \"epidemic\", \"epidemic\", \"epidemic\", \"epidemic\", \"epidemic\", \"epidemic\", \"essential\", \"essential\", \"essential\", \"essential\", \"essential\", \"evacuate\", \"evacuate\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"eventually\", \"eventually\", \"eventually\", \"eventually\", \"eventually\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"exposure\", \"exposure\", \"exposure\", \"exposure\", \"exposure\", \"exposure\", \"exposure\", \"extended\", \"extended\", \"extended\", \"extended\", \"extended\", \"extended\", \"extreme\", \"extreme\", \"extreme\", \"extreme\", \"extreme\", \"extreme\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face_mask\", \"face_mask\", \"face_mask\", \"face_mask\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"family_member\", \"family_member\", \"family_member\", \"faster\", \"faster\", \"faster\", \"faster\", \"fatal\", \"fatal\", \"fatal\", \"fatal\", \"fatal\", \"fatality\", \"fatality\", \"fatality\", \"fatality\", \"fatality\", \"february\", \"february\", \"february\", \"february\", \"february\", \"february\", \"february\", \"february\", \"february\", \"february\", \"february_february\", \"february_february\", \"february_february\", \"february_february\", \"february_queensland\", \"february_queensland\", \"february_queensland\", \"february_updated\", \"february_updated\", \"february_updated\", \"february_updated\", \"february_western\", \"february_western\", \"february_western\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"fever\", \"fever\", \"fever\", \"fever_cough\", \"fever_cough\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"fire\", \"fire\", \"fire\", \"fire\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"flew\", \"flew\", \"flew\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"flight\", \"flu\", \"flu\", \"flu\", \"flu\", \"flu\", \"fluid\", \"fluid\", \"fluid\", \"fluid\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"friday\", \"front\", \"front\", \"front\", \"front\", \"gathering\", \"gathering\", \"gathering\", \"gathering\", \"gathering\", \"gathering\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold_coast\", \"gold_coast\", \"gold_coast\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"greater\", \"greater\", \"greater\", \"greater\", \"greater\", \"greater\", \"greater\", \"greater\", \"greg\", \"greg\", \"greg\", \"greg\", \"greg\", \"greg_hunt\", \"greg_hunt\", \"greg_hunt\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"growth\", \"growth\", \"growth\", \"growth\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health_minister\", \"health_minister\", \"health_minister\", \"health_minister\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"heat\", \"heat\", \"heat\", \"heat\", \"heat\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"heavy\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"history\", \"history\", \"history\", \"history\", \"history\", \"history\", \"holding\", \"holding\", \"holding\", \"holding\", \"holding\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home_affair\", \"home_affair\", \"home_affair\", \"hong\", \"hong\", \"hong\", \"hong\", \"hong\", \"hong\", \"hong_kong\", \"hong_kong\", \"hong_kong\", \"hong_kong\", \"hong_kong\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hubei\", \"hubei\", \"hubei\", \"hubei\", \"hubei\", \"hubei_province\", \"hubei_province\", \"hubei_province\", \"hubei_province\", \"hubei_province\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hunt\", \"hunt\", \"hunt\", \"hunt\", \"hunt\", \"illness\", \"illness\", \"illness\", \"illness\", \"illness\", \"illness\", \"illness\", \"illness\", \"illness\", \"immune\", \"immune\", \"immune\", \"immune\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including\", \"including_three\", \"including_three\", \"including_three\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"indonesia\", \"infected\", \"infected\", \"infected\", \"infected\", \"infected\", \"infected\", \"infected\", \"infection\", \"infection\", \"infection\", \"infection\", \"infection\", \"infection\", \"infection\", \"infection\", \"infectious_disease\", \"infectious_disease\", \"infectious_disease\", \"infectious_disease\", \"intensive\", \"intensive\", \"intensive\", \"intensive\", \"intensive_care\", \"intensive_care\", \"intensive_care\", \"intensive_care\", \"international\", \"international\", \"international\", \"international\", \"international\", \"international\", \"international\", \"international\", \"international\", \"international\", \"island\", \"island\", \"island\", \"island\", \"island\", \"island\", \"isolated\", \"isolated\", \"isolated\", \"isolated\", \"isolated\", \"isolation\", \"isolation\", \"isolation\", \"isolation\", \"isolation\", \"isolation\", \"itas\", \"itas\", \"itas\", \"itas\", \"itas\", \"itas\", \"january\", \"january\", \"january\", \"january\", \"january\", \"january\", \"january\", \"january\", \"january_february\", \"january_february\", \"january_february\", \"january_january\", \"january_january\", \"january_january\", \"january_january\", \"january_january\", \"january_victoria\", \"january_victoria\", \"january_victoria\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan\", \"japan_advertisement\", \"japan_advertisement\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"journal\", \"journal\", \"journal\", \"journal\", \"kong\", \"kong\", \"kong\", \"kong\", \"kong\", \"land\", \"land\", \"land\", \"land\", \"land\", \"largest\", \"largest\", \"largest\", \"largest\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last_year\", \"last_year\", \"last_year\", \"last_year\", \"last_year\", \"last_year\", \"last_year\", \"last_year\", \"law\", \"law\", \"law\", \"law\", \"learning\", \"learning\", \"learning\", \"learning\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"led\", \"led\", \"led\", \"led\", \"led\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"light\", \"light\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"link\", \"link\", \"link\", \"location\", \"location\", \"location\", \"location\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"london\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lung\", \"lung\", \"lung\", \"lung\", \"lung\", \"lung\", \"mainland\", \"mainland\", \"mainland\", \"mainland\", \"mainland_china\", \"mainland_china\", \"mainland_china\", \"mainland_china\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"march\", \"march\", \"march\", \"march\", \"march\", \"march\", \"march\", \"march\", \"march\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"mask\", \"mask\", \"mask\", \"mask\", \"mask\", \"mask\", \"mask\", \"mask\", \"mass\", \"mass\", \"mass\", \"mass\", \"mass\", \"mass\", \"material\", \"material\", \"material\", \"material\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical_advice\", \"medical_advice\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"melbourne\", \"mild\", \"mild\", \"mild\", \"mild\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"minister\", \"minister\", \"minister\", \"minister\", \"minister\", \"minister\", \"minister\", \"minister\", \"ministry\", \"ministry\", \"ministry\", \"ministry\", \"model\", \"model\", \"model\", \"model\", \"model\", \"monash\", \"monash\", \"monash\", \"monash\", \"monash\", \"monash\", \"monash\", \"monash\", \"monash\", \"monash_university\", \"monash_university\", \"monash_university\", \"monash_university\", \"monash_university\", \"monash_university\", \"monash_university\", \"monitoring\", \"monitoring\", \"monitoring\", \"monitoring\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"morrison\", \"morrison\", \"morrison\", \"morrison\", \"morrison\", \"morrison\", \"morrison\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"mr\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"murphy\", \"murphy\", \"murphy\", \"murphy\", \"murphy_said\", \"murphy_said\", \"murphy_said\", \"murphy_said\", \"natural\", \"natural\", \"natural\", \"network\", \"network\", \"network\", \"new_south\", \"new_south\", \"new_south\", \"new_south\", \"new_south\", \"new_south\", \"new_south\", \"new_south\", \"new_south\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"nose\", \"nose\", \"nose\", \"nose\", \"nose\", \"nose\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"nsw\", \"nsw\", \"nsw\", \"nsw\", \"nsw\", \"nsw\", \"nsw\", \"nsw\", \"nsw_health\", \"nsw_health\", \"nsw_health\", \"nsw_health\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"officer_brendan\", \"officer_brendan\", \"officer_brendan\", \"officer_brendan\", \"officer_dr\", \"officer_dr\", \"officer_dr\", \"official\", \"official\", \"official\", \"official\", \"official\", \"official\", \"official\", \"official\", \"official\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"online\", \"online\", \"online\", \"online\", \"online\", \"online\", \"online\", \"open\", \"open\", \"open\", \"open\", \"open\", \"open\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"pas\", \"pas\", \"pas\", \"pas\", \"pas\", \"pas\", \"passenger\", \"passenger\", \"passenger\", \"passenger\", \"passenger\", \"passenger\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per_cent\", \"per_cent\", \"per_cent\", \"per_cent\", \"per_cent\", \"per_cent\", \"per_cent\", \"per_cent\", \"personal\", \"personal\", \"personal\", \"personal\", \"personal\", \"personal\", \"philippine\", \"philippine\", \"philippine\", \"philippine\", \"philippine\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"pictured\", \"pictured\", \"pictured\", \"pictured\", \"pictured\", \"pictured\", \"pictured\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"plane\", \"pneumonia\", \"pneumonia\", \"pneumonia\", \"pneumonia\", \"police\", \"police\", \"police\", \"police\", \"police\", \"police\", \"possibility\", \"possibility\", \"possibility\", \"possibility\", \"possibility\", \"possibility\", \"posted\", \"posted\", \"posted\", \"posted\", \"premier\", \"premier\", \"premier\", \"premier\", \"premier\", \"premier\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"prime\", \"prime\", \"prime\", \"prime\", \"prime\", \"prime\", \"prime\", \"prime_minister\", \"prime_minister\", \"prime_minister\", \"prime_minister\", \"prime_minister\", \"prime_minister\", \"prime_minister\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"priority\", \"production\", \"production\", \"production\", \"production\", \"production\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"professor\", \"property\", \"property\", \"property\", \"property\", \"province\", \"province\", \"province\", \"province\", \"province\", \"published_aedt\", \"published_aedt\", \"published_aedt\", \"published_aedt\", \"published_aedt\", \"published_aedt\", \"qantas\", \"qantas\", \"qantas\", \"qantas\", \"qantas_flight\", \"qantas_flight\", \"qantas_flight\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"queensland\", \"queensland\", \"queensland\", \"queensland\", \"queensland\", \"queensland\", \"queensland\", \"queensland\", \"raised_travel\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"real\", \"real\", \"real\", \"real\", \"reported\", \"reported\", \"reported\", \"reported\", \"reported\", \"reported\", \"reported\", \"reported\", \"reported\", \"reported\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"respiratory\", \"respiratory\", \"respiratory\", \"respiratory\", \"respiratory\", \"respiratory\", \"respiratory\", \"respiratory\", \"respiratory_syndrome\", \"respiratory_syndrome\", \"respiratory_syndrome\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restriction\", \"restriction\", \"restriction\", \"restriction\", \"restriction\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"reuters\", \"reuters\", \"reuters\", \"reuters\", \"reuters\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"royal_melbourne\", \"royal_melbourne\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"sa\", \"sa\", \"sa\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sars\", \"sars\", \"sars\", \"sars\", \"sars\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say_unless\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"science\", \"science\", \"science\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott\", \"scott_morrison\", \"scott_morrison\", \"scott_morrison\", \"scott_morrison\", \"scott_morrison\", \"scott_morrison\", \"scott_morrison\", \"season\", \"season\", \"season\", \"season\", \"season\", \"seem\", \"seem\", \"seem\", \"seem\", \"self\", \"self\", \"self\", \"self\", \"self\", \"semester\", \"semester\", \"semester\", \"senior\", \"senior\", \"senior\", \"senior\", \"senior\", \"senior\", \"senior\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"severe\", \"severe\", \"severe\", \"severe\", \"severe\", \"severe\", \"severe\", \"severe\", \"severe_acute\", \"severe_acute\", \"severe_acute\", \"shanghai\", \"shanghai\", \"shanghai\", \"shanghai\", \"shanghai\", \"shanghai\", \"shelf\", \"shelf\", \"shelf\", \"shelf\", \"ship\", \"ship\", \"ship\", \"ship\", \"ship\", \"ship\", \"shut\", \"shut\", \"shut\", \"shut\", \"shut\", \"significantly\", \"significantly\", \"significantly\", \"significantly\", \"significantly\", \"significantly\", \"singapore\", \"singapore\", \"singapore\", \"singapore\", \"singapore\", \"singapore\", \"singapore\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"smoke\", \"smoke\", \"smoke\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"sold\", \"sold\", \"sold\", \"sold\", \"sold\", \"sore\", \"sore\", \"sore\", \"sore\", \"sore_throat\", \"sore_throat\", \"south\", \"south\", \"south\", \"south\", \"south\", \"south\", \"south\", \"south\", \"south\", \"south_australia\", \"south_australia\", \"south_australia\", \"south_australia\", \"south_australia\", \"south_australia\", \"specie\", \"specie\", \"specie\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"stage\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stay_home\", \"stay_home\", \"stay_home\", \"stay_home\", \"stay_home\", \"stephen\", \"stephen\", \"stephen\", \"stephen\", \"stephen\", \"stephen\", \"stephen\", \"stock\", \"stock\", \"stock\", \"stock\", \"stock\", \"stock\", \"stock\", \"stop_spread\", \"stop_spread\", \"stop_spread\", \"stop_spread\", \"store\", \"store\", \"store\", \"store\", \"store\", \"store\", \"stress\", \"stress\", \"stress\", \"stress\", \"stress\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"summer\", \"summer\", \"summer\", \"summer\", \"summer\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"supply\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney\", \"sydney_airport\", \"sydney_airport\", \"symptom\", \"symptom\", \"symptom\", \"symptom\", \"symptom\", \"symptom\", \"syndrome\", \"syndrome\", \"syndrome\", \"syndrome\", \"taiwan\", \"taiwan\", \"taiwan\", \"taiwan\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temporary\", \"temporary\", \"temporary\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test_result\", \"test_result\", \"test_result\", \"tested\", \"tested\", \"tested\", \"tested\", \"tested\", \"tested\", \"tested\", \"tested\", \"tested\", \"tested\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"three\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"told\", \"toll\", \"toll\", \"toll\", \"toll\", \"toll\", \"toll\", \"toll\", \"toll\", \"toll\", \"total_number\", \"total_number\", \"total_number\", \"total_number\", \"total_number\", \"total_number\", \"total_number\", \"total_number\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel\", \"travel_ban\", \"travel_ban\", \"travel_ban\", \"travel_ban\", \"travel_ban\", \"traveller\", \"traveller\", \"traveller\", \"traveller\", \"traveller\", \"traveller\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"treatment\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"typical\", \"typical\", \"typical\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"uk\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"university\", \"unprecedented\", \"unprecedented\", \"unprecedented\", \"unprecedented\", \"unprecedented\", \"untreated\", \"untreated\", \"untreated\", \"unwell\", \"unwell\", \"unwell\", \"upon\", \"upon\", \"upon\", \"upon\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"victoria\", \"victoria\", \"victoria\", \"victoria\", \"victoria\", \"victoria\", \"victoria\", \"victoria\", \"victoria\", \"victoria_january\", \"victoria_january\", \"victorian\", \"victorian\", \"victorian\", \"victorian\", \"victorian\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"vulnerable\", \"vulnerable\", \"vulnerable\", \"vulnerable\", \"vulnerable\", \"wale\", \"wale\", \"wale\", \"wale\", \"wale\", \"wale\", \"wale\", \"wale\", \"wale\", \"wale_january\", \"wale_january\", \"wale_january\", \"wale_january\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wearing_mask\", \"wearing_mask\", \"wearing_mask\", \"wearing_mask\", \"weather\", \"weather\", \"weather\", \"weather\", \"weather\", \"weather\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"western\", \"western\", \"western\", \"western\", \"western\", \"western\", \"western\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman_aged\", \"woman_aged\", \"woman_aged\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"worst\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wuhan\", \"wuhan\", \"wuhan\", \"wuhan\", \"wuhan\", \"wuhan\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year_old\", \"year_old\", \"year_old\", \"year_old\", \"year_old\", \"year_old\", \"year_old\", \"year_old\", \"yokohama_japan\", \"yokohama_japan\", \"yokohama_japan\", \"yokohama_japan\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 7, 9, 2, 8, 1, 6, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el4074019323846922964471662361\", ldavis_el4074019323846922964471662361_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el4074019323846922964471662361\", ldavis_el4074019323846922964471662361_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el4074019323846922964471662361\", ldavis_el4074019323846922964471662361_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot a graph to display the intertopic distance and the most relevant terms present in the topics\n",
    "lda_display = pyLDAvis.gensim.prepare(model_2, process_corpus, process_dic, sort_topics=True)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Mapping\n",
    "\n",
    "The dominant topics and topic percentage and the keywords for each title is being calculated and stored in a dataframe which is inturn used to find the **URL** links of the topics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkRMflCzQvV2"
   },
   "outputs": [],
   "source": [
    "#referred from - https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n",
    "#create a function to find the dominant topic, its % and the keywords used.\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Initialise the output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in every topic document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each topic document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                #Finding the keywords\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    #setting the columns for the dataframe\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Adding the text to the end of the dataframe\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    \n",
    "    #returning the dataframe\n",
    "    return(sent_topics_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "m3QvZMxY3MO_",
    "outputId": "56edd3a9-0f2a-4b9e-9366-bfce6accbe2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[canberra, experienced, worst, air, quality, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[dawn, broke, blackened, australian, landscape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[baby, brain, body, grow, lot, first, six, mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[living, polluted, city, may, make, bone, weak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[researcher, developed, new, battery, claim, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[scientist, discovered, specific, protein, tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[washington, jan, xinhua, international, team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[published, aedt, january, updated, aedt, janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[firefighter, celebrating, reprieve, week, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>university, australia, also, area, people, yea...</td>\n",
       "      <td>[washington, urdupoint, pakistan, point, news,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             1.0              0.9767   \n",
       "1            1             1.0              0.8514   \n",
       "2            2             1.0              0.9993   \n",
       "3            3             1.0              0.9998   \n",
       "4            4             1.0              0.9992   \n",
       "5            5             1.0              0.9995   \n",
       "6            6             1.0              0.9987   \n",
       "7            7             1.0              0.8395   \n",
       "8            8             1.0              0.9126   \n",
       "9            9             1.0              0.9988   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  university, australia, also, area, people, yea...   \n",
       "1  university, australia, also, area, people, yea...   \n",
       "2  university, australia, also, area, people, yea...   \n",
       "3  university, australia, also, area, people, yea...   \n",
       "4  university, australia, also, area, people, yea...   \n",
       "5  university, australia, also, area, people, yea...   \n",
       "6  university, australia, also, area, people, yea...   \n",
       "7  university, australia, also, area, people, yea...   \n",
       "8  university, australia, also, area, people, yea...   \n",
       "9  university, australia, also, area, people, yea...   \n",
       "\n",
       "                                                Text  \n",
       "0  [canberra, experienced, worst, air, quality, r...  \n",
       "1  [dawn, broke, blackened, australian, landscape...  \n",
       "2  [baby, brain, body, grow, lot, first, six, mon...  \n",
       "3  [living, polluted, city, may, make, bone, weak...  \n",
       "4  [researcher, developed, new, battery, claim, p...  \n",
       "5  [scientist, discovered, specific, protein, tri...  \n",
       "6  [washington, jan, xinhua, international, team,...  \n",
       "7  [published, aedt, january, updated, aedt, janu...  \n",
       "8  [firefighter, celebrating, reprieve, week, dev...  \n",
       "9  [washington, urdupoint, pakistan, point, news,...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the dominant topic for model 1\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=model_1, corpus=process_corpus, texts=process_docs)\n",
    "# Formatting the dataframe for displaying\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "#display a snippet \n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "O-ZNpsVo3AUo",
    "outputId": "5e30f77a-ffa7-42dd-cccc-dc2c93999ad8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>area, cell, australian, australia, smoke, air,...</td>\n",
       "      <td>[canberra, experienced, worst, air, quality, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>fire, australia, year, bushfires, south, clima...</td>\n",
       "      <td>[dawn, broke, blackened, australian, landscape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>university, say, time, one, also, could, year,...</td>\n",
       "      <td>[baby, brain, body, grow, lot, first, six, mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>university, say, time, one, also, could, year,...</td>\n",
       "      <td>[living, polluted, city, may, make, bone, weak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>university, say, time, one, also, could, year,...</td>\n",
       "      <td>[researcher, developed, new, battery, claim, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>university, say, time, one, also, could, year,...</td>\n",
       "      <td>[scientist, discovered, specific, protein, tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>area, cell, australian, australia, smoke, air,...</td>\n",
       "      <td>[washington, jan, xinhua, international, team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8134</td>\n",
       "      <td>fire, australia, year, bushfires, south, clima...</td>\n",
       "      <td>[published, aedt, january, updated, aedt, janu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>fire, australia, year, bushfires, south, clima...</td>\n",
       "      <td>[firefighter, celebrating, reprieve, week, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>area, cell, australian, australia, smoke, air,...</td>\n",
       "      <td>[washington, urdupoint, pakistan, point, news,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             5.0              0.4085   \n",
       "1            1             2.0              0.7010   \n",
       "2            2             1.0              0.8275   \n",
       "3            3             1.0              0.4375   \n",
       "4            4             1.0              0.8222   \n",
       "5            5             1.0              0.4541   \n",
       "6            6             5.0              0.4186   \n",
       "7            7             2.0              0.8134   \n",
       "8            8             2.0              0.9988   \n",
       "9            9             5.0              0.4046   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  area, cell, australian, australia, smoke, air,...   \n",
       "1  fire, australia, year, bushfires, south, clima...   \n",
       "2  university, say, time, one, also, could, year,...   \n",
       "3  university, say, time, one, also, could, year,...   \n",
       "4  university, say, time, one, also, could, year,...   \n",
       "5  university, say, time, one, also, could, year,...   \n",
       "6  area, cell, australian, australia, smoke, air,...   \n",
       "7  fire, australia, year, bushfires, south, clima...   \n",
       "8  fire, australia, year, bushfires, south, clima...   \n",
       "9  area, cell, australian, australia, smoke, air,...   \n",
       "\n",
       "                                                Text  \n",
       "0  [canberra, experienced, worst, air, quality, r...  \n",
       "1  [dawn, broke, blackened, australian, landscape...  \n",
       "2  [baby, brain, body, grow, lot, first, six, mon...  \n",
       "3  [living, polluted, city, may, make, bone, weak...  \n",
       "4  [researcher, developed, new, battery, claim, p...  \n",
       "5  [scientist, discovered, specific, protein, tri...  \n",
       "6  [washington, jan, xinhua, international, team,...  \n",
       "7  [published, aedt, january, updated, aedt, janu...  \n",
       "8  [firefighter, celebrating, reprieve, week, dev...  \n",
       "9  [washington, urdupoint, pakistan, point, news,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the dominant topic for model 2\n",
    "df_topic_sents_keywords2 = format_topics_sentences(ldamodel=model_2, corpus=process_corpus, texts=process_docs)\n",
    "# Formatting the dataframe for displaying \n",
    "df_dominant_topic2 = df_topic_sents_keywords2.reset_index()\n",
    "df_dominant_topic2.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "#display a snippet\n",
    "df_dominant_topic2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "waCslrGKQvbt",
    "outputId": "c1992550-dbc5-4831-cf66-8eb74e1e486d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 143, 0.0: 223})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the dominant topic for model 1\n",
    "Counter(df_dominant_topic['Dominant_Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "WM3pvXb2QvSJ",
    "outputId": "6b06ac5f-a99d-4167-c66c-3a8b4c4b700d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5.0: 26,\n",
       "         2.0: 31,\n",
       "         1.0: 52,\n",
       "         0.0: 21,\n",
       "         6.0: 85,\n",
       "         7.0: 35,\n",
       "         3.0: 12,\n",
       "         9.0: 46,\n",
       "         8.0: 49,\n",
       "         4.0: 9})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the dominant topic for model 2\n",
    "Counter(df_dominant_topic2['Dominant_Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "zI92HA22o_Sf",
    "outputId": "5f8b16d7-0586-4fbd-ebe3-1a31be3b7eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dailymail.co.uk/news/article-8009293/Coronavirus-crisis-Australian-expatriates-China-disease-changed-lives.html\n"
     ]
    }
   ],
   "source": [
    "#Finding the url corresponding to the dominant topic\n",
    "model1_url = df.iloc[223]['url']\n",
    "print(model1_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "CXxnCW0z74ja",
    "outputId": "559b13ba-7f24-481f-825a-7a77f1af9b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://global.chinadaily.com.cn/a/202001/08/WS5e153594a310cf3e35583232.html\n"
     ]
    }
   ],
   "source": [
    "#finding the url corresponding to the dominant topic\n",
    "model2_url = df.iloc[26]['url']\n",
    "print(model2_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUT :\n",
    "Based on the dominant topics we have considered two topics as examples one for topic 5 and topic 9, to support our inferences.\n",
    "In Topic 1, that relates to the work-rights and job, article from the news https://www.dailymail.co.uk/news/article-8009293/Coronavirus-crisis-Australian-expatriates-China-disease-changed-lives.html dated 16/02/2020 gives a view on the employment sector of Australia being affected by Coronavirus, where the article quotes\n",
    "Related to topic 3 on study made by Australian students on climate change  , as quoted in article http://global.chinadaily.com.cn/a/202001/08/WS5e153594a310cf3e35583232.html dated 08/01/2020 states the damage caused by the bushfires and also its adverse future climatic effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "#### RNN\n",
    "<li>Tutorial materials\n",
    "<li>https://discuss.pytorch.org/t/what-is-manual-seed/5939/10\n",
    "<li>https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/\n",
    "<li>https://discuss.pytorch.org/t/type-object-tabulardataset-has-no-attribute/58590\n",
    "<li> https://torchtext.readthedocs.io/en/latest/data.html\n",
    "<li>https://github.com/pytorch/text/issues/430</li>\n",
    "\n",
    "#### Statistical modelling :\n",
    "<li>Tutorial materials\n",
    "<li>https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "<li>https://www.geeksforgeeks.org/confusion-matrix-machine-learning/</li>\n",
    "\n",
    "#### Topic modelling:\n",
    "<li>Tutorial materials\n",
    "<li>https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "<li>https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "<li>https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "<li>https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "<li>http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
    "<li>https://stats.stackexchange.com/questions/18167/how-to-calculate-perplexity-of-a-holdout-with-latent-dirichlet-allocation\n",
    "<li>https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n",
    "<li>https://cfss.uchicago.edu/notes/topic-modeling/\n",
    "<li>https://tedboy.github.io/nlps/generated/generated/gensim.models.LdaModel.log_perplexity.html\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_semi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
